# Migration AWS - Architecture SOXauto PG-01

## üîÑ Adaptation de l'Architecture GCP vers AWS

### Comparaison des Services

| Fonction | Google Cloud (Actuel) | AWS (Production) | Impact Code |
|----------|----------------------|------------------|-------------|
| **Conteneurisation** | Cloud Run | AWS Fargate + ECS | ‚úÖ Aucun - m√™me Dockerfile |
| **Planification** | Cloud Scheduler | Amazon EventBridge (CloudWatch Events) | ‚úÖ Aucun - m√™me endpoint HTTP |
| **Secrets** | Secret Manager | AWS Secrets Manager | üî∂ Changement mineur API |
| **Data Warehouse** | BigQuery | Amazon Redshift / S3 | üî∂ Changement driver DB |
| **Monitoring** | Cloud Monitoring | CloudWatch | ‚úÖ Aucun - logs standard |
| **Storage** | Cloud Storage | Amazon S3 | üî∂ Changement API storage |

---

## üìÅ Structure de Migration

### 1. Adaptation des Utilitaires Cloud

**Nouveau fichier:** `aws_utils.py` (√©quivalent de `gcp_utils.py`)

```python
# aws_utils.py - Adaptation pour AWS
import boto3
import pandas as pd
from botocore.exceptions import ClientError
import json
import logging

class AWSSecretsManager:
    def __init__(self, region_name='eu-west-1'):
        self.client = boto3.client('secretsmanager', region_name=region_name)
    
    def get_secret(self, secret_name):
        try:
            response = self.client.get_secret_value(SecretId=secret_name)
            return response['SecretString']
        except ClientError as e:
            logging.error(f"Erreur r√©cup√©ration secret {secret_name}: {e}")
            raise

class AWSRedshiftManager:
    def __init__(self, cluster_endpoint, database, user):
        # Configuration Redshift
        pass
    
    def write_dataframe(self, df, table_name):
        # √âcriture dans Redshift via S3 staging
        pass
```

### 2. Configuration AWS

**Nouveau fichier:** `config_aws.py`

```python
# config_aws.py
import os

# Configuration AWS
AWS_REGION = os.getenv('AWS_REGION', 'eu-west-1')
AWS_ACCOUNT_ID = os.getenv('AWS_ACCOUNT_ID')

# Secrets
DB_SECRET_NAME = "jumia/sox/db-credentials"
SERVICE_ACCOUNT_SECRET = "jumia/sox/service-account"

# Data Storage
REDSHIFT_CLUSTER = "jumia-sox-cluster"
REDSHIFT_DATABASE = "jumia_sox"
REDSHIFT_SCHEMA = "reconciliation"
TABLE_PREFIX = "pg01_validated_ipe"

# S3 Configuration
S3_BUCKET = "jumia-sox-data-lake"
S3_PREFIX = "sox-automation/pg01/"

# ECS/Fargate Configuration
ECS_CLUSTER_NAME = "jumia-sox-cluster"
TASK_DEFINITION = "soxauto-pg01"
```

---

## üöÄ D√©ploiement AWS

### 1. Infrastructure as Code (Terraform)

**Fichier:** `infrastructure/main.tf`

```hcl
# D√©finition du cluster ECS Fargate
resource "aws_ecs_cluster" "sox_cluster" {
  name = "jumia-sox-cluster"
  
  setting {
    name  = "containerInsights"
    value = "enabled"
  }
}

# Task Definition pour SOXauto PG-01
resource "aws_ecs_task_definition" "soxauto_pg01" {
  family                   = "soxauto-pg01"
  network_mode             = "awsvpc"
  requires_compatibilities = ["FARGATE"]
  cpu                      = 2048
  memory                   = 4096
  execution_role_arn       = aws_iam_role.ecs_execution_role.arn
  task_role_arn           = aws_iam_role.ecs_task_role.arn

  container_definitions = jsonencode([
    {
      name  = "soxauto-pg01"
      image = "${aws_ecr_repository.soxauto.repository_url}:latest"
      
      environment = [
        {
          name  = "AWS_REGION"
          value = var.aws_region
        }
      ]
      
      secrets = [
        {
          name      = "DB_CONNECTION_STRING"
          valueFrom = aws_secretsmanager_secret.db_credentials.arn
        }
      ]
      
      logConfiguration = {
        logDriver = "awslogs"
        options = {
          awslogs-group         = aws_cloudwatch_log_group.soxauto.name
          awslogs-region        = var.aws_region
          awslogs-stream-prefix = "ecs"
        }
      }
    }
  ])
}

# EventBridge pour planification mensuelle
resource "aws_cloudwatch_event_rule" "monthly_sox" {
  name                = "sox-pg01-monthly"
  description         = "D√©clenchement mensuel SOX PG-01"
  schedule_expression = "cron(0 9 1 * ? *)"  # 1er de chaque mois √† 9h
}

resource "aws_cloudwatch_event_target" "ecs_target" {
  rule      = aws_cloudwatch_event_rule.monthly_sox.name
  target_id = "SOXAutoPG01Target"
  arn       = aws_ecs_cluster.sox_cluster.arn
  role_arn  = aws_iam_role.eventbridge_role.arn

  ecs_target {
    task_definition_arn = aws_ecs_task_definition.soxauto_pg01.arn
    launch_type         = "FARGATE"
    platform_version    = "LATEST"
    
    network_configuration {
      subnets         = var.private_subnet_ids
      security_groups = [aws_security_group.ecs_tasks.id]
    }
  }
}
```

### 2. Script de D√©ploiement

**Fichier:** `deploy_aws.sh`

```bash
#!/bin/bash
# deploy_aws.sh - D√©ploiement SOXauto PG-01 sur AWS

set -e

# Variables
AWS_REGION="eu-west-1"
ECR_REPOSITORY="jumia/soxauto-pg01"
IMAGE_TAG="latest"

echo "üöÄ D√©ploiement SOXauto PG-01 sur AWS"

# 1. Build et push de l'image Docker vers ECR
echo "üì¶ Construction et push de l'image Docker..."
aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $ECR_REPOSITORY

docker build -t $ECR_REPOSITORY:$IMAGE_TAG .
docker push $ECR_REPOSITORY:$IMAGE_TAG

# 2. D√©ploiement de l'infrastructure Terraform
echo "üèóÔ∏è D√©ploiement de l'infrastructure..."
cd infrastructure
terraform init
terraform plan -var="image_tag=$IMAGE_TAG"
terraform apply -var="image_tag=$IMAGE_TAG" -auto-approve

# 3. Cr√©ation des secrets
echo "üîê Configuration des secrets..."
aws secretsmanager create-secret \
    --name "jumia/sox/db-credentials" \
    --description "Credentials pour base de donn√©es NAV" \
    --secret-string file://secrets/db-connection.json

# 4. Test de l'endpoint
echo "üß™ Test de l'endpoint..."
TASK_ARN=$(aws ecs list-tasks --cluster jumia-sox-cluster --query 'taskArns[0]' --output text)
echo "Task d√©ploy√©e: $TASK_ARN"

echo "‚úÖ D√©ploiement termin√© avec succ√®s!"
```

---

## üîß Adaptations du Code Python

### Points de Modification Minimes

**Dans `main.py`:**
```python
# Changement d'import
# from gcp_utils import initialize_gcp_services
from aws_utils import initialize_aws_services

# Adaptation de l'initialisation
def execute_ipe_workflow():
    # secret_manager, bigquery_client = initialize_gcp_services(GCP_PROJECT_ID)
    secret_manager, redshift_client = initialize_aws_services(AWS_REGION)
    
    # Le reste du code reste identique
    for ipe_config in IPE_CONFIGS:
        runner = IPERunner(ipe_config=ipe_config, secret_manager=secret_manager)
        # ...
```

**Dans `ipe_runner.py`:**
```python
# Aucun changement n√©cessaire - la classe reste identique
# Seules les m√©thodes d'acc√®s aux secrets changent dans aws_utils.py
```

---

## üìä Avantages de l'Architecture AWS

### Performance
- **Fargate:** Scaling automatique sans gestion de serveurs
- **Redshift:** Optimis√© pour l'analytics sur gros volumes
- **S3:** Storage illimit√© et durable

### S√©curit√©
- **Secrets Manager:** Rotation automatique des credentials
- **IAM Roles:** Permissions granulaires
- **VPC:** Isolation r√©seau

### Co√ªts
- **Pay-as-you-use:** Factur√© seulement √† l'ex√©cution
- **Reserved Capacity:** R√©ductions pour Redshift
- **S3 Intelligent Tiering:** Optimisation automatique des co√ªts

---

## üìÖ Plan de Migration

### Phase 1: Pr√©paration (Semaine 1)
- [ ] Validation de l'architecture avec l'√©quipe AWS
- [ ] Cr√©ation des comptes et permissions AWS
- [ ] Adaptation du code pour AWS (aws_utils.py)

### Phase 2: Infrastructure (Semaine 2)
- [ ] D√©ploiement Terraform de l'infrastructure
- [ ] Configuration des secrets
- [ ] Tests de connectivit√©

### Phase 3: D√©ploiement (Semaine 3)
- [ ] Build et push de l'image vers ECR
- [ ] D√©ploiement de la t√¢che ECS
- [ ] Configuration EventBridge
- [ ] Tests end-to-end

### Phase 4: Production (Semaine 4)
- [ ] Monitoring et alertes CloudWatch
- [ ] Documentation op√©rationnelle
- [ ] Formation √©quipe support
- [ ] Go-live

---

**‚úÖ Conclusion:** Votre code Python actuel est √† 95% compatible AWS. Seules les couches d'acc√®s aux services cloud n√©cessitent une adaptation, ce qui confirme la robustesse de votre architecture.