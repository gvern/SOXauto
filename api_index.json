{
  "repo": "C:\\Users\\gustave.vernay.avisi\\Desktop\\SOXauto",
  "scanned_files_count": 106,
  "items_count": 772,
  "generated_by": "scan_repo_api.py",
  "items": [
    {
      "kind": "function",
      "async": false,
      "name": "example_1_clean_merge",
      "qualname": "example_1_clean_merge",
      "enclosing": [],
      "module": "scripts.audit_merge_examples",
      "file": "scripts\\audit_merge_examples.py",
      "lineno": 18,
      "end_lineno": 57,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Example 1: Clean merge with no duplicates.",
        "returns": null,
        "raw": "Example 1: Clean merge with no duplicates.\n\nThis is the ideal scenario - one-to-one relationship."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "example_2_data_quality_issue",
      "qualname": "example_2_data_quality_issue",
      "enclosing": [],
      "module": "scripts.audit_merge_examples",
      "file": "scripts\\audit_merge_examples.py",
      "lineno": 60,
      "end_lineno": 102,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Example 2: Data quality issue - duplicate customer records.",
        "returns": null,
        "raw": "Example 2: Data quality issue - duplicate customer records.\n\nThis scenario indicates a problem in the source system where\nthe same customer appears multiple times in the IPE extract."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "example_3_cartesian_product_danger",
      "qualname": "example_3_cartesian_product_danger",
      "enclosing": [],
      "module": "scripts.audit_merge_examples",
      "file": "scripts\\audit_merge_examples.py",
      "lineno": 105,
      "end_lineno": 152,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Example 3: Cartesian product risk - both sides have duplicates.",
        "returns": null,
        "raw": "Example 3: Cartesian product risk - both sides have duplicates.\n\nThis is the dangerous scenario that audit_merge is designed to catch.\nMerging would create an exploding join."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "example_4_composite_key",
      "qualname": "example_4_composite_key",
      "enclosing": [],
      "module": "scripts.audit_merge_examples",
      "file": "scripts\\audit_merge_examples.py",
      "lineno": 155,
      "end_lineno": 197,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Example 4: Multi-column join key (composite key).",
        "returns": null,
        "raw": "Example 4: Multi-column join key (composite key).\n\nShows how to audit merges on multiple columns."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "example_5_integration_in_workflow",
      "qualname": "example_5_integration_in_workflow",
      "enclosing": [],
      "module": "scripts.audit_merge_examples",
      "file": "scripts\\audit_merge_examples.py",
      "lineno": 200,
      "end_lineno": 264,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Example 5: Integration into a reconciliation workflow.",
        "returns": null,
        "raw": "Example 5: Integration into a reconciliation workflow.\n\nShows how to use audit_merge as a safety check in production code."
      }
    },
    {
      "kind": "nested_function",
      "async": false,
      "name": "safe_reconciliation",
      "qualname": "example_5_integration_in_workflow.safe_reconciliation",
      "enclosing": [
        "example_5_integration_in_workflow"
      ],
      "module": "scripts.audit_merge_examples",
      "file": "scripts\\audit_merge_examples.py",
      "lineno": 210,
      "end_lineno": 250,
      "decorators": [],
      "parameters": [
        {
          "name": "ipe_df",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "gl_df",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "join_key",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Reconciliation workflow with built-in merge auditing.",
        "returns": null,
        "raw": "Reconciliation workflow with built-in merge auditing."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.audit_merge_examples",
      "file": "scripts\\audit_merge_examples.py",
      "lineno": 267,
      "end_lineno": 285,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Run all examples.",
        "returns": null,
        "raw": "Run all examples."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "build_connection_string",
      "qualname": "build_connection_string",
      "enclosing": [],
      "module": "scripts.check_mssql_connection",
      "file": "scripts\\check_mssql_connection.py",
      "lineno": 23,
      "end_lineno": 50,
      "decorators": [],
      "parameters": [],
      "return_annotation": "str",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.check_mssql_connection",
      "file": "scripts\\check_mssql_connection.py",
      "lineno": 53,
      "end_lineno": 82,
      "decorators": [],
      "parameters": [],
      "return_annotation": "int",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "load_inputs",
      "qualname": "load_inputs",
      "enclosing": [],
      "module": "scripts.classify_bridges",
      "file": "scripts\\classify_bridges.py",
      "lineno": 37,
      "end_lineno": 52,
      "decorators": [],
      "parameters": [
        {
          "name": "paths",
          "kind": "positional_or_keyword",
          "annotation": "List[str]",
          "default": null
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.classify_bridges",
      "file": "scripts\\classify_bridges.py",
      "lineno": 55,
      "end_lineno": 70,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "excecute_spark_sql",
      "qualname": "excecute_spark_sql",
      "enclosing": [],
      "module": "scripts.database_ingestion",
      "file": "scripts\\database_ingestion.py",
      "lineno": 61,
      "end_lineno": 176,
      "decorators": [],
      "parameters": [
        {
          "name": "spark",
          "kind": "positional_or_keyword",
          "annotation": "SparkSession",
          "default": null
        },
        {
          "name": "query_list",
          "kind": "positional_or_keyword",
          "annotation": "List[str]",
          "default": null
        },
        {
          "name": "entity_config",
          "kind": "positional_or_keyword",
          "annotation": "Dict",
          "default": null
        },
        {
          "name": "connection_type",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "DataFrame",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.database_ingestion",
      "file": "scripts\\database_ingestion.py",
      "lineno": 179,
      "end_lineno": 208,
      "decorators": [],
      "parameters": [
        {
          "name": "entity",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "connection_type",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "config_root_uri",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "spark_config",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.debug_live_category",
      "file": "scripts\\debug_live_category.py",
      "lineno": 10,
      "end_lineno": 52,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.demo_debug_probe",
      "file": "scripts\\demo_debug_probe.py",
      "lineno": 21,
      "end_lineno": 135,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Demonstrate debug_probe usage.",
        "returns": null,
        "raw": "Demonstrate debug_probe usage."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "fetch_fixtures_for_entity",
      "qualname": "fetch_fixtures_for_entity",
      "enclosing": [],
      "module": "scripts.example_fetch_fixtures",
      "file": "scripts\\example_fetch_fixtures.py",
      "lineno": 13,
      "end_lineno": 54,
      "decorators": [],
      "parameters": [
        {
          "name": "entity",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "None",
      "doc": {
        "summary": "Fetch live fixtures for a specific entity.",
        "returns": null,
        "raw": "Fetch live fixtures for a specific entity.\n\nArgs:\n    entity: Entity code (e.g., 'EC_NG', 'JD_GH')"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.example_fetch_fixtures",
      "file": "scripts\\example_fetch_fixtures.py",
      "lineno": 57,
      "end_lineno": 101,
      "decorators": [],
      "parameters": [],
      "return_annotation": "None",
      "doc": {
        "summary": "Main function to demonstrate fetching fixtures for multiple entities.",
        "returns": null,
        "raw": "Main function to demonstrate fetching fixtures for multiple entities."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "simulate_reconciliation_workflow",
      "qualname": "simulate_reconciliation_workflow",
      "enclosing": [],
      "module": "scripts.example_reconciliation_with_probes",
      "file": "scripts\\example_reconciliation_with_probes.py",
      "lineno": 21,
      "end_lineno": 171,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Simulate a typical reconciliation workflow with debug probes.",
        "returns": null,
        "raw": "Simulate a typical reconciliation workflow with debug probes.\n\nThis shows how to instrument an existing workflow without refactoring."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.example_reconciliation_with_probes",
      "file": "scripts\\example_reconciliation_with_probes.py",
      "lineno": 174,
      "end_lineno": 183,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Run the integration example.",
        "returns": null,
        "raw": "Run the integration example."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_output_dir",
      "qualname": "get_output_dir",
      "enclosing": [],
      "module": "scripts.fetch_live_fixtures",
      "file": "scripts\\fetch_live_fixtures.py",
      "lineno": 53,
      "end_lineno": 63,
      "decorators": [],
      "parameters": [
        {
          "name": "entity",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "Path",
      "doc": {
        "summary": "Get the output directory path for a given entity.",
        "returns": "Path object for the entity-specific fixtures directory",
        "raw": "Get the output directory path for a given entity.\n\nArgs:\n    entity: Entity code (e.g., 'EC_NG', 'JD_GH')\n    \nReturns:\n    Path object for the entity-specific fixtures directory"
      }
    },
    {
      "kind": "function",
      "async": true,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.fetch_live_fixtures",
      "file": "scripts\\fetch_live_fixtures.py",
      "lineno": 66,
      "end_lineno": 172,
      "decorators": [],
      "parameters": [
        {
          "name": "entity",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "'EC_NG'"
        }
      ],
      "return_annotation": "None",
      "doc": {
        "summary": "Fetch live fixtures from SQL Server and save to entity-specific folders.",
        "returns": null,
        "raw": "Fetch live fixtures from SQL Server and save to entity-specific folders.\n\nThis function connects to the SQL Server database (via mocked connection in this script)\nand extracts IPE/CR data for the specified entity. Data is saved as CSV files in \ntests/fixtures/{entity}/ directory. Existing files like JDASH.csv are preserved.\n\nArgs:\n    entity: Entity code (e.g., 'EC_NG', 'JD_GH'). Must be in ALLOWED_ENTITIES whitelist.\n    \nRaises:\n    ValueError: If entity is not in the ALLOWED_ENTITIES whitelist."
      }
    },
    {
      "kind": "nested_function",
      "async": false,
      "name": "patched_exec",
      "qualname": "main.patched_exec",
      "enclosing": [
        "main"
      ],
      "module": "scripts.fetch_live_fixtures",
      "file": "scripts\\fetch_live_fixtures.py",
      "lineno": 147,
      "end_lineno": 149,
      "decorators": [],
      "parameters": [
        {
          "name": "query",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "params",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "None"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "build_connection_string",
      "qualname": "build_connection_string",
      "enclosing": [],
      "module": "scripts.generate_collection_accounts",
      "file": "scripts\\generate_collection_accounts.py",
      "lineno": 34,
      "end_lineno": 50,
      "decorators": [],
      "parameters": [],
      "return_annotation": "str",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "validate_output",
      "qualname": "validate_output",
      "enclosing": [],
      "module": "scripts.generate_collection_accounts",
      "file": "scripts\\generate_collection_accounts.py",
      "lineno": 53,
      "end_lineno": 69,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "dict",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.generate_collection_accounts",
      "file": "scripts\\generate_collection_accounts.py",
      "lineno": 72,
      "end_lineno": 116,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "build_connection_string",
      "qualname": "build_connection_string",
      "enclosing": [],
      "module": "scripts.generate_customer_accounts",
      "file": "scripts\\generate_customer_accounts.py",
      "lineno": 39,
      "end_lineno": 55,
      "decorators": [],
      "parameters": [],
      "return_annotation": "str",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "validate_output",
      "qualname": "validate_output",
      "enclosing": [],
      "module": "scripts.generate_customer_accounts",
      "file": "scripts\\generate_customer_accounts.py",
      "lineno": 58,
      "end_lineno": 89,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "dict",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.generate_customer_accounts",
      "file": "scripts\\generate_customer_accounts.py",
      "lineno": 92,
      "end_lineno": 140,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.generate_evidence_packages",
      "file": "scripts\\generate_evidence_packages.py",
      "lineno": 15,
      "end_lineno": 89,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "build_connection_string",
      "qualname": "build_connection_string",
      "enclosing": [],
      "module": "scripts.generate_other_ar",
      "file": "scripts\\generate_other_ar.py",
      "lineno": 35,
      "end_lineno": 51,
      "decorators": [],
      "parameters": [],
      "return_annotation": "str",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "run_contributor",
      "qualname": "run_contributor",
      "enclosing": [],
      "module": "scripts.generate_other_ar",
      "file": "scripts\\generate_other_ar.py",
      "lineno": 54,
      "end_lineno": 96,
      "decorators": [],
      "parameters": [
        {
          "name": "ipe_id",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "conn",
          "kind": "positional_or_keyword",
          "annotation": "pyodbc.Connection",
          "default": null
        }
      ],
      "return_annotation": "Tuple[str, pd.DataFrame, str]",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.generate_other_ar",
      "file": "scripts\\generate_other_ar.py",
      "lineno": 99,
      "end_lineno": 123,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "inspect_columns",
      "qualname": "inspect_columns",
      "enclosing": [],
      "module": "scripts.inspect_columns",
      "file": "scripts\\inspect_columns.py",
      "lineno": 4,
      "end_lineno": 32,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_columns_for_view",
      "qualname": "get_columns_for_view",
      "enclosing": [],
      "module": "scripts.inspect_schemas",
      "file": "scripts\\inspect_schemas.py",
      "lineno": 28,
      "end_lineno": 51,
      "decorators": [],
      "parameters": [
        {
          "name": "cursor",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "view_name",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.inspect_schemas",
      "file": "scripts\\inspect_schemas.py",
      "lineno": 53,
      "end_lineno": 76,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "calculate_integration_error_adjustment",
      "qualname": "calculate_integration_error_adjustment",
      "enclosing": [],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 32,
      "end_lineno": 33,
      "decorators": [],
      "parameters": [
        {
          "name": "_",
          "kind": "vararg",
          "annotation": null,
          "default": null
        },
        {
          "name": "__",
          "kind": "kwarg",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "__init__",
      "qualname": "Box.__init__",
      "enclosing": [
        "Box"
      ],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 46,
      "end_lineno": 48,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "title",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "width",
          "kind": "positional_or_keyword",
          "annotation": "int",
          "default": "61"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "header",
      "qualname": "Box.header",
      "enclosing": [
        "Box"
      ],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 50,
      "end_lineno": 60,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "line",
      "qualname": "Box.line",
      "enclosing": [
        "Box"
      ],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 62,
      "end_lineno": 63,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "text",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "footer",
      "qualname": "Box.footer",
      "enclosing": [
        "Box"
      ],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 65,
      "end_lineno": 66,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "class",
      "name": "Box",
      "qualname": "Box",
      "enclosing": [],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 45,
      "end_lineno": 66,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": null,
        "raw": null
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "print_df",
      "qualname": "print_df",
      "enclosing": [],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 69,
      "end_lineno": 85,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "title",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "limit",
          "kind": "positional_or_keyword",
          "annotation": "int",
          "default": "10"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "hr",
      "qualname": "hr",
      "enclosing": [],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 88,
      "end_lineno": 90,
      "decorators": [],
      "parameters": [
        {
          "name": "title",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "load_fixtures",
      "qualname": "load_fixtures",
      "enclosing": [],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 96,
      "end_lineno": 187,
      "decorators": [],
      "parameters": [
        {
          "name": "country_code",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "run_task2_vtc",
      "qualname": "run_task2_vtc",
      "enclosing": [],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 193,
      "end_lineno": 229,
      "decorators": [],
      "parameters": [
        {
          "name": "fixtures",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "categorized_cr03",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "None"
        },
        {
          "name": "fx_converter",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "None"
        },
        {
          "name": "cutoff_date",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "None"
        },
        {
          "name": "quiet",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "False"
        },
        {
          "name": "limit",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "10"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "run_task3_integration",
      "qualname": "run_task3_integration",
      "enclosing": [],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 232,
      "end_lineno": 260,
      "decorators": [],
      "parameters": [
        {
          "name": "fixtures",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "fx_converter",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "None"
        },
        {
          "name": "quiet",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "False"
        },
        {
          "name": "limit",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "10"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "run_task4_customer_reclass",
      "qualname": "run_task4_customer_reclass",
      "enclosing": [],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 263,
      "end_lineno": 282,
      "decorators": [],
      "parameters": [
        {
          "name": "fixtures",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "quiet",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "False"
        },
        {
          "name": "limit",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "10"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "run_task1_timing_diff",
      "qualname": "run_task1_timing_diff",
      "enclosing": [],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 285,
      "end_lineno": 309,
      "decorators": [],
      "parameters": [
        {
          "name": "fixtures",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "cutoff_date",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "None"
        },
        {
          "name": "quiet",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "False"
        },
        {
          "name": "limit",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "10"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "print_summary",
      "qualname": "print_summary",
      "enclosing": [],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 315,
      "end_lineno": 348,
      "decorators": [],
      "parameters": [
        {
          "name": "task1",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "task2",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "task3",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "task4",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "parse_args",
      "qualname": "parse_args",
      "enclosing": [],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 354,
      "end_lineno": 380,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.run_classifier_test",
      "file": "scripts\\run_classifier_test.py",
      "lineno": 383,
      "end_lineno": 481,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "load_historical_sheet",
      "qualname": "load_historical_sheet",
      "enclosing": [],
      "module": "scripts.run_demo",
      "file": "scripts\\run_demo.py",
      "lineno": 31,
      "end_lineno": 50,
      "decorators": [],
      "parameters": [
        {
          "name": "file_name",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "sheet_name",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "header_keyword",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Loads a specific sheet from an Excel file, intelligently finding the header row.",
        "returns": null,
        "raw": "Loads a specific sheet from an Excel file, intelligently finding the header row."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "normalize_for_bridges",
      "qualname": "normalize_for_bridges",
      "enclosing": [],
      "module": "scripts.run_demo",
      "file": "scripts\\run_demo.py",
      "lineno": 52,
      "end_lineno": 72,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Best-effort normalization to prepare data for the bridge classifier.",
        "returns": null,
        "raw": "Best-effort normalization to prepare data for the bridge classifier."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.run_demo",
      "file": "scripts\\run_demo.py",
      "lineno": 74,
      "end_lineno": 176,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": true,
      "name": "start_workflow",
      "qualname": "start_workflow",
      "enclosing": [],
      "module": "scripts.run_full_reconciliation_temporal_DEPRECATED",
      "file": "scripts\\run_full_reconciliation_temporal_DEPRECATED.py",
      "lineno": 33,
      "end_lineno": 142,
      "decorators": [],
      "parameters": [
        {
          "name": "cutoff_date",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "gl_accounts",
          "kind": "positional_or_keyword",
          "annotation": "list[str]",
          "default": null
        },
        {
          "name": "year_start",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "year_end",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Start the C-PG-1 reconciliation workflow.",
        "returns": "Workflow execution result",
        "raw": "Start the C-PG-1 reconciliation workflow.\n\nArgs:\n    cutoff_date: Cutoff date for reconciliation (YYYY-MM-DD)\n    gl_accounts: List of GL accounts to reconcile\n    year_start: Start of year for GL entries (YYYY-MM-DD)\n    year_end: End of year for GL entries (YYYY-MM-DD)\n    \nReturns:\n    Workflow execution result"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.run_full_reconciliation_temporal_DEPRECATED",
      "file": "scripts\\run_full_reconciliation_temporal_DEPRECATED.py",
      "lineno": 145,
      "end_lineno": 205,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Parse arguments and start the workflow.",
        "returns": null,
        "raw": "Parse arguments and start the workflow."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "parse_args",
      "qualname": "parse_args",
      "enclosing": [],
      "module": "scripts.run_headless_test",
      "file": "scripts\\run_headless_test.py",
      "lineno": 33,
      "end_lineno": 122,
      "decorators": [],
      "parameters": [],
      "return_annotation": "argparse.Namespace",
      "doc": {
        "summary": "Parse command line arguments.",
        "returns": null,
        "raw": "Parse command line arguments."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "load_config_file",
      "qualname": "load_config_file",
      "enclosing": [],
      "module": "scripts.run_headless_test",
      "file": "scripts\\run_headless_test.py",
      "lineno": 125,
      "end_lineno": 135,
      "decorators": [],
      "parameters": [
        {
          "name": "config_path",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Load parameters from a JSON config file.",
        "returns": null,
        "raw": "Load parameters from a JSON config file."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "build_params",
      "qualname": "build_params",
      "enclosing": [],
      "module": "scripts.run_headless_test",
      "file": "scripts\\run_headless_test.py",
      "lineno": 138,
      "end_lineno": 168,
      "decorators": [],
      "parameters": [
        {
          "name": "args",
          "kind": "positional_or_keyword",
          "annotation": "argparse.Namespace",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Build reconciliation parameters from command line arguments.",
        "returns": null,
        "raw": "Build reconciliation parameters from command line arguments."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "filter_summary_output",
      "qualname": "filter_summary_output",
      "enclosing": [],
      "module": "scripts.run_headless_test",
      "file": "scripts\\run_headless_test.py",
      "lineno": 171,
      "end_lineno": 186,
      "decorators": [],
      "parameters": [
        {
          "name": "result",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Filter result to include only summary information.",
        "returns": null,
        "raw": "Filter result to include only summary information."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.run_headless_test",
      "file": "scripts\\run_headless_test.py",
      "lineno": 189,
      "end_lineno": 281,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Main entry point for the headless reconciliation test.",
        "returns": null,
        "raw": "Main entry point for the headless reconciliation test."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "build_connection_string",
      "qualname": "build_connection_string",
      "enclosing": [],
      "module": "scripts.run_sql_from_catalog",
      "file": "scripts\\run_sql_from_catalog.py",
      "lineno": 42,
      "end_lineno": 60,
      "decorators": [],
      "parameters": [],
      "return_annotation": "str",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_items_to_run",
      "qualname": "get_items_to_run",
      "enclosing": [],
      "module": "scripts.run_sql_from_catalog",
      "file": "scripts\\run_sql_from_catalog.py",
      "lineno": 63,
      "end_lineno": 68,
      "decorators": [],
      "parameters": [
        {
          "name": "only_ids",
          "kind": "positional_or_keyword",
          "annotation": "Optional[List[str]]",
          "default": null
        }
      ],
      "return_annotation": "List",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "run_query_to_csv",
      "qualname": "run_query_to_csv",
      "enclosing": [],
      "module": "scripts.run_sql_from_catalog",
      "file": "scripts\\run_sql_from_catalog.py",
      "lineno": 71,
      "end_lineno": 83,
      "decorators": [],
      "parameters": [
        {
          "name": "conn",
          "kind": "positional_or_keyword",
          "annotation": "pyodbc.Connection",
          "default": null
        },
        {
          "name": "item",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "outdir",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.run_sql_from_catalog",
      "file": "scripts\\run_sql_from_catalog.py",
      "lineno": 86,
      "end_lineno": 114,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_scenario_1_clean_merge",
      "qualname": "test_scenario_1_clean_merge",
      "enclosing": [],
      "module": "scripts.validate_audit_merge",
      "file": "scripts\\validate_audit_merge.py",
      "lineno": 19,
      "end_lineno": 47,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test 1: Clean merge with no duplicates.",
        "returns": null,
        "raw": "Test 1: Clean merge with no duplicates."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_scenario_2_left_duplicates",
      "qualname": "test_scenario_2_left_duplicates",
      "enclosing": [],
      "module": "scripts.validate_audit_merge",
      "file": "scripts\\validate_audit_merge.py",
      "lineno": 50,
      "end_lineno": 91,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test 2: Duplicates in left DataFrame only.",
        "returns": null,
        "raw": "Test 2: Duplicates in left DataFrame only."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_scenario_3_cartesian_risk",
      "qualname": "test_scenario_3_cartesian_risk",
      "enclosing": [],
      "module": "scripts.validate_audit_merge",
      "file": "scripts\\validate_audit_merge.py",
      "lineno": 94,
      "end_lineno": 130,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test 3: Duplicates on both sides (Cartesian product risk).",
        "returns": null,
        "raw": "Test 3: Duplicates on both sides (Cartesian product risk)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_scenario_4_multi_key",
      "qualname": "test_scenario_4_multi_key",
      "enclosing": [],
      "module": "scripts.validate_audit_merge",
      "file": "scripts\\validate_audit_merge.py",
      "lineno": 133,
      "end_lineno": 163,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test 4: Multiple join keys.",
        "returns": null,
        "raw": "Test 4: Multiple join keys."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.validate_audit_merge",
      "file": "scripts\\validate_audit_merge.py",
      "lineno": 166,
      "end_lineno": 196,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Run all validation tests.",
        "returns": null,
        "raw": "Run all validation tests."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "__init__",
      "qualname": "IPEConfigValidator.__init__",
      "enclosing": [
        "IPEConfigValidator"
      ],
      "module": "scripts.validate_ipe_config",
      "file": "scripts\\validate_ipe_config.py",
      "lineno": 30,
      "end_lineno": 34,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "validate_all",
      "qualname": "IPEConfigValidator.validate_all",
      "enclosing": [
        "IPEConfigValidator"
      ],
      "module": "scripts.validate_ipe_config",
      "file": "scripts\\validate_ipe_config.py",
      "lineno": 36,
      "end_lineno": 55,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": "bool",
      "doc": {
        "summary": "Run all validation checks.",
        "returns": null,
        "raw": "Run all validation checks."
      }
    },
    {
      "kind": "class",
      "name": "IPEConfigValidator",
      "qualname": "IPEConfigValidator",
      "enclosing": [],
      "module": "scripts.validate_ipe_config",
      "file": "scripts\\validate_ipe_config.py",
      "lineno": 27,
      "end_lineno": 212,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Validates IPE configurations for security and correctness.",
        "raw": "Validates IPE configurations for security and correctness."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.validate_ipe_config",
      "file": "scripts\\validate_ipe_config.py",
      "lineno": 215,
      "end_lineno": 221,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Main execution function.",
        "returns": null,
        "raw": "Main execution function."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "demonstrate_multi_entity_fixture_loading",
      "qualname": "demonstrate_multi_entity_fixture_loading",
      "enclosing": [],
      "module": "scripts.verify_qa_fixes",
      "file": "scripts\\verify_qa_fixes.py",
      "lineno": 25,
      "end_lineno": 56,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Demonstrate multi-entity fixture loading.",
        "returns": null,
        "raw": "Demonstrate multi-entity fixture loading."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "demonstrate_vtc_date_parameter",
      "qualname": "demonstrate_vtc_date_parameter",
      "enclosing": [],
      "module": "scripts.verify_qa_fixes",
      "file": "scripts\\verify_qa_fixes.py",
      "lineno": 59,
      "end_lineno": 96,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Demonstrate VTC date parameter wiring.",
        "returns": null,
        "raw": "Demonstrate VTC date parameter wiring."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "demonstrate_script_parameter_flow",
      "qualname": "demonstrate_script_parameter_flow",
      "enclosing": [],
      "module": "scripts.verify_qa_fixes",
      "file": "scripts\\verify_qa_fixes.py",
      "lineno": 99,
      "end_lineno": 135,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Demonstrate script parameter flow.",
        "returns": null,
        "raw": "Demonstrate script parameter flow."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "scripts.verify_qa_fixes",
      "file": "scripts\\verify_qa_fixes.py",
      "lineno": 138,
      "end_lineno": 173,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Run all demonstrations.",
        "returns": null,
        "raw": "Run all demonstrations."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "lambda_handler",
      "qualname": "lambda_handler",
      "enclosing": [],
      "module": "src.api.app",
      "file": "src\\api\\app.py",
      "lineno": 29,
      "end_lineno": 52,
      "decorators": [
        "app.route('/', methods=['POST'])"
      ],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Entry point for AWS Lambda and ECS.",
        "returns": null,
        "raw": "Entry point for AWS Lambda and ECS.\nAccepts HTTP POST requests with optional parameters."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "health_check",
      "qualname": "health_check",
      "enclosing": [],
      "module": "src.api.app",
      "file": "src\\api\\app.py",
      "lineno": 56,
      "end_lineno": 62,
      "decorators": [
        "app.route('/health', methods=['GET'])"
      ],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Health check endpoint for AWS ECS/Lambda.",
        "returns": null,
        "raw": "Health check endpoint for AWS ECS/Lambda."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_configuration",
      "qualname": "get_configuration",
      "enclosing": [],
      "module": "src.api.app",
      "file": "src\\api\\app.py",
      "lineno": 66,
      "end_lineno": 79,
      "decorators": [
        "app.route('/config', methods=['GET'])"
      ],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Returns current configuration (without secrets).",
        "returns": null,
        "raw": "Returns current configuration (without secrets)."
      }
    },
    {
      "kind": "class",
      "name": "BridgeRule",
      "qualname": "BridgeRule",
      "enclosing": [],
      "module": "src.bridges.catalog",
      "file": "src\\bridges\\catalog.py",
      "lineno": 15,
      "end_lineno": 24,
      "decorators": [
        "dataclass(frozen=True)"
      ],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": null,
        "raw": null
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "load_rules",
      "qualname": "load_rules",
      "enclosing": [],
      "module": "src.bridges.catalog",
      "file": "src\\bridges\\catalog.py",
      "lineno": 27,
      "end_lineno": 153,
      "decorators": [],
      "parameters": [],
      "return_annotation": "List[BridgeRule]",
      "doc": {
        "summary": "Return the initial set of bridge rules distilled from the provided business table.",
        "returns": null,
        "raw": "Return the initial set of bridge rules distilled from the provided business table.\n\nNotes on enrichments:\n- bank_posting_group: Requires joining NAV Bank Accounts + Bank Account Posting Group by Service Provider No.\n- refund_channel: Requires OMS fields to distinguish Retail vs MPL; may use existing flags in RPT_SOI or related.\n- jforce_voucher_only: Consider only payments by voucher when evaluating JForce payouts."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "classify_expired",
      "qualname": "classify_expired",
      "enclosing": [],
      "module": "src.bridges.cat_expired_classifier",
      "file": "src\\bridges\\cat_expired_classifier.py",
      "lineno": 20,
      "end_lineno": 127,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "amount_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "description_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Classify NAV GL entries as Expired voucher transactions.",
        "returns": "DataFrame with 'bridge_category' and 'voucher_type' columns populated\nfor rows matching expired criteria.",
        "raw": "Classify NAV GL entries as Expired voucher transactions.\n\nOnly applies to rows where:\n- Amount is positive\n- Integration_Type is 'Manual'\n- bridge_category is not already set\n- Description contains 'EXPR' pattern\n\nArgs:\n    df: DataFrame containing GL entries with amount, description, and Integration_Type columns.\n    amount_col: Name of the amount column. If None, auto-detects.\n    description_col: Name of the description column. If None, auto-detects.\n\nReturns:\n    DataFrame with 'bridge_category' and 'voucher_type' columns populated\n    for rows matching expired criteria.\n\nExample:\n    >>> df = pd.DataFrame({\n    ...     'Amount': [30.0],\n    ...     'Document Description': ['EXPR_APLGY voucher cleanup'],\n    ...     'Integration_Type': ['Manual']\n    ... })\n    >>> result = classify_expired(df)\n    >>> print(result['bridge_category'].iloc[0])\n    'Expired - Apology'"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "classify_manual_cancellation",
      "qualname": "classify_manual_cancellation",
      "enclosing": [],
      "module": "src.bridges.cat_expired_classifier",
      "file": "src\\bridges\\cat_expired_classifier.py",
      "lineno": 130,
      "end_lineno": 207,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "amount_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "doc_type_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Classify Manual Cancellation transactions via Credit Memo.",
        "returns": "DataFrame with classifications for manual cancellation entries.",
        "raw": "Classify Manual Cancellation transactions via Credit Memo.\n\nOnly applies to rows where:\n- Amount is positive\n- Integration_Type is 'Manual'\n- bridge_category is not already set\n- Document Type is 'Credit Memo'\n\nArgs:\n    df: DataFrame containing GL entries.\n    amount_col: Name of the amount column. If None, auto-detects.\n    doc_type_col: Name of the document type column. If None, auto-detects.\n\nReturns:\n    DataFrame with classifications for manual cancellation entries."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "classify_issuance",
      "qualname": "classify_issuance",
      "enclosing": [],
      "module": "src.bridges.cat_issuance_classifier",
      "file": "src\\bridges\\cat_issuance_classifier.py",
      "lineno": 31,
      "end_lineno": 135,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "amount_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "description_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "doc_no_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Classify NAV GL entries with negative amounts as Issuance transactions.",
        "returns": "DataFrame with 'bridge_category' and 'voucher_type' columns populated\nfor rows matching issuance criteria.",
        "raw": "Classify NAV GL entries with negative amounts as Issuance transactions.\n\nOnly applies to rows where:\n- Amount is negative\n- Integration_Type is already set (from nav_classifier)\n- bridge_category is not already set\n\nArgs:\n    df: DataFrame containing GL entries with amount, description, and Integration_Type columns.\n    amount_col: Name of the amount column. If None, auto-detects.\n    description_col: Name of the description column. If None, auto-detects.\n    doc_no_col: Name of the document number column. If None, auto-detects.\n\nReturns:\n    DataFrame with 'bridge_category' and 'voucher_type' columns populated\n    for rows matching issuance criteria.\n\nExample:\n    >>> df = pd.DataFrame({\n    ...     'Amount': [-100.0],\n    ...     'Document Description': ['Refund voucher'],\n    ...     'Integration_Type': ['Integration']\n    ... })\n    >>> result = classify_issuance(df)\n    >>> print(result['bridge_category'].iloc[0])\n    'Issuance - Refund'"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "classify_integration_type",
      "qualname": "classify_integration_type",
      "enclosing": [],
      "module": "src.bridges.cat_nav_classifier",
      "file": "src\\bridges\\cat_nav_classifier.py",
      "lineno": 18,
      "end_lineno": 76,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "user_id_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Classify NAV GL entries as Manual or Integration based on User ID.",
        "returns": "DataFrame with added 'Integration_Type' column containing either\n'Integration' or 'Manual'.",
        "raw": "Classify NAV GL entries as Manual or Integration based on User ID.\n\nThe integration type is determined by strict matching against the\nspecific user ID 'JUMIA/NAV31AFR.BATCH.SRVC'.\n\nArgs:\n    df: DataFrame containing GL entries with a user ID column.\n    user_id_col: Name of the user ID column. If None, auto-detects from\n                 common column names: 'User ID', 'user_id', 'User_ID', 'userid'\n\nReturns:\n    DataFrame with added 'Integration_Type' column containing either\n    'Integration' or 'Manual'.\n\nExample:\n    >>> df = pd.DataFrame({'User ID': ['JUMIA/NAV31AFR.BATCH.SRVC', 'USER/01']})\n    >>> result = classify_integration_type(df)\n    >>> print(result['Integration_Type'].tolist())\n    ['Integration', 'Manual']"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "is_integration_user",
      "qualname": "is_integration_user",
      "enclosing": [],
      "module": "src.bridges.cat_nav_classifier",
      "file": "src\\bridges\\cat_nav_classifier.py",
      "lineno": 79,
      "end_lineno": 102,
      "decorators": [],
      "parameters": [
        {
          "name": "user_id",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "bool",
      "doc": {
        "summary": "Check if a user ID represents an integration/batch user.",
        "returns": "True if the user ID matches the integration user (JUMIA/NAV31AFR.BATCH.SRVC), False otherwise.",
        "raw": "Check if a user ID represents an integration/batch user.\n\nArgs:\n    user_id: The user ID string to check.\n\nReturns:\n    True if the user ID matches the integration user (JUMIA/NAV31AFR.BATCH.SRVC), False otherwise.\n\nExample:\n    >>> is_integration_user(\"JUMIA/NAV31AFR.BATCH.SRVC\")\n    True\n    >>> is_integration_user(\"JUMIA\\NAV31AFR.BATCH.SRVC\")\n    True\n    >>> is_integration_user(\"USER/01\")\n    False"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "categorize_nav_vouchers",
      "qualname": "categorize_nav_vouchers",
      "enclosing": [],
      "module": "src.bridges.cat_pipeline",
      "file": "src\\bridges\\cat_pipeline.py",
      "lineno": 39,
      "end_lineno": 177,
      "decorators": [],
      "parameters": [
        {
          "name": "cr_03_df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "ipe_08_df",
          "kind": "positional_or_keyword",
          "annotation": "Optional[pd.DataFrame]",
          "default": "None"
        },
        {
          "name": "doc_voucher_usage_df",
          "kind": "positional_or_keyword",
          "annotation": "Optional[pd.DataFrame]",
          "default": "None"
        },
        {
          "name": "gl_account_filter",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "'18412'"
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Main categorization pipeline for NAV GL entries.",
        "returns": "DataFrame with added 'bridge_category', 'voucher_type', and 'Integration_Type' columns",
        "raw": "Main categorization pipeline for NAV GL entries.\n\nApplies all categorization rules in priority order to classify NAV GL entries\n(CR_03) according to the voucher accrual analysis business rules.\n\nCategories produced:\n- 'Issuance - Refund': Voucher issuance for refunds\n- 'Issuance - Apology': Voucher issuance for apologies (COMMERCIAL GESTURE)\n- 'Issuance - JForce': Voucher issuance for JForce (PYT_PF)\n- 'Issuance - Store Credit': Manual voucher issuance (Document No starts with country code)\n- 'Issuance': Generic issuance if no sub-category matches\n- 'Usage': Voucher usage transactions\n- 'Cancellation - Apology': Automated cancellation (Voucher Accrual description)\n- 'Cancellation - Store Credit': Manual cancellation via Credit Memo\n- 'Expired - Apology': Expired apology vouchers (EXPR_APLGY)\n- 'Expired - Refund': Expired refund vouchers (EXPR_JFORCE)\n- 'Expired - Store Credit': Expired store credit vouchers (EXPR_STR CRDT)\n- 'Expired': Generic expired vouchers\n- 'VTC': Voucher to Cash refund transactions\n- None: Transactions that don't match any rule\n\nArgs:\n    cr_03_df: DataFrame containing NAV GL entries with columns like:\n              'Chart of Accounts No_', 'Amount', 'Bal_ Account Type',\n              'User ID', 'Document Description', 'Document Type',\n              'Document No', '[Voucher No_]'\n    ipe_08_df: Optional DataFrame from IPE_08 (Issuance TV) for voucher type lookups.\n               Expected columns: 'id', 'business_use'\n    doc_voucher_usage_df: Optional DataFrame from DOC_VOUCHER_USAGE (Usage TV).\n                          Expected columns: 'id', 'business_use', 'Transaction_No'\n    gl_account_filter: GL account to filter for categorization (default: \"18412\")\n\nReturns:\n    DataFrame with added 'bridge_category', 'voucher_type', and 'Integration_Type' columns\n\nExample:\n    >>> cr_03_df = pd.DataFrame({\n    ...     'Chart of Accounts No_': ['18412', '18412'],\n    ...     'Amount': [-100.0, 50.0],\n    ...     'User ID': ['JUMIA/NAV13AFR.BATCH.SRVC', 'USER/01'],\n    ...     'Document Description': ['Refund voucher', 'Manual RND entry']\n    ... })\n    >>> result = categorize_nav_vouchers(cr_03_df)\n    >>> print(result[['bridge_category', 'voucher_type']].to_dict())"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_categorization_summary",
      "qualname": "get_categorization_summary",
      "enclosing": [],
      "module": "src.bridges.cat_pipeline",
      "file": "src\\bridges\\cat_pipeline.py",
      "lineno": 248,
      "end_lineno": 299,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "dict",
      "doc": {
        "summary": "Generate a summary of categorization results.",
        "returns": "Dictionary with summary statistics:\n{\n'total_rows': int,\n'categorized_rows': int,\n'uncategorized_rows': int,\n'by_category': dict,\n'by_voucher_type': dict,\n'by_integration_type': dict\n}",
        "raw": "Generate a summary of categorization results.\n\nArgs:\n    df: DataFrame with categorization columns.\n\nReturns:\n    Dictionary with summary statistics:\n    {\n        'total_rows': int,\n        'categorized_rows': int,\n        'uncategorized_rows': int,\n        'by_category': dict,\n        'by_voucher_type': dict,\n        'by_integration_type': dict\n    }"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "classify_usage",
      "qualname": "classify_usage",
      "enclosing": [],
      "module": "src.bridges.cat_usage_classifier",
      "file": "src\\bridges\\cat_usage_classifier.py",
      "lineno": 19,
      "end_lineno": 155,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "amount_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "description_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "ipe_08_df",
          "kind": "positional_or_keyword",
          "annotation": "Optional[pd.DataFrame]",
          "default": "None"
        },
        {
          "name": "doc_voucher_usage_df",
          "kind": "positional_or_keyword",
          "annotation": "Optional[pd.DataFrame]",
          "default": "None"
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Classify NAV GL entries with positive amounts and Integration type as Usage.",
        "returns": "DataFrame with 'bridge_category' and 'voucher_type' columns populated\nfor rows matching usage criteria.",
        "raw": "Classify NAV GL entries with positive amounts and Integration type as Usage.\n\nOnly applies to rows where:\n- Amount is positive\n- Integration_Type is 'Integration'\n- bridge_category is not already set\n\nSpecial case: If description contains \"VOUCHER ACCRUAL\", classify as\n\"Cancellation - Apology\" instead of Usage.\n\nArgs:\n    df: DataFrame containing GL entries with amount, description, and Integration_Type columns.\n    amount_col: Name of the amount column. If None, auto-detects.\n    description_col: Name of the description column. If None, auto-detects.\n    ipe_08_df: Optional DataFrame from IPE_08 for voucher type lookups.\n               Expected columns: 'id', 'business_use'\n    doc_voucher_usage_df: Optional DataFrame for fallback voucher type lookups.\n                          Expected columns: 'id', 'business_use', 'Transaction_No'\n\nReturns:\n    DataFrame with 'bridge_category' and 'voucher_type' columns populated\n    for rows matching usage criteria.\n\nExample:\n    >>> df = pd.DataFrame({\n    ...     'Amount': [100.0],\n    ...     'Document Description': ['Item price credit'],\n    ...     'Integration_Type': ['Integration']\n    ... })\n    >>> result = classify_usage(df)\n    >>> print(result['bridge_category'].iloc[0])\n    'Usage'"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "classify_manual_usage",
      "qualname": "classify_manual_usage",
      "enclosing": [],
      "module": "src.bridges.cat_usage_classifier",
      "file": "src\\bridges\\cat_usage_classifier.py",
      "lineno": 158,
      "end_lineno": 274,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "amount_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "description_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "ipe_08_df",
          "kind": "positional_or_keyword",
          "annotation": "Optional[pd.DataFrame]",
          "default": "None"
        },
        {
          "name": "doc_voucher_usage_df",
          "kind": "positional_or_keyword",
          "annotation": "Optional[pd.DataFrame]",
          "default": "None"
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Classify Manual Usage transactions (Nigeria exception - ITEMPRICECREDIT).",
        "returns": "DataFrame with updated classifications for manual usage entries.",
        "raw": "Classify Manual Usage transactions (Nigeria exception - ITEMPRICECREDIT).\n\nOnly applies to rows where:\n- Amount is positive\n- Integration_Type is 'Manual'\n- bridge_category is not already set\n- Description contains 'ITEMPRICECREDIT'\n\nArgs:\n    df: DataFrame containing GL entries.\n    amount_col: Name of the amount column. If None, auto-detects.\n    description_col: Name of the description column. If None, auto-detects.\n    ipe_08_df: Optional DataFrame for voucher type lookups.\n    doc_voucher_usage_df: Optional DataFrame for fallback voucher type lookups.\n\nReturns:\n    DataFrame with updated classifications for manual usage entries."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "lookup_voucher_type",
      "qualname": "lookup_voucher_type",
      "enclosing": [],
      "module": "src.bridges.cat_usage_classifier",
      "file": "src\\bridges\\cat_usage_classifier.py",
      "lineno": 315,
      "end_lineno": 397,
      "decorators": [],
      "parameters": [
        {
          "name": "voucher_no",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "doc_no",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "ipe_08_df",
          "kind": "positional_or_keyword",
          "annotation": "Optional[pd.DataFrame]",
          "default": null
        },
        {
          "name": "doc_voucher_usage_df",
          "kind": "positional_or_keyword",
          "annotation": "Optional[pd.DataFrame]",
          "default": null
        }
      ],
      "return_annotation": "Optional[str]",
      "doc": {
        "summary": "Lookup voucher type from IPE_08 or doc_voucher_usage_df with robust fallback strategy.",
        "returns": "The voucher type (business_use) if found, None otherwise",
        "raw": "Lookup voucher type from IPE_08 or doc_voucher_usage_df with robust fallback strategy.\n\nStrategy:\n1. Primary Lookup: Match NAV Voucher No to TV File 'id' column\n   - Try IPE_08 first (Issuance data)\n   - Then try doc_voucher_usage_df (Usage data)\n2. Secondary Lookup (Fallback): If Voucher No is missing or no match found:\n   - Match NAV Document No to TV File 'Transaction_No' column\n   - Retrieve business_use (Voucher Type) from matching record\n\nThis handles the Nigeria Integration Issue where descriptions like ITEMPRICECREDIT\nappear without a voucher ID but have a transaction number.\n\nArgs:\n    voucher_no: The voucher number from NAV ([Voucher No_])\n    doc_no: The document number from NAV (Document No)\n    ipe_08_df: IPE_08 DataFrame with 'id' and 'business_use' columns\n    doc_voucher_usage_df: Usage TV DataFrame with 'id', 'business_use', 'Transaction_No' columns\n\nReturns:\n    The voucher type (business_use) if found, None otherwise\n\nExamples:\n    >>> # Primary lookup by voucher_no\n    >>> lookup_voucher_type(\"V12345\", \"DOC-001\", ipe_08_df, usage_df)\n    'refund'\n    \n    >>> # Fallback to doc_no when voucher_no is missing\n    >>> lookup_voucher_type(\"\", \"TRX-67890\", ipe_08_df, usage_df)\n    'store_credit'"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "classify_vtc",
      "qualname": "classify_vtc",
      "enclosing": [],
      "module": "src.bridges.cat_vtc_classifier",
      "file": "src\\bridges\\cat_vtc_classifier.py",
      "lineno": 19,
      "end_lineno": 153,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "amount_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "description_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "bal_account_type_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "comment_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Classify NAV GL entries as VTC (Voucher to Cash) transactions.",
        "returns": "DataFrame with 'bridge_category' and 'voucher_type' columns populated\nfor rows matching VTC criteria.",
        "raw": "Classify NAV GL entries as VTC (Voucher to Cash) transactions.\n\nVTC transactions represent voucher refunds paid to customers via bank transfer.\nThis classifier handles both Bank Account-based VTC (highest priority) and\npattern-based VTC (MANUAL RND, PYT_/GTB).\n\nArgs:\n    df: DataFrame containing GL entries with amount, description, and Integration_Type columns.\n    amount_col: Name of the amount column. If None, auto-detects.\n    description_col: Name of the description column. If None, auto-detects.\n    bal_account_type_col: Name of the balancing account type column. If None, auto-detects.\n    comment_col: Name of the comment column. If None, auto-detects.\n\nReturns:\n    DataFrame with 'bridge_category' and 'voucher_type' columns populated\n    for rows matching VTC criteria.\n\nExample:\n    >>> df = pd.DataFrame({\n    ...     'Amount': [-100.0],\n    ...     'Bal_ Account Type': ['Bank Account'],\n    ...     'Integration_Type': ['Manual']\n    ... })\n    >>> result = classify_vtc(df)\n    >>> print(result['bridge_category'].iloc[0])\n    'VTC'"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "classify_vtc_bank_account",
      "qualname": "classify_vtc_bank_account",
      "enclosing": [],
      "module": "src.bridges.cat_vtc_classifier",
      "file": "src\\bridges\\cat_vtc_classifier.py",
      "lineno": 156,
      "end_lineno": 232,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "amount_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "bal_account_type_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Classify VTC transactions based on Bank Account balancing type.",
        "returns": "DataFrame with VTC classifications for Bank Account entries.",
        "raw": "Classify VTC transactions based on Bank Account balancing type.\n\nThis is a specialized version that only checks the Bank Account pattern.\nShould be called with highest priority in the categorization pipeline.\n\nBusiness Rule:\n- Manual user\n- Positive amount (> 0)\n- Balancing Account Type = \"Bank Account\"\n\nArgs:\n    df: DataFrame containing GL entries.\n    amount_col: Name of the amount column. If None, auto-detects.\n    bal_account_type_col: Name of the balancing account type column. If None, auto-detects.\n\nReturns:\n    DataFrame with VTC classifications for Bank Account entries."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "classify_vtc_pattern",
      "qualname": "classify_vtc_pattern",
      "enclosing": [],
      "module": "src.bridges.cat_vtc_classifier",
      "file": "src\\bridges\\cat_vtc_classifier.py",
      "lineno": 235,
      "end_lineno": 331,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "amount_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "description_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "comment_col",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Classify VTC transactions based on description/comment patterns.",
        "returns": "DataFrame with VTC classifications for pattern-based entries.",
        "raw": "Classify VTC transactions based on description/comment patterns.\n\nThis handles:\n- MANUAL RND pattern\n- PYT_ with GTB in comment\n\nArgs:\n    df: DataFrame containing GL entries.\n    amount_col: Name of the amount column. If None, auto-detects.\n    description_col: Name of the description column. If None, auto-detects.\n    comment_col: Name of the comment column. If None, auto-detects.\n\nReturns:\n    DataFrame with VTC classifications for pattern-based entries."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "classify_bridges",
      "qualname": "classify_bridges",
      "enclosing": [],
      "module": "src.bridges.classifier",
      "file": "src\\bridges\\classifier.py",
      "lineno": 47,
      "end_lineno": 82,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "rules",
          "kind": "positional_or_keyword",
          "annotation": "List[BridgeRule]",
          "default": null
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Return a copy of df with added classification columns:",
        "returns": null,
        "raw": "Return a copy of df with added classification columns:\n- bridge_key\n- bridge_title\n- dr_gl_accounts (comma string)\n- cr_gl_accounts (comma string)\n- required_enrichments (comma string)\n\nIf multiple rules match, the first in the list wins (order defines priority)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "calculate_customer_posting_group_bridge",
      "qualname": "calculate_customer_posting_group_bridge",
      "enclosing": [],
      "module": "src.bridges.classifier",
      "file": "src\\bridges\\classifier.py",
      "lineno": 85,
      "end_lineno": 143,
      "decorators": [],
      "parameters": [
        {
          "name": "ipe_07_df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "tuple[float, pd.DataFrame]",
      "doc": {
        "summary": "Identify customers with multiple posting groups for manual review.",
        "returns": "tuple: (bridge_amount, proof_df)\n- bridge_amount: Always 0 (this is an identification task, not a calculation)\n- proof_df: DataFrame with customers that have multiple posting groups,\nincluding 'Customer No_', 'Customer Name', and all associated\n'Customer Posting Group' values (comma-separated)",
        "raw": "Identify customers with multiple posting groups for manual review.\n\nThis bridge does not calculate a monetary value but identifies customers\nthat have inconsistent posting group assignments across entries.\n\nArgs:\n    ipe_07_df: DataFrame from IPE_07 extraction containing customer ledger entries\n               Expected columns: 'Customer No_', 'Customer Name', 'Customer Posting Group'\n\nReturns:\n    tuple: (bridge_amount, proof_df)\n        - bridge_amount: Always 0 (this is an identification task, not a calculation)\n        - proof_df: DataFrame with customers that have multiple posting groups,\n                   including 'Customer No_', 'Customer Name', and all associated\n                   'Customer Posting Group' values (comma-separated)"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "calculate_vtc_adjustment",
      "qualname": "calculate_vtc_adjustment",
      "enclosing": [],
      "module": "src.bridges.classifier",
      "file": "src\\bridges\\classifier.py",
      "lineno": 146,
      "end_lineno": 329,
      "decorators": [],
      "parameters": [
        {
          "name": "ipe_08_df",
          "kind": "positional_or_keyword",
          "annotation": "Optional[pd.DataFrame]",
          "default": null
        },
        {
          "name": "categorized_cr_03_df",
          "kind": "positional_or_keyword",
          "annotation": "Optional[pd.DataFrame]",
          "default": null
        },
        {
          "name": "fx_converter",
          "kind": "positional_or_keyword",
          "annotation": "Optional['FXConverter']",
          "default": "None"
        },
        {
          "name": "cutoff_date",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "Tuple[float, pd.DataFrame, Dict[str, Any]]",
      "doc": {
        "summary": "Calculate VTC (Voucher to Cash) refund reconciliation adjustment.",
        "returns": "tuple: (adjustment_amount_usd, proof_df, vtc_metrics) where:\n- adjustment_amount_usd: Sum of unmatched voucher amounts in USD\n- proof_df: DataFrame of unmatched vouchers with Amount_USD column\n- vtc_metrics: Dict containing total_count and breakdown_by_type",
        "raw": "Calculate VTC (Voucher to Cash) refund reconciliation adjustment.\n\nThis function identifies \"canceled refund vouchers\" from BOB (IPE_08) that do not\nhave a corresponding cancellation entry in NAV (CR_03).\n\nArgs:\n    ipe_08_df: DataFrame containing voucher liabilities from BOB with columns:\n        - id: Voucher ID\n        - business_use: Business use type\n        - is_valid: Validity status (or Is_Valid)\n        - is_active: Active status (0 for canceled)\n        - inactive_at: Date when voucher became inactive (for date filtering)\n        - remaining_amount: Amount for the voucher\n        - ID_COMPANY: Company code (required if fx_converter is provided)\n    categorized_cr_03_df: DataFrame containing categorized NAV GL entries with columns:\n        - [Voucher No_]: Voucher number from NAV\n        - bridge_category: Category of the entry (e.g., 'Cancellation', 'VTC Manual')\n    fx_converter: Optional FXConverter instance for USD conversion.\n                 If None, returns amounts in local currency.\n    cutoff_date: Optional cutoff date (YYYY-MM-DD format) for filtering by reconciliation month.\n                 If provided, only vouchers where inactive_at falls within the cutoff month\n                 will be included.\n\nReturns:\n    tuple: (adjustment_amount_usd, proof_df, vtc_metrics) where:\n        - adjustment_amount_usd: Sum of unmatched voucher amounts in USD\n        - proof_df: DataFrame of unmatched vouchers with Amount_USD column\n        - vtc_metrics: Dict containing total_count and breakdown_by_type"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "calculate_timing_difference_bridge",
      "qualname": "calculate_timing_difference_bridge",
      "enclosing": [],
      "module": "src.bridges.classifier",
      "file": "src\\bridges\\classifier.py",
      "lineno": 747,
      "end_lineno": 946,
      "decorators": [],
      "parameters": [
        {
          "name": "jdash_df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "ipe_08_df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "cutoff_date",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "Tuple[float, pd.DataFrame]",
      "doc": {
        "summary": "Calculates the Timing Difference Bridge by comparing Ordered Amount (Jdash)",
        "returns": "tuple: (variance_sum, proof_df) where:\n- variance_sum: Sum of variance (Jdash Amount Used from Ops - IPE_08 Total Amount Used from Accounting)\n- proof_df: DataFrame with reconciliation details including variance",
        "raw": "Calculates the Timing Difference Bridge by comparing Ordered Amount (Jdash)\nagainst Delivered Amount (IPE_08 - Issuance).\n\nLogic (Validated Manual Process - Finance Team):\nCompares the Ordered Amount (Usage from Ops) from Jdash export against \nthe Total Amount Used (Usage from Accounting) from the Issuance IPE to \nidentify timing differences (pending/timing difference).\n\nBusiness Rules:\n1. Filter Source A (IPE_08 - Issuance):\n   - Filter vouchers created within 1 year before cutoff_date\n   - Filter for is_active == 0 (Inactive)\n   - Filter for business_use in NON_MARKETING_USES\n2. Prepare Source B (Jdash):\n   - Aggregate by Voucher Id summing Amount Used (Ops)\n3. Reconciliation Logic:\n   - Left Join of Filtered IPE_08 (Left) with Jdash (Right) on Voucher ID\n   - Fill missing Jdash amounts with 0\n4. Calculate Variance:\n   - Variance = Jdash['Amount Used'] - IPE_08['Total Amount Used']\n   - (Ordered Amount from Ops - Usage Amount from Accounting = Pending/Timing Difference)\n   - IMPORTANT: Use \"Total Amount Used\" NOT \"Remaining Amount\" or \"Discount Amount\"\n\nArgs:\n    jdash_df: DataFrame from Jdash export with columns:\n        - Voucher Id: Voucher identifier\n        - Amount Used: Amount ordered/used from Ops\n    ipe_08_df: DataFrame from IPE_08 (Issuance) with columns:\n        - id: Voucher ID\n        - business_use: Business use type\n        - is_active: Active status (0 for inactive)\n        - Total Amount Used (or usage_tv): Usage amount from Accounting (NOT Remaining Amount)\n        - created_at: Creation date of voucher\n    cutoff_date: Reconciliation cutoff date (YYYY-MM-DD)\n\nReturns:\n    tuple: (variance_sum, proof_df) where:\n        - variance_sum: Sum of variance (Jdash Amount Used from Ops - IPE_08 Total Amount Used from Accounting)\n        - proof_df: DataFrame with reconciliation details including variance"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "parse_args",
      "qualname": "parse_args",
      "enclosing": [],
      "module": "src.bridges.timing_difference",
      "file": "src\\bridges\\timing_difference.py",
      "lineno": 22,
      "end_lineno": 45,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "load_data",
      "qualname": "load_data",
      "enclosing": [],
      "module": "src.bridges.timing_difference",
      "file": "src\\bridges\\timing_difference.py",
      "lineno": 49,
      "end_lineno": 95,
      "decorators": [],
      "parameters": [
        {
          "name": "xlsx_path",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "issued_sheet",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "usage_sheet",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "issued_header",
          "kind": "positional_or_keyword",
          "annotation": "int | None",
          "default": null
        },
        {
          "name": "usage_header",
          "kind": "positional_or_keyword",
          "annotation": "int | None",
          "default": null
        },
        {
          "name": "expiration_sheet",
          "kind": "positional_or_keyword",
          "annotation": "str | None",
          "default": null
        },
        {
          "name": "expiration_header",
          "kind": "positional_or_keyword",
          "annotation": "int | None",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Loads data from the specified Excel worksheets.",
        "returns": null,
        "raw": "Loads data from the specified Excel worksheets."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "prepare_data",
      "qualname": "prepare_data",
      "enclosing": [],
      "module": "src.bridges.timing_difference",
      "file": "src\\bridges\\timing_difference.py",
      "lineno": 99,
      "end_lineno": 149,
      "decorators": [],
      "parameters": [
        {
          "name": "issued_df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "usage_df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "expiration_df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame | None",
          "default": null
        },
        {
          "name": "order_date_col",
          "kind": "kwonly",
          "annotation": "str",
          "default": null
        },
        {
          "name": "delivery_date_col",
          "kind": "kwonly",
          "annotation": "str",
          "default": null
        },
        {
          "name": "cancellation_date_col",
          "kind": "kwonly",
          "annotation": "str",
          "default": null
        },
        {
          "name": "voucher_id_col",
          "kind": "kwonly",
          "annotation": "str",
          "default": null
        },
        {
          "name": "order_id_col",
          "kind": "kwonly",
          "annotation": "str",
          "default": null
        },
        {
          "name": "inactive_date_col",
          "kind": "kwonly",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Cleans and prepares the dataframes for analysis.",
        "returns": null,
        "raw": "Cleans and prepares the dataframes for analysis."
      }
    },
    {
      "kind": "nested_function",
      "async": false,
      "name": "parse_txn_date",
      "qualname": "prepare_data.parse_txn_date",
      "enclosing": [
        "prepare_data"
      ],
      "module": "src.bridges.timing_difference",
      "file": "src\\bridges\\timing_difference.py",
      "lineno": 119,
      "end_lineno": 128,
      "decorators": [],
      "parameters": [
        {
          "name": "val",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "find_timing_difference_vouchers",
      "qualname": "find_timing_difference_vouchers",
      "enclosing": [],
      "module": "src.bridges.timing_difference",
      "file": "src\\bridges\\timing_difference.py",
      "lineno": 153,
      "end_lineno": 189,
      "decorators": [],
      "parameters": [
        {
          "name": "issued_df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "usage_df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "country_col",
          "kind": "kwonly",
          "annotation": "str",
          "default": null
        },
        {
          "name": "business_use_col",
          "kind": "kwonly",
          "annotation": "str",
          "default": null
        },
        {
          "name": "voucher_id_col",
          "kind": "kwonly",
          "annotation": "str",
          "default": null
        },
        {
          "name": "country_filter",
          "kind": "kwonly",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Identifies vouchers that represent a timing difference.",
        "returns": null,
        "raw": "Identifies vouchers that represent a timing difference."
      }
    },
    {
      "kind": "nested_function",
      "async": false,
      "name": "is_country_match",
      "qualname": "find_timing_difference_vouchers.is_country_match",
      "enclosing": [
        "find_timing_difference_vouchers"
      ],
      "module": "src.bridges.timing_difference",
      "file": "src\\bridges\\timing_difference.py",
      "lineno": 162,
      "end_lineno": 164,
      "decorators": [],
      "parameters": [
        {
          "name": "val",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "output_results",
      "qualname": "output_results",
      "enclosing": [],
      "module": "src.bridges.timing_difference",
      "file": "src\\bridges\\timing_difference.py",
      "lineno": 193,
      "end_lineno": 205,
      "decorators": [],
      "parameters": [
        {
          "name": "timing_difference_vouchers",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "output_path",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "voucher_id_col",
          "kind": "kwonly",
          "annotation": "str",
          "default": null
        },
        {
          "name": "order_id_col",
          "kind": "kwonly",
          "annotation": "str",
          "default": null
        },
        {
          "name": "amount_col",
          "kind": "kwonly",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Saves the results to a CSV file.",
        "returns": null,
        "raw": "Saves the results to a CSV file."
      }
    },
    {
      "kind": "class",
      "name": "DFProbe",
      "qualname": "DFProbe",
      "enclosing": [],
      "module": "src.core.debug_probe",
      "file": "src\\core\\debug_probe.py",
      "lineno": 37,
      "end_lineno": 62,
      "decorators": [
        "dataclass"
      ],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Dataclass representing DataFrame probe statistics.",
        "raw": "Dataclass representing DataFrame probe statistics.\n\nAttributes:\n    name: Name/identifier for this probe point\n    rows: Number of rows in the DataFrame\n    cols: Number of columns in the DataFrame\n    nulls_total: Total null values across all columns\n    duplicated_rows: Number of duplicated rows\n    amount_sum: Sum of amount column (if specified)\n    amount_col: Name of the amount column (if specified)\n    min_date: Minimum date value (if date_col specified)\n    max_date: Maximum date value (if date_col specified)\n    unique_keys: Dictionary of unique value counts for key columns"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "probe_df",
      "qualname": "probe_df",
      "enclosing": [],
      "module": "src.core.debug_probe",
      "file": "src\\core\\debug_probe.py",
      "lineno": 65,
      "end_lineno": 276,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "out_dir",
          "kind": "positional_or_keyword",
          "annotation": "str | Path",
          "default": null
        },
        {
          "name": "amount_col",
          "kind": "kwonly",
          "annotation": "str | None",
          "default": "None"
        },
        {
          "name": "date_col",
          "kind": "kwonly",
          "annotation": "str | None",
          "default": "None"
        },
        {
          "name": "key_cols",
          "kind": "kwonly",
          "annotation": "list[str] | None",
          "default": "None"
        },
        {
          "name": "snapshot",
          "kind": "kwonly",
          "annotation": "bool",
          "default": "False"
        },
        {
          "name": "snapshot_cols",
          "kind": "kwonly",
          "annotation": "list[str] | None",
          "default": "None"
        },
        {
          "name": "snapshot_max_rows",
          "kind": "kwonly",
          "annotation": "int",
          "default": "10000"
        }
      ],
      "return_annotation": "DFProbe",
      "doc": {
        "summary": "Probe a DataFrame and collect statistics for pipeline instrumentation.",
        "returns": "DFProbe: A dataclass containing all collected statistics",
        "raw": "Probe a DataFrame and collect statistics for pipeline instrumentation.\n\nThis function collects comprehensive statistics about a DataFrame at a specific\npoint in the pipeline, logs them to a file, and optionally saves a CSV snapshot.\n\nArgs:\n    df: The DataFrame to probe\n    name: Identifier for this probe point (e.g., \"after_merge\", \"final_output\")\n    out_dir: Directory path where logs and snapshots will be saved\n    amount_col: Optional column name for amount/value summation\n    date_col: Optional column name for date range calculation\n    key_cols: Optional list of column names to count unique values\n    snapshot: If True, save a CSV snapshot of the DataFrame\n    snapshot_cols: Optional list of columns to include in snapshot (None = all)\n    snapshot_max_rows: Maximum number of rows to save in snapshot (default: 10000)\n    \nReturns:\n    DFProbe: A dataclass containing all collected statistics\n\nNotes:\n    If any of ``amount_col``, ``date_col``, ``key_cols``, or ``snapshot_cols``\n    refer to columns that are not present in ``df``, those metrics are skipped\n    and a warning is logged. No exception is raised for missing columns.\nExample:\n    >>> import pandas as pd\n    >>> from src.core.debug_probe import probe_df\n    >>> df = pd.DataFrame({\"id\": [1, 2, 3], \"amount\": [100, 200, 300]})\n    >>> probe = probe_df(df, \"test\", \"/tmp/probes\", amount_col=\"amount\")\n    >>> probe.amount_sum\n    600.0"
      }
    },
    {
      "kind": "nested_function",
      "async": false,
      "name": "sanitize_for_json",
      "qualname": "probe_df.sanitize_for_json",
      "enclosing": [
        "probe_df"
      ],
      "module": "src.core.debug_probe",
      "file": "src\\core\\debug_probe.py",
      "lineno": 211,
      "end_lineno": 227,
      "decorators": [],
      "parameters": [
        {
          "name": "obj",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Convert NaN, Infinity, and Decimal values for JSON serialization.",
        "returns": null,
        "raw": "Convert NaN, Infinity, and Decimal values for JSON serialization.\n\n- NaN, Infinity, -Infinity -> None\n- Decimal -> float"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_latest_evidence_zip",
      "qualname": "get_latest_evidence_zip",
      "enclosing": [],
      "module": "src.core.evidence_locator",
      "file": "src\\core\\evidence_locator.py",
      "lineno": 15,
      "end_lineno": 62,
      "decorators": [],
      "parameters": [
        {
          "name": "item_id",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "evidence_root",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "Optional[str]",
      "doc": {
        "summary": "Finds the most recent ZIP evidence package generated for a given IPE item.",
        "returns": "Full path to the most recent ZIP file, or None if no evidence found.",
        "raw": "Finds the most recent ZIP evidence package generated for a given IPE item.\n\nThis function searches the evidence directory for folders matching the item_id\npattern and returns the path to the most recently created ZIP file.\n\nArgs:\n    item_id: The IPE or CR identifier (e.g., 'IPE_07', 'CR_03')\n    evidence_root: Optional path to the evidence directory. If None, \n                   defaults to 'evidence/' relative to repository root.\n\nReturns:\n    Full path to the most recent ZIP file, or None if no evidence found.\n\nExample:\n    >>> zip_path = get_latest_evidence_zip('IPE_07')\n    >>> if zip_path:\n    ...     print(f\"Found evidence: {zip_path}\")"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "find_evidence_packages",
      "qualname": "find_evidence_packages",
      "enclosing": [],
      "module": "src.core.evidence_locator",
      "file": "src\\core\\evidence_locator.py",
      "lineno": 65,
      "end_lineno": 93,
      "decorators": [],
      "parameters": [
        {
          "name": "item_id",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "evidence_root",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "list",
      "doc": {
        "summary": "Find all evidence packages for a given IPE item.",
        "returns": "List of tuples (modification_time, zip_path) sorted by time descending.",
        "raw": "Find all evidence packages for a given IPE item.\n\nArgs:\n    item_id: The IPE or CR identifier (e.g., 'IPE_07', 'CR_03')\n    evidence_root: Optional path to the evidence directory.\n\nReturns:\n    List of tuples (modification_time, zip_path) sorted by time descending."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "__init__",
      "qualname": "ExtractionPipeline.__init__",
      "enclosing": [
        "ExtractionPipeline"
      ],
      "module": "src.core.extraction_pipeline",
      "file": "src\\core\\extraction_pipeline.py",
      "lineno": 47,
      "end_lineno": 84,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "params",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        },
        {
          "name": "country_code",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "period_str",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Initialize the extraction pipeline.",
        "returns": null,
        "raw": "Initialize the extraction pipeline.\n\nArgs:\n    params: Dictionary of SQL parameters including 'cutoff_date', \n            'id_companies_active', etc.\n    country_code: Optional country code. If not provided, extracted from params.\n    period_str: Optional period string (YYYYMM). If not provided, derived from cutoff_date."
      }
    },
    {
      "kind": "method",
      "async": true,
      "name": "run_extraction_with_evidence",
      "qualname": "ExtractionPipeline.run_extraction_with_evidence",
      "enclosing": [
        "ExtractionPipeline"
      ],
      "module": "src.core.extraction_pipeline",
      "file": "src\\core\\extraction_pipeline.py",
      "lineno": 86,
      "end_lineno": 151,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "item_id",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "Tuple[pd.DataFrame, Optional[str]]",
      "doc": {
        "summary": "Executes extraction via IPERunner.run() with evidence generation.",
        "returns": "Tuple of (DataFrame, zip_path) where:\n- DataFrame: Extracted data (or empty DataFrame on failure)\n- zip_path: Path to evidence ZIP (or None if not generated)",
        "raw": "Executes extraction via IPERunner.run() with evidence generation.\n\nIncludes a CRITICAL PATCH for CR_05 to handle column names with '?' characters.\n\nArgs:\n    item_id: The IPE or CR identifier (e.g., 'IPE_07', 'CR_05')\n\nReturns:\n    Tuple of (DataFrame, zip_path) where:\n        - DataFrame: Extracted data (or empty DataFrame on failure)\n        - zip_path: Path to evidence ZIP (or None if not generated)"
      }
    },
    {
      "kind": "nested_function",
      "async": false,
      "name": "patched_exec",
      "qualname": "ExtractionPipeline.run_extraction_with_evidence.patched_exec",
      "enclosing": [
        "ExtractionPipeline",
        "run_extraction_with_evidence"
      ],
      "module": "src.core.extraction_pipeline",
      "file": "src\\core\\extraction_pipeline.py",
      "lineno": 138,
      "end_lineno": 139,
      "decorators": [],
      "parameters": [
        {
          "name": "query",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "params",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "None"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "filter_by_country",
      "qualname": "ExtractionPipeline.filter_by_country",
      "enclosing": [
        "ExtractionPipeline"
      ],
      "module": "src.core.extraction_pipeline",
      "file": "src\\core\\extraction_pipeline.py",
      "lineno": 191,
      "end_lineno": 211,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Filter DataFrame by country code.",
        "returns": "Filtered DataFrame (or original if no country column found)",
        "raw": "Filter DataFrame by country code.\n\nLooks for common country column names and filters accordingly.\n\nArgs:\n    df: DataFrame to filter\n\nReturns:\n    Filtered DataFrame (or original if no country column found)"
      }
    },
    {
      "kind": "class",
      "name": "ExtractionPipeline",
      "qualname": "ExtractionPipeline",
      "enclosing": [],
      "module": "src.core.extraction_pipeline",
      "file": "src\\core\\extraction_pipeline.py",
      "lineno": 30,
      "end_lineno": 211,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Orchestrates IPE data extraction with evidence generation.",
        "raw": "Orchestrates IPE data extraction with evidence generation.\n\nThis class provides a unified interface for extracting data from various\nIPE sources, with support for:\n- Live database extraction via IPERunner\n- Fixture fallback for development/testing\n- Evidence package generation\n- CR_05 column name patching\n\nAttributes:\n    params: Dictionary of SQL parameters for extractions\n    country_code: Country code (e.g., 'JD_GH', 'EC_NG')\n    period_str: Period string in YYYYMM format"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": true,
      "name": "run_extraction_with_evidence",
      "qualname": "run_extraction_with_evidence",
      "enclosing": [],
      "module": "src.core.extraction_pipeline",
      "file": "src\\core\\extraction_pipeline.py",
      "lineno": 214,
      "end_lineno": 236,
      "decorators": [],
      "parameters": [
        {
          "name": "item_id",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "params",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        },
        {
          "name": "country_code",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "period_str",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "Tuple[pd.DataFrame, Optional[str]]",
      "doc": {
        "summary": "Standalone function for backward compatibility.",
        "returns": "Tuple of (DataFrame, zip_path)",
        "raw": "Standalone function for backward compatibility.\n\nExecutes extraction via IPERunner.run() ensuring Rich Metadata & Evidence Generation.\nIncludes CRITICAL PATCH for CR_05 (handling columns with '?').\n\nArgs:\n    item_id: The IPE or CR identifier\n    params: SQL parameters dictionary\n    country_code: Country code (e.g., 'JD_GH')\n    period_str: Period in YYYYMM format\n\nReturns:\n    Tuple of (DataFrame, zip_path)"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "load_all_data",
      "qualname": "load_all_data",
      "enclosing": [],
      "module": "src.core.extraction_pipeline",
      "file": "src\\core\\extraction_pipeline.py",
      "lineno": 239,
      "end_lineno": 368,
      "decorators": [],
      "parameters": [
        {
          "name": "params",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        },
        {
          "name": "uploaded_files",
          "kind": "positional_or_keyword",
          "annotation": "Optional[Dict[str, Any]]",
          "default": "None"
        },
        {
          "name": "required_ipes",
          "kind": "positional_or_keyword",
          "annotation": "Optional[list]",
          "default": "None"
        },
        {
          "name": "progress_callback",
          "kind": "positional_or_keyword",
          "annotation": "Optional[callable]",
          "default": "None"
        }
      ],
      "return_annotation": "Tuple[Dict[str, pd.DataFrame], Dict[str, Optional[str]], Dict[str, str]]",
      "doc": {
        "summary": "Orchestrates loading and evidence collection for multiple IPEs.",
        "returns": "Tuple of (data_store, evidence_store, source_store) where:\n- data_store: Dict mapping item_id to DataFrame\n- evidence_store: Dict mapping item_id to ZIP path (or None)\n- source_store: Dict mapping item_id to source type\n(\"Uploaded File\", \"Live Database\", \"Local Fixture\", \"No Data\")",
        "raw": "Orchestrates loading and evidence collection for multiple IPEs.\n\nThis is the main entry point for loading all required data for a reconciliation.\nIt supports manual file uploads, live database extraction, and fixture fallbacks.\n\nArgs:\n    params: SQL parameters dictionary including:\n        - cutoff_date: Cutoff date in YYYY-MM-DD format\n        - id_companies_active: Company filter in SQL format\n        - Other SQL parameters\n    uploaded_files: Optional dictionary of {item_id: file_path_or_object} \n                    for manual CSV overrides\n    required_ipes: Optional list of IPE IDs to load. Defaults to standard set.\n    progress_callback: Optional callback function(item_id, progress_pct, message)\n                       for progress reporting\n\nReturns:\n    Tuple of (data_store, evidence_store, source_store) where:\n        - data_store: Dict mapping item_id to DataFrame\n        - evidence_store: Dict mapping item_id to ZIP path (or None)\n        - source_store: Dict mapping item_id to source type \n                       (\"Uploaded File\", \"Live Database\", \"Local Fixture\", \"No Data\")"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "load_jdash_data",
      "qualname": "load_jdash_data",
      "enclosing": [],
      "module": "src.core.jdash_loader",
      "file": "src\\core\\jdash_loader.py",
      "lineno": 20,
      "end_lineno": 97,
      "decorators": [],
      "parameters": [
        {
          "name": "source",
          "kind": "positional_or_keyword",
          "annotation": "Optional[Union[str, Any]]",
          "default": "None"
        },
        {
          "name": "fixture_fallback",
          "kind": "positional_or_keyword",
          "annotation": "bool",
          "default": "True"
        },
        {
          "name": "company",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "Tuple[pd.DataFrame, str]",
      "doc": {
        "summary": "Load and normalize JDASH (voucher usage) data.",
        "returns": "Tuple of (DataFrame, source_description) where:\n- DataFrame: Normalized JDASH data with columns 'Voucher Id' and 'Amount Used'\n- source_description: String describing the data source",
        "raw": "Load and normalize JDASH (voucher usage) data.\n\nSupports multiple input types:\n- File path (string)\n- File-like object (with read method)\n- DataFrame (passed through)\n- None (uses fixture fallback if enabled)\n\nSupports company-specific subfolders with fallback to root fixtures:\n1. First tries: tests/fixtures/{company}/fixture_JDASH.csv\n2. Then tries: tests/fixtures/fixture_JDASH.csv (shared/reference files)\n\nArgs:\n    source: Data source - can be file path, file-like object, DataFrame, or None\n    fixture_fallback: If True, falls back to local fixture when source is None\n    company: Optional company code (e.g., 'EC_NG', 'JD_GH') for company-specific fixtures\n\nReturns:\n    Tuple of (DataFrame, source_description) where:\n        - DataFrame: Normalized JDASH data with columns 'Voucher Id' and 'Amount Used'\n        - source_description: String describing the data source\n\nExample:\n    >>> df, source = load_jdash_data(\"/path/to/jdash.csv\")\n    >>> print(f\"Loaded {len(df)} rows from {source}\")\n    >>> # Load company-specific fixture\n    >>> df, source = load_jdash_data(company=\"EC_NG\")"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "aggregate_jdash_by_voucher",
      "qualname": "aggregate_jdash_by_voucher",
      "enclosing": [],
      "module": "src.core.jdash_loader",
      "file": "src\\core\\jdash_loader.py",
      "lineno": 140,
      "end_lineno": 167,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Aggregate JDASH data by Voucher Id.",
        "returns": "Aggregated DataFrame with one row per voucher",
        "raw": "Aggregate JDASH data by Voucher Id.\n\nSums up 'Amount Used' for each unique Voucher Id.\n\nArgs:\n    df: JDASH DataFrame with 'Voucher Id' and 'Amount Used' columns\n\nReturns:\n    Aggregated DataFrame with one row per voucher"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "validate_jdash_data",
      "qualname": "validate_jdash_data",
      "enclosing": [],
      "module": "src.core.jdash_loader",
      "file": "src\\core\\jdash_loader.py",
      "lineno": 170,
      "end_lineno": 240,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "dict",
      "doc": {
        "summary": "Validate JDASH data quality.",
        "returns": "Dictionary with validation results:\n{\n'valid': bool,\n'errors': list of error messages,\n'warnings': list of warning messages,\n'stats': dict with basic statistics\n}",
        "raw": "Validate JDASH data quality.\n\nChecks for:\n- Required columns presence\n- Null values in key columns\n- Duplicate voucher IDs\n- Negative amounts\n\nArgs:\n    df: JDASH DataFrame to validate\n\nReturns:\n    Dictionary with validation results:\n        {\n            'valid': bool,\n            'errors': list of error messages,\n            'warnings': list of warning messages,\n            'stats': dict with basic statistics\n        }"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "add_fields",
      "qualname": "CustomJsonFormatter.add_fields",
      "enclosing": [
        "CustomJsonFormatter"
      ],
      "module": "src.core.logging_config",
      "file": "src\\core\\logging_config.py",
      "lineno": 24,
      "end_lineno": 43,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "log_record",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "record",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "message_dict",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Add custom fields to the log record.",
        "returns": null,
        "raw": "Add custom fields to the log record.\n\nArgs:\n    log_record: Dictionary that will be logged as JSON\n    record: Original LogRecord object\n    message_dict: Dictionary of extra fields"
      }
    },
    {
      "kind": "class",
      "name": "CustomJsonFormatter",
      "qualname": "CustomJsonFormatter",
      "enclosing": [],
      "module": "src.core.logging_config",
      "file": "src\\core\\logging_config.py",
      "lineno": 19,
      "end_lineno": 43,
      "decorators": [],
      "bases": [
        "JsonFormatter"
      ],
      "keywords": [],
      "doc": {
        "summary": "Custom JSON formatter that adds standard fields to all log records.",
        "raw": "Custom JSON formatter that adds standard fields to all log records."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "setup_logging",
      "qualname": "setup_logging",
      "enclosing": [],
      "module": "src.core.logging_config",
      "file": "src\\core\\logging_config.py",
      "lineno": 46,
      "end_lineno": 85,
      "decorators": [],
      "parameters": [
        {
          "name": "level",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "logging.INFO"
        },
        {
          "name": "format_as_json",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "True"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Configure application-wide logging.",
        "returns": null,
        "raw": "Configure application-wide logging.\n\nArgs:\n    level: Logging level (default: INFO)\n    format_as_json: If True, use JSON formatting; if False, use standard formatting"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_logger",
      "qualname": "get_logger",
      "enclosing": [],
      "module": "src.core.logging_config",
      "file": "src\\core\\logging_config.py",
      "lineno": 88,
      "end_lineno": 98,
      "decorators": [],
      "parameters": [
        {
          "name": "name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "logging.Logger",
      "doc": {
        "summary": "Get a logger instance with the specified name.",
        "returns": "Configured logger instance",
        "raw": "Get a logger instance with the specified name.\n\nArgs:\n    name: Logger name (typically __name__)\n    \nReturns:\n    Configured logger instance"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main_workflow_local",
      "qualname": "main_workflow_local",
      "enclosing": [],
      "module": "src.core.main",
      "file": "src\\core\\main.py",
      "lineno": 22,
      "end_lineno": 37,
      "decorators": [],
      "parameters": [
        {
          "name": "cutoff_date",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "None"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Entry point for local execution (development/test).",
        "returns": null,
        "raw": "Entry point for local execution (development/test).\n\nArgs:\n    cutoff_date: Optional cutoff date"
      }
    },
    {
      "kind": "class",
      "name": "WorkflowExecutionError",
      "qualname": "WorkflowExecutionError",
      "enclosing": [],
      "module": "src.core.main",
      "file": "src\\core\\main.py",
      "lineno": 82,
      "end_lineno": 84,
      "decorators": [],
      "bases": [
        "Exception"
      ],
      "keywords": [],
      "doc": {
        "summary": "Exception raised when the global workflow fails.",
        "raw": "Exception raised when the global workflow fails."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "execute_ipe_workflow",
      "qualname": "execute_ipe_workflow",
      "enclosing": [],
      "module": "src.core.main",
      "file": "src\\core\\main.py",
      "lineno": 87,
      "end_lineno": 231,
      "decorators": [],
      "parameters": [
        {
          "name": "cutoff_date",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "None"
        }
      ],
      "return_annotation": "Tuple[Dict[str, Any], int]",
      "doc": {
        "summary": "Executes the complete IPE extraction and validation workflow.",
        "returns": "Tuple containing (results, HTTP_status_code)",
        "raw": "Executes the complete IPE extraction and validation workflow.\n\nArgs:\n    cutoff_date: Optional cutoff date (format YYYY-MM-DD)\n    \nReturns:\n    Tuple containing (results, HTTP_status_code)"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "lambda_handler",
      "qualname": "lambda_handler",
      "enclosing": [],
      "module": "src.core.main",
      "file": "src\\core\\main.py",
      "lineno": 275,
      "end_lineno": 297,
      "decorators": [
        "app.route('/', methods=['POST'])"
      ],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Entry point for AWS Lambda and ECS.",
        "returns": null,
        "raw": "Entry point for AWS Lambda and ECS.\nAccepts HTTP POST requests with optional parameters."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "health_check",
      "qualname": "health_check",
      "enclosing": [],
      "module": "src.core.main",
      "file": "src\\core\\main.py",
      "lineno": 301,
      "end_lineno": 307,
      "decorators": [
        "app.route('/health', methods=['GET'])"
      ],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Health check endpoint for AWS ECS/Lambda.",
        "returns": null,
        "raw": "Health check endpoint for AWS ECS/Lambda."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_configuration",
      "qualname": "get_configuration",
      "enclosing": [],
      "module": "src.core.main",
      "file": "src\\core\\main.py",
      "lineno": 311,
      "end_lineno": 324,
      "decorators": [
        "app.route('/config', methods=['GET'])"
      ],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Returns current configuration (without secrets).",
        "returns": null,
        "raw": "Returns current configuration (without secrets)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main_workflow_local",
      "qualname": "main_workflow_local",
      "enclosing": [],
      "module": "src.core.main",
      "file": "src\\core\\main.py",
      "lineno": 327,
      "end_lineno": 342,
      "decorators": [],
      "parameters": [
        {
          "name": "cutoff_date",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "None"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Entry point for local execution (development/test).",
        "returns": null,
        "raw": "Entry point for local execution (development/test).\n\nArgs:\n    cutoff_date: Optional cutoff date"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "check",
      "qualname": "QualityRule.check",
      "enclosing": [
        "QualityRule"
      ],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 19,
      "end_lineno": 29,
      "decorators": [
        "abstractmethod"
      ],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "tuple[bool, str]",
      "doc": {
        "summary": "Execute the quality check on a DataFrame.",
        "returns": "Tuple of (pass/fail bool, detail message string)",
        "raw": "Execute the quality check on a DataFrame.\n\nArgs:\n    df: The DataFrame to check\n\nReturns:\n    Tuple of (pass/fail bool, detail message string)"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "get_name",
      "qualname": "QualityRule.get_name",
      "enclosing": [
        "QualityRule"
      ],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 32,
      "end_lineno": 34,
      "decorators": [
        "abstractmethod"
      ],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": "Return a human-readable name for this rule.",
        "returns": null,
        "raw": "Return a human-readable name for this rule."
      }
    },
    {
      "kind": "class",
      "name": "QualityRule",
      "qualname": "QualityRule",
      "enclosing": [],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 15,
      "end_lineno": 34,
      "decorators": [
        "dataclass"
      ],
      "bases": [
        "ABC"
      ],
      "keywords": [],
      "doc": {
        "summary": "Base class for data quality rules.",
        "raw": "Base class for data quality rules."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "check",
      "qualname": "RowCountCheck.check",
      "enclosing": [
        "RowCountCheck"
      ],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 43,
      "end_lineno": 53,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "tuple[bool, str]",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "get_name",
      "qualname": "RowCountCheck.get_name",
      "enclosing": [
        "RowCountCheck"
      ],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 55,
      "end_lineno": 56,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "class",
      "name": "RowCountCheck",
      "qualname": "RowCountCheck",
      "enclosing": [],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 38,
      "end_lineno": 56,
      "decorators": [
        "dataclass"
      ],
      "bases": [
        "QualityRule"
      ],
      "keywords": [],
      "doc": {
        "summary": "Check that DataFrame has a row count within specified bounds.",
        "raw": "Check that DataFrame has a row count within specified bounds."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "check",
      "qualname": "ColumnExistsCheck.check",
      "enclosing": [
        "ColumnExistsCheck"
      ],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 64,
      "end_lineno": 75,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "tuple[bool, str]",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "get_name",
      "qualname": "ColumnExistsCheck.get_name",
      "enclosing": [
        "ColumnExistsCheck"
      ],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 77,
      "end_lineno": 78,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "class",
      "name": "ColumnExistsCheck",
      "qualname": "ColumnExistsCheck",
      "enclosing": [],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 60,
      "end_lineno": 78,
      "decorators": [
        "dataclass"
      ],
      "bases": [
        "QualityRule"
      ],
      "keywords": [],
      "doc": {
        "summary": "Check that a specified column exists in the DataFrame.",
        "raw": "Check that a specified column exists in the DataFrame."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "check",
      "qualname": "NumericSumCheck.check",
      "enclosing": [
        "NumericSumCheck"
      ],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 87,
      "end_lineno": 112,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "tuple[bool, str]",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "get_name",
      "qualname": "NumericSumCheck.get_name",
      "enclosing": [
        "NumericSumCheck"
      ],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 114,
      "end_lineno": 115,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "class",
      "name": "NumericSumCheck",
      "qualname": "NumericSumCheck",
      "enclosing": [],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 82,
      "end_lineno": 115,
      "decorators": [
        "dataclass"
      ],
      "bases": [
        "QualityRule"
      ],
      "keywords": [],
      "doc": {
        "summary": "Check that the sum of a numeric column meets a condition.",
        "raw": "Check that the sum of a numeric column meets a condition."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "check",
      "qualname": "NoNullsCheck.check",
      "enclosing": [
        "NoNullsCheck"
      ],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 123,
      "end_lineno": 137,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "tuple[bool, str]",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "get_name",
      "qualname": "NoNullsCheck.get_name",
      "enclosing": [
        "NoNullsCheck"
      ],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 139,
      "end_lineno": 140,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "class",
      "name": "NoNullsCheck",
      "qualname": "NoNullsCheck",
      "enclosing": [],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 119,
      "end_lineno": 140,
      "decorators": [
        "dataclass"
      ],
      "bases": [
        "QualityRule"
      ],
      "keywords": [],
      "doc": {
        "summary": "Check that a column contains no null values.",
        "raw": "Check that a column contains no null values."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "class",
      "name": "QualityReport",
      "qualname": "QualityReport",
      "enclosing": [],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 144,
      "end_lineno": 155,
      "decorators": [
        "dataclass"
      ],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Container for quality check results.",
        "raw": "Container for quality check results."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "run_checks",
      "qualname": "DataQualityEngine.run_checks",
      "enclosing": [
        "DataQualityEngine"
      ],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 161,
      "end_lineno": 185,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "rules",
          "kind": "positional_or_keyword",
          "annotation": "List[QualityRule]",
          "default": null
        }
      ],
      "return_annotation": "QualityReport",
      "doc": {
        "summary": "Run all quality checks on the provided DataFrame.",
        "returns": "QualityReport with overall status and detailed results",
        "raw": "Run all quality checks on the provided DataFrame.\n\nArgs:\n    df: DataFrame to validate\n    rules: List of QualityRule instances to apply\n\nReturns:\n    QualityReport with overall status and detailed results"
      }
    },
    {
      "kind": "class",
      "name": "DataQualityEngine",
      "qualname": "DataQualityEngine",
      "enclosing": [],
      "module": "src.core.quality_checker",
      "file": "src\\core\\quality_checker.py",
      "lineno": 158,
      "end_lineno": 185,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Engine for running data quality checks on DataFrames.",
        "raw": "Engine for running data quality checks on DataFrames."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "filter_ipe08_scope",
      "qualname": "filter_ipe08_scope",
      "enclosing": [],
      "module": "src.core.scope_filtering",
      "file": "src\\core\\scope_filtering.py",
      "lineno": 31,
      "end_lineno": 83,
      "decorators": [],
      "parameters": [
        {
          "name": "ipe_08_df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Filter IPE_08 DataFrame to include only Non-Marketing voucher types.",
        "returns": "DataFrame filtered to Non-Marketing vouchers with dates converted to datetime\n\nExample:\n>>> filtered = filter_ipe08_scope(ipe_08_df)\n>>> print(f\"Filtered from {len(ipe_08_df)} to {len(filtered)} vouchers\")",
        "raw": "Filter IPE_08 DataFrame to include only Non-Marketing voucher types.\n\nThis helper ensures consistent filtering across all bridge calculations\nthat use IPE_08 data. Only vouchers with business_use in the Non-Marketing\ncategory are included.\n\nBusiness Rule:\nNon-Marketing voucher types are: apology_v2, jforce, refund, \nstore_credit, Jpay store_credit\n\nArgs:\n    ipe_08_df: DataFrame from IPE_08 extraction containing voucher data\n               Expected columns: 'business_use' (or 'business_use_formatted')\n               and optional date columns\n\nReturns:\n    DataFrame filtered to Non-Marketing vouchers with dates converted to datetime\n    \nExample:\n    >>> filtered = filter_ipe08_scope(ipe_08_df)\n    >>> print(f\"Filtered from {len(ipe_08_df)} to {len(filtered)} vouchers\")"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "filter_gl_18412",
      "qualname": "filter_gl_18412",
      "enclosing": [],
      "module": "src.core.scope_filtering",
      "file": "src\\core\\scope_filtering.py",
      "lineno": 86,
      "end_lineno": 128,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Filter DataFrame to include only entries for GL account 18412.",
        "returns": "DataFrame filtered to GL 18412 entries only",
        "raw": "Filter DataFrame to include only entries for GL account 18412.\n\nGL 18412 is the voucher accrual account used for voucher liability tracking.\n\nArgs:\n    df: DataFrame with GL account column (various naming conventions supported)\n\nReturns:\n    DataFrame filtered to GL 18412 entries only"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "apply_non_marketing_filter",
      "qualname": "apply_non_marketing_filter",
      "enclosing": [],
      "module": "src.core.scope_filtering",
      "file": "src\\core\\scope_filtering.py",
      "lineno": 131,
      "end_lineno": 170,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "business_use_column",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Apply Non-Marketing filter to any DataFrame with a business_use column.",
        "returns": "Filtered DataFrame containing only Non-Marketing vouchers",
        "raw": "Apply Non-Marketing filter to any DataFrame with a business_use column.\n\nThis is a more flexible version of filter_ipe08_scope that allows\nspecifying the column name.\n\nArgs:\n    df: DataFrame to filter\n    business_use_column: Name of the column containing business use type.\n                        If None, auto-detects common column names.\n\nReturns:\n    Filtered DataFrame containing only Non-Marketing vouchers"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_non_marketing_summary",
      "qualname": "get_non_marketing_summary",
      "enclosing": [],
      "module": "src.core.scope_filtering",
      "file": "src\\core\\scope_filtering.py",
      "lineno": 173,
      "end_lineno": 225,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "dict",
      "doc": {
        "summary": "Get summary statistics for Non-Marketing filtering.",
        "returns": "Dictionary with filtering statistics:\n{\n'total_vouchers': int,\n'non_marketing_count': int,\n'marketing_count': int,\n'breakdown_by_type': dict\n}",
        "raw": "Get summary statistics for Non-Marketing filtering.\n\nArgs:\n    df: DataFrame with business_use column\n\nReturns:\n    Dictionary with filtering statistics:\n        {\n            'total_vouchers': int,\n            'non_marketing_count': int,\n            'marketing_count': int,\n            'breakdown_by_type': dict\n        }"
      }
    },
    {
      "kind": "class",
      "name": "CatalogSource",
      "qualname": "CatalogSource",
      "enclosing": [],
      "module": "src.core.catalog.cpg1",
      "file": "src\\core\\catalog\\cpg1.py",
      "lineno": 25,
      "end_lineno": 30,
      "decorators": [
        "dataclass"
      ],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Represents a single upstream source (table/view/file).",
        "raw": "Represents a single upstream source (table/view/file)."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "class",
      "name": "CatalogItem",
      "qualname": "CatalogItem",
      "enclosing": [],
      "module": "src.core.catalog.cpg1",
      "file": "src\\core\\catalog\\cpg1.py",
      "lineno": 34,
      "end_lineno": 56,
      "decorators": [
        "dataclass"
      ],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Catalog entry describing an IPE/CR/DOC used by C-PG-1.",
        "raw": "Catalog entry describing an IPE/CR/DOC used by C-PG-1."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "list_items",
      "qualname": "list_items",
      "enclosing": [],
      "module": "src.core.catalog.cpg1",
      "file": "src\\core\\catalog\\cpg1.py",
      "lineno": 669,
      "end_lineno": 674,
      "decorators": [],
      "parameters": [
        {
          "name": "item_type",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "List[CatalogItem]",
      "doc": {
        "summary": "List all catalog items, optionally filtered by type (IPE|CR|DOC).",
        "returns": null,
        "raw": "List all catalog items, optionally filtered by type (IPE|CR|DOC)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_item_by_id",
      "qualname": "get_item_by_id",
      "enclosing": [],
      "module": "src.core.catalog.cpg1",
      "file": "src\\core\\catalog\\cpg1.py",
      "lineno": 677,
      "end_lineno": 682,
      "decorators": [],
      "parameters": [
        {
          "name": "item_id",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "Optional[CatalogItem]",
      "doc": {
        "summary": "Retrieve a catalog item by its ID (returns None if not found).",
        "returns": null,
        "raw": "Retrieve a catalog item by its ID (returns None if not found)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "to_dicts",
      "qualname": "to_dicts",
      "enclosing": [],
      "module": "src.core.catalog.cpg1",
      "file": "src\\core\\catalog\\cpg1.py",
      "lineno": 685,
      "end_lineno": 695,
      "decorators": [],
      "parameters": [
        {
          "name": "items",
          "kind": "positional_or_keyword",
          "annotation": "Optional[List[CatalogItem]]",
          "default": "None"
        }
      ],
      "return_annotation": "List[Dict[str, Any]]",
      "doc": {
        "summary": "Serialize catalog items to simple dictionaries (useful for APIs).",
        "returns": null,
        "raw": "Serialize catalog items to simple dictionaries (useful for APIs)."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "__init__",
      "qualname": "DigitalEvidenceManager.__init__",
      "enclosing": [
        "DigitalEvidenceManager"
      ],
      "module": "src.core.evidence.manager",
      "file": "src\\core\\evidence\\manager.py",
      "lineno": 27,
      "end_lineno": 35,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "base_evidence_dir",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "'evidence'"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Initializes the evidence manager.",
        "returns": null,
        "raw": "Initializes the evidence manager.\n\nArgs:\n    base_evidence_dir: Root directory for storing evidence"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "create_evidence_package",
      "qualname": "DigitalEvidenceManager.create_evidence_package",
      "enclosing": [
        "DigitalEvidenceManager"
      ],
      "module": "src.core.evidence.manager",
      "file": "src\\core\\evidence\\manager.py",
      "lineno": 37,
      "end_lineno": 75,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "ipe_id",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "execution_metadata",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        },
        {
          "name": "country",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "period",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": "Creates a timestamped evidence directory for an IPE execution.",
        "returns": "Path to the created evidence directory",
        "raw": "Creates a timestamped evidence directory for an IPE execution.\n\nArgs:\n    ipe_id: IPE identifier\n    execution_metadata: Execution metadata\n    country: Country code (e.g., 'NG', 'KE')\n    period: Period in YYYYMM format (e.g., '202509')\n    \nReturns:\n    Path to the created evidence directory"
      }
    },
    {
      "kind": "class",
      "name": "DigitalEvidenceManager",
      "qualname": "DigitalEvidenceManager",
      "enclosing": [],
      "module": "src.core.evidence.manager",
      "file": "src\\core\\evidence\\manager.py",
      "lineno": 21,
      "end_lineno": 75,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Digital evidence manager for SOX extractions.",
        "raw": "Digital evidence manager for SOX extractions.\nCreates a complete and tamper-proof evidence package for each execution."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "__init__",
      "qualname": "IPEEvidenceGenerator.__init__",
      "enclosing": [
        "IPEEvidenceGenerator"
      ],
      "module": "src.core.evidence.manager",
      "file": "src\\core\\evidence\\manager.py",
      "lineno": 83,
      "end_lineno": 93,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "evidence_dir",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "ipe_id",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Initializes the generator for a specific IPE.",
        "returns": null,
        "raw": "Initializes the generator for a specific IPE.\n\nArgs:\n    evidence_dir: Directory to store evidence\n    ipe_id: IPE identifier"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "save_executed_query",
      "qualname": "IPEEvidenceGenerator.save_executed_query",
      "enclosing": [
        "IPEEvidenceGenerator"
      ],
      "module": "src.core.evidence.manager",
      "file": "src\\core\\evidence\\manager.py",
      "lineno": 95,
      "end_lineno": 124,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "query",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "parameters",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": "None"
        }
      ],
      "return_annotation": "None",
      "doc": {
        "summary": "Saves the exact SQL query executed with its parameters.",
        "returns": null,
        "raw": "Saves the exact SQL query executed with its parameters.\n\nArgs:\n    query: SQL query executed\n    parameters: Parameters used in the query"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "save_data_snapshot",
      "qualname": "IPEEvidenceGenerator.save_data_snapshot",
      "enclosing": [
        "IPEEvidenceGenerator"
      ],
      "module": "src.core.evidence.manager",
      "file": "src\\core\\evidence\\manager.py",
      "lineno": 126,
      "end_lineno": 187,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "dataframe",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "snapshot_rows",
          "kind": "positional_or_keyword",
          "annotation": "int",
          "default": "100"
        }
      ],
      "return_annotation": "None",
      "doc": {
        "summary": "Saves a snapshot of extracted data (programmatic equivalent of a screenshot).",
        "returns": null,
        "raw": "Saves a snapshot of extracted data (programmatic equivalent of a screenshot).\nUses tail (last rows) instead of head for better visibility of recent data.\n\nArgs:\n    dataframe: DataFrame containing extracted data\n    snapshot_rows: Number of rows to include in snapshot"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "generate_integrity_hash",
      "qualname": "IPEEvidenceGenerator.generate_integrity_hash",
      "enclosing": [
        "IPEEvidenceGenerator"
      ],
      "module": "src.core.evidence.manager",
      "file": "src\\core\\evidence\\manager.py",
      "lineno": 189,
      "end_lineno": 245,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "dataframe",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": "Generates a cryptographic hash of the complete dataset.",
        "returns": "SHA-256 hash of the data",
        "raw": "Generates a cryptographic hash of the complete dataset.\nThis hash proves data integrity and detects any tampering.\n\nArgs:\n    dataframe: Complete DataFrame of extracted data\n    \nReturns:\n    SHA-256 hash of the data"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "save_validation_results",
      "qualname": "IPEEvidenceGenerator.save_validation_results",
      "enclosing": [
        "IPEEvidenceGenerator"
      ],
      "module": "src.core.evidence.manager",
      "file": "src\\core\\evidence\\manager.py",
      "lineno": 247,
      "end_lineno": 279,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "validation_results",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        }
      ],
      "return_annotation": "None",
      "doc": {
        "summary": "Saves detailed SOX validation results.",
        "returns": null,
        "raw": "Saves detailed SOX validation results.\n\nArgs:\n    validation_results: Validation test results"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "finalize_evidence_package",
      "qualname": "IPEEvidenceGenerator.finalize_evidence_package",
      "enclosing": [
        "IPEEvidenceGenerator"
      ],
      "module": "src.core.evidence.manager",
      "file": "src\\core\\evidence\\manager.py",
      "lineno": 281,
      "end_lineno": 323,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": "Finalizes the evidence package by saving the execution log",
        "returns": "Path to the created ZIP archive",
        "raw": "Finalizes the evidence package by saving the execution log\nand creating a secure ZIP archive.\n\nReturns:\n    Path to the created ZIP archive"
      }
    },
    {
      "kind": "class",
      "name": "IPEEvidenceGenerator",
      "qualname": "IPEEvidenceGenerator",
      "enclosing": [],
      "module": "src.core.evidence.manager",
      "file": "src\\core\\evidence\\manager.py",
      "lineno": 78,
      "end_lineno": 343,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Evidence generator specific to an IPE execution.",
        "raw": "Evidence generator specific to an IPE execution."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "verify_package_integrity",
      "qualname": "EvidenceValidator.verify_package_integrity",
      "enclosing": [
        "EvidenceValidator"
      ],
      "module": "src.core.evidence.manager",
      "file": "src\\core\\evidence\\manager.py",
      "lineno": 352,
      "end_lineno": 401,
      "decorators": [
        "staticmethod"
      ],
      "parameters": [
        {
          "name": "evidence_dir",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Verifies the integrity of an evidence package.",
        "returns": "Verification results",
        "raw": "Verifies the integrity of an evidence package.\n\nArgs:\n    evidence_dir: Evidence package directory\n    \nReturns:\n    Verification results"
      }
    },
    {
      "kind": "class",
      "name": "EvidenceValidator",
      "qualname": "EvidenceValidator",
      "enclosing": [],
      "module": "src.core.evidence.manager",
      "file": "src\\core\\evidence\\manager.py",
      "lineno": 346,
      "end_lineno": 401,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Validator to verify evidence package integrity.",
        "raw": "Validator to verify evidence package integrity."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "get_component_ipes",
      "qualname": "CPG1ReconciliationConfig.get_component_ipes",
      "enclosing": [
        "CPG1ReconciliationConfig"
      ],
      "module": "src.core.reconciliation.cpg1",
      "file": "src\\core\\reconciliation\\cpg1.py",
      "lineno": 60,
      "end_lineno": 62,
      "decorators": [
        "classmethod"
      ],
      "parameters": [
        {
          "name": "cls",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": "List[str]",
      "doc": {
        "summary": "Return list of IPE IDs that comprise the target values.",
        "returns": null,
        "raw": "Return list of IPE IDs that comprise the target values."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "get_gl_description",
      "qualname": "CPG1ReconciliationConfig.get_gl_description",
      "enclosing": [
        "CPG1ReconciliationConfig"
      ],
      "module": "src.core.reconciliation.cpg1",
      "file": "src\\core\\reconciliation\\cpg1.py",
      "lineno": 65,
      "end_lineno": 67,
      "decorators": [
        "classmethod"
      ],
      "parameters": [
        {
          "name": "cls",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "gl_account",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": "Get human-readable description for a GL account number.",
        "returns": null,
        "raw": "Get human-readable description for a GL account number."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "calculate_variance",
      "qualname": "CPG1ReconciliationConfig.calculate_variance",
      "enclosing": [
        "CPG1ReconciliationConfig"
      ],
      "module": "src.core.reconciliation.cpg1",
      "file": "src\\core\\reconciliation\\cpg1.py",
      "lineno": 70,
      "end_lineno": 86,
      "decorators": [
        "classmethod"
      ],
      "parameters": [
        {
          "name": "cls",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "actuals",
          "kind": "positional_or_keyword",
          "annotation": "float",
          "default": null
        },
        {
          "name": "target_values",
          "kind": "positional_or_keyword",
          "annotation": "float",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Calculate reconciliation variance and determine status.",
        "returns": null,
        "raw": "Calculate reconciliation variance and determine status."
      }
    },
    {
      "kind": "class",
      "name": "CPG1ReconciliationConfig",
      "qualname": "CPG1ReconciliationConfig",
      "enclosing": [],
      "module": "src.core.reconciliation.cpg1",
      "file": "src\\core\\reconciliation\\cpg1.py",
      "lineno": 14,
      "end_lineno": 86,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "C-PG-1 Reconciliation Business Logic",
        "raw": "C-PG-1 Reconciliation Business Logic\n\nThis defines how to calculate the reconciliation:\nACTUALS (CR_04) vs TARGET VALUES (sum of 6 components)"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "run_reconciliation",
      "qualname": "run_reconciliation",
      "enclosing": [],
      "module": "src.core.reconciliation.run_reconciliation",
      "file": "src\\core\\reconciliation\\run_reconciliation.py",
      "lineno": 80,
      "end_lineno": 339,
      "decorators": [],
      "parameters": [
        {
          "name": "params",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Execute a complete SOX reconciliation workflow in headless mode.",
        "returns": "Dictionary containing all reconciliation results:\n{\n'status': str - 'SUCCESS', 'WARNING', or 'ERROR'\n'timestamp': str - ISO timestamp of execution\n'params': dict - Input parameters used\n'dataframes': dict - All DataFrames (as serializable dicts)\n'dataframe_summaries': dict - Row counts and column info\n'evidence_paths': dict - Paths to evidence packages\n'data_sources': dict - Source of each data item\n'quality_reports': dict - Quality check results\n'categorization': dict - Bridge categorization results\n'bridges': dict - Bridge calculation results\n'reconciliation': dict - Overall reconciliation metrics\n'errors': list - Any errors encountered\n'warnings': list - Any warnings generated\n}",
        "raw": "Execute a complete SOX reconciliation workflow in headless mode.\n\nThis function orchestrates the entire reconciliation pipeline:\n1. Extraction - Load data from sources (database or fixtures)\n2. Preprocessing - Apply quality checks and scope filtering\n3. Categorization - Classify NAV GL entries by bridge category\n4. Bridge Analysis - Calculate reconciliation bridges and adjustments\n\nArgs:\n    params: Dictionary containing reconciliation parameters:\n        - cutoff_date (str): Cutoff date in YYYY-MM-DD format (required)\n        - id_companies_active (str): Company filter in SQL format, \n                                     e.g., \"('EC_NG')\" (required)\n        - gl_accounts (List[str], optional): GL accounts to include\n        - required_ipes (List[str], optional): IPE IDs to load. \n                                               Note: 'JDASH' is required for timing difference bridge.\n                                               'IPE_31' is required for bridge classification.\n        - uploaded_files (Dict[str, Any], optional): Manual file uploads\n        - run_bridges (bool, optional): Whether to run bridge analysis (default: True)\n        - validate_quality (bool, optional): Whether to run quality checks (default: True)\n\nReturns:\n    Dictionary containing all reconciliation results:\n    {\n        'status': str - 'SUCCESS', 'WARNING', or 'ERROR'\n        'timestamp': str - ISO timestamp of execution\n        'params': dict - Input parameters used\n        'dataframes': dict - All DataFrames (as serializable dicts)\n        'dataframe_summaries': dict - Row counts and column info\n        'evidence_paths': dict - Paths to evidence packages\n        'data_sources': dict - Source of each data item\n        'quality_reports': dict - Quality check results\n        'categorization': dict - Bridge categorization results\n        'bridges': dict - Bridge calculation results\n        'reconciliation': dict - Overall reconciliation metrics\n        'errors': list - Any errors encountered\n        'warnings': list - Any warnings generated\n    }\n\nExample:\n    >>> params = {\n    ...     'cutoff_date': '2025-09-30',\n    ...     'id_companies_active': \"('EC_NG')\",\n    ... }\n    >>> result = run_reconciliation(params)\n    >>> print(f\"Status: {result['status']}\")\n    >>> print(f\"Total rows processed: {sum(s['row_count'] for s in result['dataframe_summaries'].values())}\")"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "__init__",
      "qualname": "SummaryBuilder.__init__",
      "enclosing": [
        "SummaryBuilder"
      ],
      "module": "src.core.reconciliation.summary_builder",
      "file": "src\\core\\reconciliation\\summary_builder.py",
      "lineno": 38,
      "end_lineno": 46,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "data_store",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, pd.DataFrame]",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Initialize the summary builder.",
        "returns": null,
        "raw": "Initialize the summary builder.\n\nArgs:\n    data_store: Dictionary mapping IPE/CR IDs to DataFrames"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "build",
      "qualname": "SummaryBuilder.build",
      "enclosing": [
        "SummaryBuilder"
      ],
      "module": "src.core.reconciliation.summary_builder",
      "file": "src\\core\\reconciliation\\summary_builder.py",
      "lineno": 48,
      "end_lineno": 86,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Build complete reconciliation metrics.",
        "returns": "Dictionary with reconciliation metrics:\n{\n'actuals': float - GL balance total\n'target_values': float - Sum of component IPEs\n'variance': float - Difference\n'status': str - 'RECONCILED' or 'VARIANCE_DETECTED'\n'component_totals': dict - Per-IPE totals\n}",
        "raw": "Build complete reconciliation metrics.\n\nReturns:\n    Dictionary with reconciliation metrics:\n    {\n        'actuals': float - GL balance total\n        'target_values': float - Sum of component IPEs\n        'variance': float - Difference\n        'status': str - 'RECONCILED' or 'VARIANCE_DETECTED'\n        'component_totals': dict - Per-IPE totals\n    }"
      }
    },
    {
      "kind": "class",
      "name": "SummaryBuilder",
      "qualname": "SummaryBuilder",
      "enclosing": [],
      "module": "src.core.reconciliation.summary_builder",
      "file": "src\\core\\reconciliation\\summary_builder.py",
      "lineno": 26,
      "end_lineno": 151,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Build financial reconciliation summaries.",
        "raw": "Build financial reconciliation summaries.\n\nUses CPG1ReconciliationConfig for business logic and rules.\n\nExample:\n    >>> builder = SummaryBuilder(data_store)\n    >>> metrics = builder.build()\n    >>> print(f\"Variance: {metrics['variance']}\")"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "calculate_reconciliation_metrics",
      "qualname": "calculate_reconciliation_metrics",
      "enclosing": [],
      "module": "src.core.reconciliation.summary_builder",
      "file": "src\\core\\reconciliation\\summary_builder.py",
      "lineno": 154,
      "end_lineno": 169,
      "decorators": [],
      "parameters": [
        {
          "name": "data_store",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, pd.DataFrame]",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Calculate overall reconciliation metrics.",
        "returns": "Dictionary with reconciliation metrics",
        "raw": "Calculate overall reconciliation metrics.\n\nConvenience function that creates a SummaryBuilder and builds metrics.\n\nArgs:\n    data_store: Dictionary mapping IPE/CR IDs to DataFrames\n\nReturns:\n    Dictionary with reconciliation metrics"
      }
    },
    {
      "kind": "class",
      "name": "IPEValidationError",
      "qualname": "IPEValidationError",
      "enclosing": [],
      "module": "src.core.runners.mssql_runner",
      "file": "src\\core\\runners\\mssql_runner.py",
      "lineno": 21,
      "end_lineno": 23,
      "decorators": [],
      "bases": [
        "Exception"
      ],
      "keywords": [],
      "doc": {
        "summary": "Exception raised when IPE validation fails.",
        "raw": "Exception raised when IPE validation fails."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "class",
      "name": "IPEConnectionError",
      "qualname": "IPEConnectionError",
      "enclosing": [],
      "module": "src.core.runners.mssql_runner",
      "file": "src\\core\\runners\\mssql_runner.py",
      "lineno": 26,
      "end_lineno": 28,
      "decorators": [],
      "bases": [
        "Exception"
      ],
      "keywords": [],
      "doc": {
        "summary": "Exception raised when database connection fails.",
        "raw": "Exception raised when database connection fails."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "__init__",
      "qualname": "IPERunner.__init__",
      "enclosing": [
        "IPERunner"
      ],
      "module": "src.core.runners.mssql_runner",
      "file": "src\\core\\runners\\mssql_runner.py",
      "lineno": 37,
      "end_lineno": 79,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "ipe_config",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        },
        {
          "name": "secret_manager",
          "kind": "positional_or_keyword",
          "annotation": "AWSSecretsManager",
          "default": null
        },
        {
          "name": "cutoff_date",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "evidence_manager",
          "kind": "positional_or_keyword",
          "annotation": "Optional[DigitalEvidenceManager]",
          "default": "None"
        },
        {
          "name": "country",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "period",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "full_params",
          "kind": "positional_or_keyword",
          "annotation": "Optional[Dict[str, Any]]",
          "default": "None"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Initialize the runner for a specific IPE.",
        "returns": null,
        "raw": "Initialize the runner for a specific IPE.\n\nArgs:\n    ipe_config: IPE configuration (from config.py)\n    secret_manager: AWS Secrets Manager instance\n    cutoff_date: Cutoff date for extractions (format: YYYY-MM-DD)\n    evidence_manager: Digital evidence manager for SOX compliance\n    country: Country code (e.g., 'NG', 'KE') for evidence naming\n    period: Period in YYYYMM format (e.g., '202509') for evidence naming\n    full_params: Full dictionary of all SQL parameters to be logged"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "run",
      "qualname": "IPERunner.run",
      "enclosing": [
        "IPERunner"
      ],
      "module": "src.core.runners.mssql_runner",
      "file": "src\\core\\runners\\mssql_runner.py",
      "lineno": 294,
      "end_lineno": 409,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Execute complete IPE: extraction, validation and SOX evidence generation.",
        "returns": "DataFrame containing extracted and validated data\n\nRaises:\nIPEValidationError: If validation fails\nIPEConnectionError: If connection problem occurs",
        "raw": "Execute complete IPE: extraction, validation and SOX evidence generation.\n\nReturns:\n    DataFrame containing extracted and validated data\n    \nRaises:\n    IPEValidationError: If validation fails\n    IPEConnectionError: If connection problem occurs"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "run_demo",
      "qualname": "IPERunner.run_demo",
      "enclosing": [
        "IPERunner"
      ],
      "module": "src.core.runners.mssql_runner",
      "file": "src\\core\\runners\\mssql_runner.py",
      "lineno": 412,
      "end_lineno": 634,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "demo_dataframe",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "source_name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Demo execution path: uses a provided DataFrame instead of querying the DB",
        "returns": null,
        "raw": "Demo execution path: uses a provided DataFrame instead of querying the DB\nand generates a complete evidence package."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "get_validation_summary",
      "qualname": "IPERunner.get_validation_summary",
      "enclosing": [
        "IPERunner"
      ],
      "module": "src.core.runners.mssql_runner",
      "file": "src\\core\\runners\\mssql_runner.py",
      "lineno": 636,
      "end_lineno": 649,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Returns a summary of validation results.",
        "returns": "Dictionary containing validation summary",
        "raw": "Returns a summary of validation results.\n\nReturns:\n    Dictionary containing validation summary"
      }
    },
    {
      "kind": "class",
      "name": "IPERunner",
      "qualname": "IPERunner",
      "enclosing": [],
      "module": "src.core.runners.mssql_runner",
      "file": "src\\core\\runners\\mssql_runner.py",
      "lineno": 31,
      "end_lineno": 649,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Class responsible for executing a single IPE.",
        "raw": "Class responsible for executing a single IPE.\nManages data extraction, validation, and cleanup."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_sql_query_for_item",
      "qualname": "get_sql_query_for_item",
      "enclosing": [],
      "module": "src.frontend.app",
      "file": "src\\frontend\\app.py",
      "lineno": 72,
      "end_lineno": 77,
      "decorators": [],
      "parameters": [
        {
          "name": "item_id",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": "Retrieve the SQL query for a catalog item.",
        "returns": null,
        "raw": "Retrieve the SQL query for a catalog item."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "convert_df",
      "qualname": "convert_df",
      "enclosing": [],
      "module": "src.frontend.app",
      "file": "src\\frontend\\app.py",
      "lineno": 81,
      "end_lineno": 83,
      "decorators": [
        "st.cache_data"
      ],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "bytes",
      "doc": {
        "summary": "Convert a DataFrame to CSV bytes for Streamlit download buttons.",
        "returns": null,
        "raw": "Convert a DataFrame to CSV bytes for Streamlit download buttons."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_latest_evidence_zip",
      "qualname": "get_latest_evidence_zip",
      "enclosing": [],
      "module": "src.frontend.app",
      "file": "src\\frontend\\app.py",
      "lineno": 128,
      "end_lineno": 150,
      "decorators": [],
      "parameters": [
        {
          "name": "item_id",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Finds the most recent ZIP package generated for an IPE.",
        "returns": null,
        "raw": "Finds the most recent ZIP package generated for an IPE."
      }
    },
    {
      "kind": "function",
      "async": true,
      "name": "run_extraction_with_evidence",
      "qualname": "run_extraction_with_evidence",
      "enclosing": [],
      "module": "src.frontend.app",
      "file": "src\\frontend\\app.py",
      "lineno": 153,
      "end_lineno": 213,
      "decorators": [],
      "parameters": [
        {
          "name": "item_id",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "params",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "country_code",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "period_str",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Executes extraction via IPERunner.run() ensuring Rich Metadata & Evidence Generation.",
        "returns": null,
        "raw": "Executes extraction via IPERunner.run() ensuring Rich Metadata & Evidence Generation.\nIncludes a PATCH for CR_05 column names."
      }
    },
    {
      "kind": "nested_function",
      "async": false,
      "name": "patched_exec",
      "qualname": "run_extraction_with_evidence.patched_exec",
      "enclosing": [
        "run_extraction_with_evidence"
      ],
      "module": "src.frontend.app",
      "file": "src\\frontend\\app.py",
      "lineno": 191,
      "end_lineno": 192,
      "decorators": [],
      "parameters": [
        {
          "name": "query",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "params",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "None"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "load_jdash_data",
      "qualname": "load_jdash_data",
      "enclosing": [],
      "module": "src.frontend.app",
      "file": "src\\frontend\\app.py",
      "lineno": 216,
      "end_lineno": 222,
      "decorators": [],
      "parameters": [
        {
          "name": "uploaded_file",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "load_all_data",
      "qualname": "load_all_data",
      "enclosing": [],
      "module": "src.frontend.app",
      "file": "src\\frontend\\app.py",
      "lineno": 225,
      "end_lineno": 319,
      "decorators": [],
      "parameters": [
        {
          "name": "params",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "uploaded_files",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "None"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Orchestrates loading and evidence collection with context.",
        "returns": "tuple: (data_store, evidence_store, source_store) where source_store tracks\nthe source of each dataset (\"Uploaded File\", \"Live Database\", \"Local Fixture\")",
        "raw": "Orchestrates loading and evidence collection with context.\n\nArgs:\n    params: SQL parameters dictionary\n    uploaded_files: Dictionary of {item_id: UploadedFile} for manual CSV overrides\n\nReturns:\n    tuple: (data_store, evidence_store, source_store) where source_store tracks \n           the source of each dataset (\"Uploaded File\", \"Live Database\", \"Local Fixture\")"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "src.frontend.app",
      "file": "src\\frontend\\app.py",
      "lineno": 325,
      "end_lineno": 754,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "nested_function",
      "async": false,
      "name": "display_source_badge",
      "qualname": "main.display_source_badge",
      "enclosing": [
        "main"
      ],
      "module": "src.frontend.app",
      "file": "src\\frontend\\app.py",
      "lineno": 476,
      "end_lineno": 485,
      "decorators": [],
      "parameters": [
        {
          "name": "source",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Display a colored badge indicating the data source.",
        "returns": null,
        "raw": "Display a colored badge indicating the data source."
      }
    },
    {
      "kind": "class",
      "name": "AuditRequest",
      "qualname": "AuditRequest",
      "enclosing": [],
      "module": "src.frontend.n8n_api",
      "file": "src\\frontend\\n8n_api.py",
      "lineno": 35,
      "end_lineno": 42,
      "decorators": [],
      "bases": [
        "BaseModel"
      ],
      "keywords": [],
      "doc": {
        "summary": null,
        "raw": null
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "health_check",
      "qualname": "health_check",
      "enclosing": [],
      "module": "src.frontend.n8n_api",
      "file": "src\\frontend\\n8n_api.py",
      "lineno": 128,
      "end_lineno": 130,
      "decorators": [
        "app.get('/health')"
      ],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Health check pour n8n ou Kubernetes.",
        "returns": null,
        "raw": "Health check pour n8n ou Kubernetes."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "run_task1",
      "qualname": "run_task1",
      "enclosing": [],
      "module": "src.frontend.n8n_api",
      "file": "src\\frontend\\n8n_api.py",
      "lineno": 133,
      "end_lineno": 164,
      "decorators": [
        "app.post('/run-audit/task1-timing')"
      ],
      "parameters": [
        {
          "name": "req",
          "kind": "positional_or_keyword",
          "annotation": "AuditRequest",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Excute la Tche 1 : Timing Difference.",
        "returns": null,
        "raw": "Excute la Tche 1 : Timing Difference.\nNcessite les donnes Jdash dans le corps de la requte (JSON)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "run_task2",
      "qualname": "run_task2",
      "enclosing": [],
      "module": "src.frontend.n8n_api",
      "file": "src\\frontend\\n8n_api.py",
      "lineno": 167,
      "end_lineno": 200,
      "decorators": [
        "app.post('/run-audit/task2-vtc')"
      ],
      "parameters": [
        {
          "name": "req",
          "kind": "positional_or_keyword",
          "annotation": "AuditRequest",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Excute la Tche 2 : VTC Adjustment.",
        "returns": null,
        "raw": "Excute la Tche 2 : VTC Adjustment.\nDclenche l'extraction de CR_03, IPE_08 et DOC_VOUCHER_USAGE."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "run_task3",
      "qualname": "run_task3",
      "enclosing": [],
      "module": "src.frontend.n8n_api",
      "file": "src\\frontend\\n8n_api.py",
      "lineno": 203,
      "end_lineno": 222,
      "decorators": [
        "app.post('/run-audit/task3-integration')"
      ],
      "parameters": [
        {
          "name": "req",
          "kind": "positional_or_keyword",
          "annotation": "AuditRequest",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Excute la Tche 3 : Integration Errors.",
        "returns": null,
        "raw": "Excute la Tche 3 : Integration Errors."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "run_task4",
      "qualname": "run_task4",
      "enclosing": [],
      "module": "src.frontend.n8n_api",
      "file": "src\\frontend\\n8n_api.py",
      "lineno": 225,
      "end_lineno": 241,
      "decorators": [
        "app.post('/run-audit/task4-reclass')"
      ],
      "parameters": [
        {
          "name": "req",
          "kind": "positional_or_keyword",
          "annotation": "AuditRequest",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Excute la Tche 4 : Customer Reclass.",
        "returns": null,
        "raw": "Excute la Tche 4 : Customer Reclass."
      }
    },
    {
      "kind": "class",
      "name": "WorkflowExecutionError",
      "qualname": "WorkflowExecutionError",
      "enclosing": [],
      "module": "src.orchestrators.workflow",
      "file": "src\\orchestrators\\workflow.py",
      "lineno": 29,
      "end_lineno": 31,
      "decorators": [],
      "bases": [
        "Exception"
      ],
      "keywords": [],
      "doc": {
        "summary": "Exception raised when the global workflow fails.",
        "raw": "Exception raised when the global workflow fails."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "execute_ipe_workflow",
      "qualname": "execute_ipe_workflow",
      "enclosing": [],
      "module": "src.orchestrators.workflow",
      "file": "src\\orchestrators\\workflow.py",
      "lineno": 34,
      "end_lineno": 195,
      "decorators": [],
      "parameters": [
        {
          "name": "cutoff_date",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "None"
        },
        {
          "name": "country",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "None"
        }
      ],
      "return_annotation": "Tuple[Dict[str, Any], int]",
      "doc": {
        "summary": "Executes the complete IPE extraction and validation workflow.",
        "returns": "Tuple containing (results, HTTP_status_code)",
        "raw": "Executes the complete IPE extraction and validation workflow.\n\nArgs:\n    cutoff_date: Optional cutoff date (format YYYY-MM-DD)\n    country: Optional country code (e.g., 'NG', 'KE') for evidence folder naming\n    \nReturns:\n    Tuple containing (results, HTTP_status_code)"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "dataframe_to_dict",
      "qualname": "dataframe_to_dict",
      "enclosing": [],
      "module": "src.orchestrators.archive_temporal.cpg1_activities",
      "file": "src\\orchestrators\\archive_temporal\\cpg1_activities.py",
      "lineno": 30,
      "end_lineno": 48,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Serialize a pandas DataFrame to a JSON-compatible dictionary.",
        "returns": "Dictionary with data and metadata",
        "raw": "Serialize a pandas DataFrame to a JSON-compatible dictionary.\n\nArgs:\n    df: DataFrame to serialize\n\nReturns:\n    Dictionary with data and metadata"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "dict_to_dataframe",
      "qualname": "dict_to_dataframe",
      "enclosing": [],
      "module": "src.orchestrators.archive_temporal.cpg1_activities",
      "file": "src\\orchestrators\\archive_temporal\\cpg1_activities.py",
      "lineno": 51,
      "end_lineno": 79,
      "decorators": [],
      "parameters": [
        {
          "name": "data_dict",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Deserialize a dictionary back to a pandas DataFrame.",
        "returns": "Reconstructed DataFrame",
        "raw": "Deserialize a dictionary back to a pandas DataFrame.\n\nArgs:\n    data_dict: Dictionary containing DataFrame data\n\nReturns:\n    Reconstructed DataFrame"
      }
    },
    {
      "kind": "function",
      "async": true,
      "name": "execute_ipe_query_activity",
      "qualname": "execute_ipe_query_activity",
      "enclosing": [],
      "module": "src.orchestrators.archive_temporal.cpg1_activities",
      "file": "src\\orchestrators\\archive_temporal\\cpg1_activities.py",
      "lineno": 83,
      "end_lineno": 191,
      "decorators": [
        "activity.defn(name='execute_ipe_query')"
      ],
      "parameters": [
        {
          "name": "ipe_id",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "cutoff_date",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "country",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Execute an IPE query using the IPERunner.",
        "returns": "Dictionary containing:\n- data: Serialized DataFrame\n- validation_results: Validation summary\n- evidence_path: Path to evidence package",
        "raw": "Execute an IPE query using the IPERunner.\n\nArgs:\n    ipe_id: IPE identifier (e.g., \"IPE_07\", \"IPE_31\")\n    cutoff_date: Optional cutoff date for the query (YYYY-MM-DD)\n    country: Optional country code (e.g., 'NG', 'KE') for evidence folder naming\n\nReturns:\n    Dictionary containing:\n    - data: Serialized DataFrame\n    - validation_results: Validation summary\n    - evidence_path: Path to evidence package"
      }
    },
    {
      "kind": "function",
      "async": true,
      "name": "execute_cr_query_activity",
      "qualname": "execute_cr_query_activity",
      "enclosing": [],
      "module": "src.orchestrators.archive_temporal.cpg1_activities",
      "file": "src\\orchestrators\\archive_temporal\\cpg1_activities.py",
      "lineno": 195,
      "end_lineno": 254,
      "decorators": [
        "activity.defn(name='execute_cr_query')"
      ],
      "parameters": [
        {
          "name": "cr_id",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "parameters",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Execute a CR (Custom Report) query.",
        "returns": "Dictionary containing serialized DataFrame",
        "raw": "Execute a CR (Custom Report) query.\n\nArgs:\n    cr_id: CR identifier (e.g., \"CR_03\", \"CR_04\")\n    parameters: Query parameters (e.g., cutoff_date, gl_accounts)\n\nReturns:\n    Dictionary containing serialized DataFrame"
      }
    },
    {
      "kind": "function",
      "async": true,
      "name": "calculate_timing_difference_bridge_activity",
      "qualname": "calculate_timing_difference_bridge_activity",
      "enclosing": [],
      "module": "src.orchestrators.archive_temporal.cpg1_activities",
      "file": "src\\orchestrators\\archive_temporal\\cpg1_activities.py",
      "lineno": 258,
      "end_lineno": 301,
      "decorators": [
        "activity.defn(name='calculate_timing_difference_bridge')"
      ],
      "parameters": [
        {
          "name": "ipe_08_data",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        },
        {
          "name": "cutoff_date",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Calculate timing difference bridge using cut-off logic.",
        "returns": "Dictionary with bridge_amount and proof data",
        "raw": "Calculate timing difference bridge using cut-off logic.\n\nArgs:\n    ipe_08_data: Serialized IPE_08 DataFrame\n    cutoff_date: Reconciliation cutoff date (YYYY-MM-DD)\n\nReturns:\n    Dictionary with bridge_amount and proof data"
      }
    },
    {
      "kind": "function",
      "async": true,
      "name": "calculate_vtc_adjustment_activity",
      "qualname": "calculate_vtc_adjustment_activity",
      "enclosing": [],
      "module": "src.orchestrators.archive_temporal.cpg1_activities",
      "file": "src\\orchestrators\\archive_temporal\\cpg1_activities.py",
      "lineno": 305,
      "end_lineno": 354,
      "decorators": [
        "activity.defn(name='calculate_vtc_adjustment')"
      ],
      "parameters": [
        {
          "name": "ipe_08_data",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        },
        {
          "name": "categorized_cr_03_data",
          "kind": "positional_or_keyword",
          "annotation": "Optional[Dict[str, Any]]",
          "default": "None"
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Calculate VTC (Voucher to Cash) adjustment.",
        "returns": "Dictionary with adjustment_amount and proof data",
        "raw": "Calculate VTC (Voucher to Cash) adjustment.\n\nArgs:\n    ipe_08_data: Serialized IPE_08 DataFrame\n    categorized_cr_03_data: Optional serialized categorized CR_03 DataFrame\n\nReturns:\n    Dictionary with adjustment_amount and proof data"
      }
    },
    {
      "kind": "function",
      "async": true,
      "name": "calculate_customer_posting_group_bridge_activity",
      "qualname": "calculate_customer_posting_group_bridge_activity",
      "enclosing": [],
      "module": "src.orchestrators.archive_temporal.cpg1_activities",
      "file": "src\\orchestrators\\archive_temporal\\cpg1_activities.py",
      "lineno": 358,
      "end_lineno": 401,
      "decorators": [
        "activity.defn(name='calculate_customer_posting_group_bridge')"
      ],
      "parameters": [
        {
          "name": "ipe_07_data",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Calculate customer posting group bridge (identifies posting group inconsistencies).",
        "returns": "Dictionary with bridge_amount and proof data",
        "raw": "Calculate customer posting group bridge (identifies posting group inconsistencies).\n\nArgs:\n    ipe_07_data: Serialized IPE_07 DataFrame\n\nReturns:\n    Dictionary with bridge_amount and proof data"
      }
    },
    {
      "kind": "function",
      "async": true,
      "name": "save_evidence_activity",
      "qualname": "save_evidence_activity",
      "enclosing": [],
      "module": "src.orchestrators.archive_temporal.cpg1_activities",
      "file": "src\\orchestrators\\archive_temporal\\cpg1_activities.py",
      "lineno": 405,
      "end_lineno": 464,
      "decorators": [
        "activity.defn(name='save_evidence')"
      ],
      "parameters": [
        {
          "name": "evidence_type",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "evidence_data",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        },
        {
          "name": "metadata",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Save evidence for audit trail.",
        "returns": "Dictionary with evidence_path and confirmation",
        "raw": "Save evidence for audit trail.\n\nArgs:\n    evidence_type: Type of evidence (e.g., \"bridge\", \"adjustment\", \"validation\")\n    evidence_data: Evidence data to save\n    metadata: Additional metadata for the evidence\n\nReturns:\n    Dictionary with evidence_path and confirmation"
      }
    },
    {
      "kind": "function",
      "async": true,
      "name": "classify_bridges_activity",
      "qualname": "classify_bridges_activity",
      "enclosing": [],
      "module": "src.orchestrators.archive_temporal.cpg1_activities",
      "file": "src\\orchestrators\\archive_temporal\\cpg1_activities.py",
      "lineno": 468,
      "end_lineno": 522,
      "decorators": [
        "activity.defn(name='classify_bridges')"
      ],
      "parameters": [
        {
          "name": "dataframe_data",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        },
        {
          "name": "rules_config",
          "kind": "positional_or_keyword",
          "annotation": "Optional[List[Dict[str, Any]]]",
          "default": "None"
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Apply bridge classification rules to data.",
        "returns": "Dictionary with classified data",
        "raw": "Apply bridge classification rules to data.\n\nArgs:\n    dataframe_data: Serialized DataFrame to classify\n    rules_config: Optional bridge rules configuration\n\nReturns:\n    Dictionary with classified data"
      }
    },
    {
      "kind": "function",
      "async": true,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "src.orchestrators.archive_temporal.cpg1_worker",
      "file": "src\\orchestrators\\archive_temporal\\cpg1_worker.py",
      "lineno": 49,
      "end_lineno": 106,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Start the Temporal worker.",
        "returns": null,
        "raw": "Start the Temporal worker."
      }
    },
    {
      "kind": "method",
      "async": true,
      "name": "run",
      "qualname": "Cpg1Workflow.run",
      "enclosing": [
        "Cpg1Workflow"
      ],
      "module": "src.orchestrators.archive_temporal.cpg1_workflow",
      "file": "src\\orchestrators\\archive_temporal\\cpg1_workflow.py",
      "lineno": 65,
      "end_lineno": 361,
      "decorators": [
        "workflow.run"
      ],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "workflow_input",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any]",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Main workflow execution method.",
        "returns": "Dictionary with workflow execution results",
        "raw": "Main workflow execution method.\n\nArgs:\n    workflow_input: Dictionary containing:\n        - cutoff_date: Cutoff date for reconciliation (YYYY-MM-DD)\n        - gl_accounts: List of GL accounts to reconcile\n        - year_start: Start of year for GL entries (YYYY-MM-DD)\n        - year_end: End of year for GL entries (YYYY-MM-DD)\n\nReturns:\n    Dictionary with workflow execution results"
      }
    },
    {
      "kind": "class",
      "name": "Cpg1Workflow",
      "qualname": "Cpg1Workflow",
      "enclosing": [],
      "module": "src.orchestrators.archive_temporal.cpg1_workflow",
      "file": "src\\orchestrators\\archive_temporal\\cpg1_workflow.py",
      "lineno": 52,
      "end_lineno": 361,
      "decorators": [
        "workflow.defn(name='Cpg1Workflow')"
      ],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Main workflow for C-PG-1 reconciliation process.",
        "raw": "Main workflow for C-PG-1 reconciliation process.\n\nThis workflow orchestrates the entire reconciliation by:\n1. Fetching IPE data (customer accounts, collection accounts, etc.)\n2. Fetching CR data (NAV GL entries and balances)\n3. Calculating variance between IPE and CR\n4. Calling classifiers to identify bridges and adjustments\n5. Saving evidence for audit trail"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "__init__",
      "qualname": "AWSSecretsManager.__init__",
      "enclosing": [
        "AWSSecretsManager"
      ],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 33,
      "end_lineno": 74,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "region_name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "'eu-west-1'"
        },
        {
          "name": "use_okta",
          "kind": "positional_or_keyword",
          "annotation": "bool",
          "default": "None"
        },
        {
          "name": "profile_name",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Initializes the AWS Secrets Manager client.",
        "returns": null,
        "raw": "Initializes the AWS Secrets Manager client.\n\nArgs:\n    region_name: AWS region (default 'eu-west-1')\n    use_okta: Whether to use Okta authentication (auto-detect if None)\n    profile_name: AWS profile name for Okta SSO (e.g., 'jumia-sox-prod')"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "get_secret",
      "qualname": "AWSSecretsManager.get_secret",
      "enclosing": [
        "AWSSecretsManager"
      ],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 76,
      "end_lineno": 114,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "secret_name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": "Retrieves a secret from AWS Secrets Manager.",
        "returns": "The secret value as a string\n\nRaises:\nException: If the secret is not found or inaccessible",
        "raw": "Retrieves a secret from AWS Secrets Manager.\n\nArgs:\n    secret_name: The secret identifier\n    \nReturns:\n    The secret value as a string\n    \nRaises:\n    Exception: If the secret is not found or inaccessible"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "get_json_secret",
      "qualname": "AWSSecretsManager.get_json_secret",
      "enclosing": [
        "AWSSecretsManager"
      ],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 116,
      "end_lineno": 131,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "secret_name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Retrieves a JSON secret and returns it as a dictionary.",
        "returns": "The parsed secret as a dictionary",
        "raw": "Retrieves a JSON secret and returns it as a dictionary.\n\nArgs:\n    secret_name: The JSON secret identifier\n    \nReturns:\n    The parsed secret as a dictionary"
      }
    },
    {
      "kind": "class",
      "name": "AWSSecretsManager",
      "qualname": "AWSSecretsManager",
      "enclosing": [],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 30,
      "end_lineno": 131,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Manager for accessing secrets in AWS Secrets Manager with Okta SSO support.",
        "raw": "Manager for accessing secrets in AWS Secrets Manager with Okta SSO support."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "__init__",
      "qualname": "AWSRedshift.__init__",
      "enclosing": [
        "AWSRedshift"
      ],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 137,
      "end_lineno": 170,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "cluster_endpoint",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "database",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "user",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "password",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "port",
          "kind": "positional_or_keyword",
          "annotation": "int",
          "default": "5439"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Initializes the Redshift connection.",
        "returns": null,
        "raw": "Initializes the Redshift connection.\n\nArgs:\n    cluster_endpoint: Redshift cluster endpoint\n    database: Database name\n    user: Database user\n    password: Database password\n    port: Database port (default 5439)"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "write_dataframe",
      "qualname": "AWSRedshift.write_dataframe",
      "enclosing": [
        "AWSRedshift"
      ],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 172,
      "end_lineno": 212,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "dataframe",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "schema",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "table",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "write_mode",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "'replace'"
        }
      ],
      "return_annotation": "None",
      "doc": {
        "summary": "Writes a Pandas DataFrame to a Redshift table.",
        "returns": null,
        "raw": "Writes a Pandas DataFrame to a Redshift table.\n\nArgs:\n    dataframe: The DataFrame to write\n    schema: The Redshift schema\n    table: The table name\n    write_mode: Write mode ('replace', 'append')"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "query_to_dataframe",
      "qualname": "AWSRedshift.query_to_dataframe",
      "enclosing": [
        "AWSRedshift"
      ],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 214,
      "end_lineno": 230,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "query",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "pd.DataFrame",
      "doc": {
        "summary": "Executes a Redshift query and returns results as a DataFrame.",
        "returns": "DataFrame containing query results",
        "raw": "Executes a Redshift query and returns results as a DataFrame.\n\nArgs:\n    query: The SQL query to execute\n    \nReturns:\n    DataFrame containing query results"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "close",
      "qualname": "AWSRedshift.close",
      "enclosing": [
        "AWSRedshift"
      ],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 232,
      "end_lineno": 239,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Closes the Redshift connection.",
        "returns": null,
        "raw": "Closes the Redshift connection."
      }
    },
    {
      "kind": "class",
      "name": "AWSRedshift",
      "qualname": "AWSRedshift",
      "enclosing": [],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 134,
      "end_lineno": 239,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Manager for Amazon Redshift interactions.",
        "raw": "Manager for Amazon Redshift interactions."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "__init__",
      "qualname": "AWSS3Manager.__init__",
      "enclosing": [
        "AWSS3Manager"
      ],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 245,
      "end_lineno": 290,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "region_name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "'eu-west-1'"
        },
        {
          "name": "use_okta",
          "kind": "positional_or_keyword",
          "annotation": "bool",
          "default": "None"
        },
        {
          "name": "profile_name",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Initializes the S3 client.",
        "returns": null,
        "raw": "Initializes the S3 client.\n\nArgs:\n    region_name: AWS region\n    use_okta: Whether to use Okta authentication (auto-detect if None)\n    profile_name: AWS profile name for Okta SSO"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "upload_dataframe_as_csv",
      "qualname": "AWSS3Manager.upload_dataframe_as_csv",
      "enclosing": [
        "AWSS3Manager"
      ],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 292,
      "end_lineno": 321,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "dataframe",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "bucket",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "key",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": "Uploads a DataFrame to S3 as a CSV file.",
        "returns": "S3 URI of the uploaded file",
        "raw": "Uploads a DataFrame to S3 as a CSV file.\n\nArgs:\n    dataframe: The DataFrame to upload\n    bucket: S3 bucket name\n    key: S3 object key (path)\n    \nReturns:\n    S3 URI of the uploaded file"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "upload_file",
      "qualname": "AWSS3Manager.upload_file",
      "enclosing": [
        "AWSS3Manager"
      ],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 323,
      "end_lineno": 343,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "file_path",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "bucket",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "key",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": "Uploads a local file to S3.",
        "returns": "S3 URI of the uploaded file",
        "raw": "Uploads a local file to S3.\n\nArgs:\n    file_path: Path to the local file\n    bucket: S3 bucket name\n    key: S3 object key (path)\n    \nReturns:\n    S3 URI of the uploaded file"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "download_file",
      "qualname": "AWSS3Manager.download_file",
      "enclosing": [
        "AWSS3Manager"
      ],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 345,
      "end_lineno": 364,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "bucket",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "key",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "local_path",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": "Downloads a file from S3 to local path.",
        "returns": "Local file path",
        "raw": "Downloads a file from S3 to local path.\n\nArgs:\n    bucket: S3 bucket name\n    key: S3 object key (path)\n    local_path: Local file path to save to\n    \nReturns:\n    Local file path"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "list_objects",
      "qualname": "AWSS3Manager.list_objects",
      "enclosing": [
        "AWSS3Manager"
      ],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 366,
      "end_lineno": 393,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "bucket",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "prefix",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "''"
        }
      ],
      "return_annotation": "list",
      "doc": {
        "summary": "Lists objects in an S3 bucket with optional prefix.",
        "returns": "List of object keys",
        "raw": "Lists objects in an S3 bucket with optional prefix.\n\nArgs:\n    bucket: S3 bucket name\n    prefix: Object key prefix to filter by\n    \nReturns:\n    List of object keys"
      }
    },
    {
      "kind": "class",
      "name": "AWSS3Manager",
      "qualname": "AWSS3Manager",
      "enclosing": [],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 242,
      "end_lineno": 393,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Manager for Amazon S3 interactions with Okta SSO support.",
        "raw": "Manager for Amazon S3 interactions with Okta SSO support."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "initialize_aws_services",
      "qualname": "initialize_aws_services",
      "enclosing": [],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 396,
      "end_lineno": 415,
      "decorators": [],
      "parameters": [
        {
          "name": "region_name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "'eu-west-1'"
        }
      ],
      "return_annotation": "tuple",
      "doc": {
        "summary": "Initializes necessary AWS services.",
        "returns": "Tuple containing (secrets_manager, s3_manager)",
        "raw": "Initializes necessary AWS services.\n\nArgs:\n    region_name: AWS region\n    \nReturns:\n    Tuple containing (secrets_manager, s3_manager)"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_redshift_connection",
      "qualname": "get_redshift_connection",
      "enclosing": [],
      "module": "src.utils.aws_utils",
      "file": "src\\utils\\aws_utils.py",
      "lineno": 418,
      "end_lineno": 442,
      "decorators": [],
      "parameters": [
        {
          "name": "secrets_manager",
          "kind": "positional_or_keyword",
          "annotation": "AWSSecretsManager",
          "default": null
        },
        {
          "name": "secret_name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "AWSRedshift",
      "doc": {
        "summary": "Initializes a Redshift connection using credentials from Secrets Manager.",
        "returns": "AWSRedshift instance",
        "raw": "Initializes a Redshift connection using credentials from Secrets Manager.\n\nArgs:\n    secrets_manager: AWS Secrets Manager instance\n    secret_name: Name of the secret containing Redshift credentials\n    \nReturns:\n    AWSRedshift instance"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "probe_df",
      "qualname": "probe_df",
      "enclosing": [],
      "module": "src.utils.debug_probes",
      "file": "src\\utils\\debug_probes.py",
      "lineno": 26,
      "end_lineno": 104,
      "decorators": [],
      "parameters": [
        {
          "name": "df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "checkpoint_name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "debug_dir",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "'outputs/_debug_sep2025_ng'"
        },
        {
          "name": "metrics",
          "kind": "positional_or_keyword",
          "annotation": "Optional[List[str]]",
          "default": "None"
        }
      ],
      "return_annotation": "None",
      "doc": {
        "summary": "Probe a DataFrame at a specific checkpoint in the reconciliation flow.",
        "returns": null,
        "raw": "Probe a DataFrame at a specific checkpoint in the reconciliation flow.\n\nCaptures key metrics and writes them to a debug log file. This is a \nlightweight inspection tool that doesn't modify the DataFrame.\n\nArgs:\n    df: The DataFrame to inspect\n    checkpoint_name: Descriptive name for this checkpoint (e.g., \"NAV_raw_load\")\n    debug_dir: Directory to write debug logs (created if not exists)\n    metrics: Optional list of column names to calculate sum/count for\n\nExample:\n    >>> probe_df(nav_df, \"NAV_raw_load\", metrics=[\"Amount\"])\n    >>> probe_df(ipe08_df, \"IPE08_scope_filtered\", metrics=[\"TotalAmountUsed\"])"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "audit_merge",
      "qualname": "audit_merge",
      "enclosing": [],
      "module": "src.utils.debug_probes",
      "file": "src\\utils\\debug_probes.py",
      "lineno": 107,
      "end_lineno": 234,
      "decorators": [],
      "parameters": [
        {
          "name": "left_df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "right_df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "on",
          "kind": "positional_or_keyword",
          "annotation": "Union[str, List[str]]",
          "default": null
        },
        {
          "name": "merge_name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "debug_dir",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "'outputs/_debug_sep2025_ng'"
        },
        {
          "name": "how",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "'inner'"
        }
      ],
      "return_annotation": "None",
      "doc": {
        "summary": "Audit a merge operation before it happens.",
        "returns": null,
        "raw": "Audit a merge operation before it happens.\n\nThis function analyzes the keys used for merging and reports:\n- Key uniqueness on both sides\n- Expected match rate\n- Potential data loss from the merge\n\nArgs:\n    left_df: Left DataFrame for merge\n    right_df: Right DataFrame for merge\n    on: Column(s) to merge on\n    merge_name: Descriptive name for this merge (e.g., \"JDash_IPE_timing\")\n    debug_dir: Directory to write debug logs\n    how: Type of merge ('inner', 'left', 'right', 'outer')\n\nExample:\n    >>> audit_merge(jdash_df, ipe_df, on=['OrderId'], \n    ...             merge_name=\"Timing_Diff_Merge\", how=\"inner\")"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "__init__",
      "qualname": "FXConverter.__init__",
      "enclosing": [
        "FXConverter"
      ],
      "module": "src.utils.fx_utils",
      "file": "src\\utils\\fx_utils.py",
      "lineno": 24,
      "end_lineno": 60,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "cr05_df",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "default_rate",
          "kind": "positional_or_keyword",
          "annotation": "float",
          "default": "1.0"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Initialize the FX Converter with CR_05 FX rates data.",
        "returns": null,
        "raw": "Initialize the FX Converter with CR_05 FX rates data.\n\nArgs:\n    cr05_df: DataFrame from CR_05 containing columns:\n        - Company_Code: Company identifier\n        - FX_rate: Exchange rate (Local Currency / USD)\n    default_rate: Rate to use when company not found or rate is invalid.\n                 Default is 1.0 (assumes USD when no rate available).\n\nRaises:\n    ValueError: If cr05_df is None or missing required columns"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "convert_to_usd",
      "qualname": "FXConverter.convert_to_usd",
      "enclosing": [
        "FXConverter"
      ],
      "module": "src.utils.fx_utils",
      "file": "src\\utils\\fx_utils.py",
      "lineno": 62,
      "end_lineno": 107,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "amount",
          "kind": "positional_or_keyword",
          "annotation": "float",
          "default": null
        },
        {
          "name": "company_code",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "float",
      "doc": {
        "summary": "Convert a local currency amount to USD.",
        "returns": "Amount in USD. Returns 0.0 if input amount is None/NaN.\nReturns original amount if company_code not found (assumes rate=1).",
        "raw": "Convert a local currency amount to USD.\n\nFormula: Amount_USD = Amount_LCY / FX_rate\n\nArgs:\n    amount: Amount in local currency\n    company_code: Company code to look up the FX rate\n\nReturns:\n    Amount in USD. Returns 0.0 if input amount is None/NaN.\n    Returns original amount if company_code not found (assumes rate=1).\n\nExamples:\n    >>> converter = FXConverter(cr05_df)\n    >>> converter.convert_to_usd(1000.0, \"JD_GH\")  # If rate is 15.5\n    64.52\n    >>> converter.convert_to_usd(100.0, \"UNKNOWN\")  # Company not found\n    100.0\n    >>> converter.convert_to_usd(None, \"JD_GH\")\n    0.0"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "convert_series_to_usd",
      "qualname": "FXConverter.convert_series_to_usd",
      "enclosing": [
        "FXConverter"
      ],
      "module": "src.utils.fx_utils",
      "file": "src\\utils\\fx_utils.py",
      "lineno": 109,
      "end_lineno": 148,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "amount_series",
          "kind": "positional_or_keyword",
          "annotation": "pd.Series",
          "default": null
        },
        {
          "name": "company_code_series",
          "kind": "positional_or_keyword",
          "annotation": "pd.Series",
          "default": null
        }
      ],
      "return_annotation": "pd.Series",
      "doc": {
        "summary": "Convert a pandas Series of amounts to USD using corresponding company codes.",
        "returns": "Series of amounts in USD",
        "raw": "Convert a pandas Series of amounts to USD using corresponding company codes.\n\nThis is a vectorized helper for converting entire DataFrame columns.\n\nArgs:\n    amount_series: Series of amounts in local currency\n    company_code_series: Series of company codes (must have same index)\n\nReturns:\n    Series of amounts in USD\n\nExamples:\n    >>> amounts = pd.Series([1000, 2000, 3000])\n    >>> companies = pd.Series([\"JD_GH\", \"EC_NG\", \"EC_KE\"])\n    >>> converter.convert_series_to_usd(amounts, companies)\n    0    64.52\n    1   500.00\n    2   100.00\n    dtype: float64"
      }
    },
    {
      "kind": "class",
      "name": "FXConverter",
      "qualname": "FXConverter",
      "enclosing": [],
      "module": "src.utils.fx_utils",
      "file": "src\\utils\\fx_utils.py",
      "lineno": 12,
      "end_lineno": 148,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "FX Converter for converting local currency amounts to USD.",
        "raw": "FX Converter for converting local currency amounts to USD.\n\nUses monthly \"Closing\" rates extracted via CR_05 control report.\nThe conversion formula is: Amount_USD = Amount_LCY / FX_rate\n\nAttributes:\n    rates_dict (dict): Dictionary mapping Company_Code to FX_rate\n    default_rate (float): Default rate to use when company not found (1.0)"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "format",
      "qualname": "JsonFormatter.format",
      "enclosing": [
        "JsonFormatter"
      ],
      "module": "src.utils.logging",
      "file": "src\\utils\\logging.py",
      "lineno": 20,
      "end_lineno": 65,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "record",
          "kind": "positional_or_keyword",
          "annotation": "logging.LogRecord",
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "class",
      "name": "JsonFormatter",
      "qualname": "JsonFormatter",
      "enclosing": [],
      "module": "src.utils.logging",
      "file": "src\\utils\\logging.py",
      "lineno": 17,
      "end_lineno": 65,
      "decorators": [],
      "bases": [
        "logging.Formatter"
      ],
      "keywords": [],
      "doc": {
        "summary": "Simple JSON formatter without external dependencies.",
        "raw": "Simple JSON formatter without external dependencies."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "setup_json_logging",
      "qualname": "setup_json_logging",
      "enclosing": [],
      "module": "src.utils.logging",
      "file": "src\\utils\\logging.py",
      "lineno": 68,
      "end_lineno": 82,
      "decorators": [],
      "parameters": [
        {
          "name": "level",
          "kind": "positional_or_keyword",
          "annotation": "int",
          "default": "logging.INFO"
        }
      ],
      "return_annotation": "None",
      "doc": {
        "summary": "Configure root logger with JSON formatter once.",
        "returns": null,
        "raw": "Configure root logger with JSON formatter once."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "enrich",
      "qualname": "enrich",
      "enclosing": [],
      "module": "src.utils.logging",
      "file": "src\\utils\\logging.py",
      "lineno": 85,
      "end_lineno": 87,
      "decorators": [],
      "parameters": [
        {
          "name": "logger",
          "kind": "positional_or_keyword",
          "annotation": "logging.Logger",
          "default": null
        },
        {
          "name": "context",
          "kind": "kwarg",
          "annotation": "Any",
          "default": null
        }
      ],
      "return_annotation": "logging.LoggerAdapter",
      "doc": {
        "summary": "Return a LoggerAdapter that injects static context into each record.",
        "returns": null,
        "raw": "Return a LoggerAdapter that injects static context into each record."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "audit_merge",
      "qualname": "audit_merge",
      "enclosing": [],
      "module": "src.utils.merge_utils",
      "file": "src\\utils\\merge_utils.py",
      "lineno": 16,
      "end_lineno": 179,
      "decorators": [],
      "parameters": [
        {
          "name": "left",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "right",
          "kind": "positional_or_keyword",
          "annotation": "pd.DataFrame",
          "default": null
        },
        {
          "name": "on",
          "kind": "positional_or_keyword",
          "annotation": "Union[str, List[str]]",
          "default": null
        },
        {
          "name": "name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "out_dir",
          "kind": "positional_or_keyword",
          "annotation": "Union[str, Path]",
          "default": null
        }
      ],
      "return_annotation": "dict",
      "doc": {
        "summary": "Audit a DataFrame merge operation to detect potential Cartesian products.",
        "returns": "dict: Audit results containing:\n- left_duplicates: Number of duplicate keys in left DataFrame\n- right_duplicates: Number of duplicate keys in right DataFrame\n- left_duplicates: Number of duplicate key occurrences in the left DataFrame\n- right_duplicates: Number of duplicate key occurrences in the right DataFrame\n- left_total_rows: Total rows in the left DataFrame\n- right_total_rows: Total rows in the right DataFrame\n- has_duplicates: Boolean indicating if any duplicates were found in either DataFrame\n- left_unique_dup_keys: Number of distinct join-key combinations that are duplicated in the left DataFrame\n- right_unique_dup_keys: Number of distinct join-key combinations that are duplicated in the right DataFrame\n- left_dup_keys_file: Optional path (as str or Path) to a CSV file with duplicated join keys from the left DataFrame;\npresent only when left-side duplicates are found and export succeeds\n- right_dup_keys_file: Optional path (as str or Path) to a CSV file with duplicated join keys from the right DataFrame;\npresent only when right-side duplicates are found and export succeeds\n- left_duplicates_path: Optional path to CSV with left duplicate keys (or None)\n- right_duplicates_path: Optional path to CSV with right duplicate keys (or None)",
        "raw": "Audit a DataFrame merge operation to detect potential Cartesian products.\n\nThis function counts duplicates on the join keys in both left and right\ndataframes before performing the merge. If duplicates are found, it exports\nthe problematic keys to CSV files for inspection.\n\nArgs:\n    left: Left DataFrame for the merge\n    right: Right DataFrame for the merge\n    on: Column name(s) to join on. Can be a single string or list of strings\n    name: Name identifier for this merge operation (used in log messages and file names)\n    out_dir: Directory path where audit outputs will be saved\n    \nReturns:\n    dict: Audit results containing:\n        - left_duplicates: Number of duplicate keys in left DataFrame\n        - right_duplicates: Number of duplicate keys in right DataFrame\n        - left_duplicates: Number of duplicate key occurrences in the left DataFrame\n        - right_duplicates: Number of duplicate key occurrences in the right DataFrame\n        - left_total_rows: Total rows in the left DataFrame\n        - right_total_rows: Total rows in the right DataFrame\n        - has_duplicates: Boolean indicating if any duplicates were found in either DataFrame\n        - left_unique_dup_keys: Number of distinct join-key combinations that are duplicated in the left DataFrame\n        - right_unique_dup_keys: Number of distinct join-key combinations that are duplicated in the right DataFrame\n        - left_dup_keys_file: Optional path (as str or Path) to a CSV file with duplicated join keys from the left DataFrame;\n          present only when left-side duplicates are found and export succeeds\n        - right_dup_keys_file: Optional path (as str or Path) to a CSV file with duplicated join keys from the right DataFrame;\n          present only when right-side duplicates are found and export succeeds\n        - left_duplicates_path: Optional path to CSV with left duplicate keys (or None)\n        - right_duplicates_path: Optional path to CSV with right duplicate keys (or None)\n\nExample:\n    >>> left_df = pd.DataFrame({'id': [1, 1, 2], 'value': [10, 20, 30]})\n    >>> right_df = pd.DataFrame({'id': [1, 2, 2], 'amount': [100, 200, 300]})\n    >>> audit_merge(left_df, right_df, on='id', name='test_merge', out_dir='./output')\n    {\n    ...     'left_duplicates': 1,\n    ...     'right_duplicates': 1,\n    ...     'left_total_rows': 3,\n    ...     'right_total_rows': 3,\n    ...     'left_unique_dup_keys': 1,\n    ...     'right_unique_dup_keys': 1,\n    ...     'has_duplicates': True,\n    ...     'left_duplicates_path': '<out_dir>/test_merge_left_duplicates.csv',\n    ...     'right_duplicates_path': '<out_dir>/test_merge_right_duplicates.csv',\n    ... }"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "__init__",
      "qualname": "OktaAWSAuth.__init__",
      "enclosing": [
        "OktaAWSAuth"
      ],
      "module": "src.utils.okta_aws_auth",
      "file": "src\\utils\\okta_aws_auth.py",
      "lineno": 30,
      "end_lineno": 60,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "profile_name",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "region_name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": "'eu-west-1'"
        },
        {
          "name": "sso_start_url",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "sso_region",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "sso_account_id",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        },
        {
          "name": "sso_role_name",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Initialize Okta AWS authentication.",
        "returns": null,
        "raw": "Initialize Okta AWS authentication.\n\nArgs:\n    profile_name: AWS CLI profile name (e.g., 'jumia-sox-dev')\n    region_name: AWS region (default: 'eu-west-1')\n    sso_start_url: Okta SSO start URL\n    sso_region: SSO region (usually 'eu-west-1')\n    sso_account_id: AWS account ID\n    sso_role_name: AWS role name to assume"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "get_session",
      "qualname": "OktaAWSAuth.get_session",
      "enclosing": [
        "OktaAWSAuth"
      ],
      "module": "src.utils.okta_aws_auth",
      "file": "src\\utils\\okta_aws_auth.py",
      "lineno": 62,
      "end_lineno": 95,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "force_refresh",
          "kind": "positional_or_keyword",
          "annotation": "bool",
          "default": "False"
        }
      ],
      "return_annotation": "boto3.Session",
      "doc": {
        "summary": "Get an authenticated boto3 session.",
        "returns": "Authenticated boto3.Session",
        "raw": "Get an authenticated boto3 session.\n\nArgs:\n    force_refresh: Force credential refresh even if cached\n    \nReturns:\n    Authenticated boto3.Session"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "get_client",
      "qualname": "OktaAWSAuth.get_client",
      "enclosing": [
        "OktaAWSAuth"
      ],
      "module": "src.utils.okta_aws_auth",
      "file": "src\\utils\\okta_aws_auth.py",
      "lineno": 242,
      "end_lineno": 254,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "service_name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "kwargs",
          "kind": "kwarg",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Get an authenticated boto3 client.",
        "returns": "Authenticated boto3 client",
        "raw": "Get an authenticated boto3 client.\n\nArgs:\n    service_name: AWS service name (e.g., 's3', 'secretsmanager')\n    **kwargs: Additional arguments for client creation\n    \nReturns:\n    Authenticated boto3 client"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "get_credentials",
      "qualname": "OktaAWSAuth.get_credentials",
      "enclosing": [
        "OktaAWSAuth"
      ],
      "module": "src.utils.okta_aws_auth",
      "file": "src\\utils\\okta_aws_auth.py",
      "lineno": 256,
      "end_lineno": 271,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": "Dict[str, str]",
      "doc": {
        "summary": "Get AWS credentials as a dictionary.",
        "returns": "Dictionary with AWS credentials",
        "raw": "Get AWS credentials as a dictionary.\n\nReturns:\n    Dictionary with AWS credentials"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "assume_role",
      "qualname": "OktaAWSAuth.assume_role",
      "enclosing": [
        "OktaAWSAuth"
      ],
      "module": "src.utils.okta_aws_auth",
      "file": "src\\utils\\okta_aws_auth.py",
      "lineno": 273,
      "end_lineno": 309,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "role_arn",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "session_name",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "boto3.Session",
      "doc": {
        "summary": "Assume an AWS IAM role.",
        "returns": "New boto3.Session with assumed role credentials",
        "raw": "Assume an AWS IAM role.\n\nArgs:\n    role_arn: ARN of the role to assume\n    session_name: Optional session name\n    \nReturns:\n    New boto3.Session with assumed role credentials"
      }
    },
    {
      "kind": "class",
      "name": "OktaAWSAuth",
      "qualname": "OktaAWSAuth",
      "enclosing": [],
      "module": "src.utils.okta_aws_auth",
      "file": "src\\utils\\okta_aws_auth.py",
      "lineno": 20,
      "end_lineno": 309,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Manages AWS authentication through Okta SSO.",
        "raw": "Manages AWS authentication through Okta SSO.\n\nSupports multiple authentication methods:\n1. AWS SSO (preferred for Okta integration)\n2. Okta AWS CLI tool\n3. Session token caching for efficiency"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "setup_okta_profile",
      "qualname": "setup_okta_profile",
      "enclosing": [],
      "module": "src.utils.okta_aws_auth",
      "file": "src\\utils\\okta_aws_auth.py",
      "lineno": 312,
      "end_lineno": 353,
      "decorators": [],
      "parameters": [
        {
          "name": "profile_name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "sso_start_url",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "sso_region",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "account_id",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "role_name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Helper function to set up AWS SSO profile for Okta.",
        "returns": null,
        "raw": "Helper function to set up AWS SSO profile for Okta.\n\nArgs:\n    profile_name: Profile name (e.g., 'jumia-sox-prod')\n    sso_start_url: Okta SSO URL\n    sso_region: AWS region for SSO\n    account_id: AWS account ID\n    role_name: IAM role name"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_bank_posting_group",
      "qualname": "get_bank_posting_group",
      "enclosing": [],
      "module": "src.utils.sql_enrichment",
      "file": "src\\utils\\sql_enrichment.py",
      "lineno": 13,
      "end_lineno": 34,
      "decorators": [],
      "parameters": [
        {
          "name": "conn",
          "kind": "positional_or_keyword",
          "annotation": "pyodbc.Connection",
          "default": null
        },
        {
          "name": "service_provider_no",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "id_company",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": "None"
        }
      ],
      "return_annotation": "Optional[str]",
      "doc": {
        "summary": "Return the Bank Account Posting Group code for a given Service Provider No_.",
        "returns": null,
        "raw": "Return the Bank Account Posting Group code for a given Service Provider No_.\n\nIf multiple matches, returns an arbitrary first; callers may need to disambiguate by company."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_refund_channel",
      "qualname": "get_refund_channel",
      "enclosing": [],
      "module": "src.utils.sql_enrichment",
      "file": "src\\utils\\sql_enrichment.py",
      "lineno": 37,
      "end_lineno": 52,
      "decorators": [],
      "parameters": [
        {
          "name": "conn",
          "kind": "positional_or_keyword",
          "annotation": "pyodbc.Connection",
          "default": null
        },
        {
          "name": "order_nr",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "Optional[str]",
      "doc": {
        "summary": "Return refund channel for an order (e.g., 'Retail' or 'MPL'), derived from OMS records.",
        "returns": null,
        "raw": "Return refund channel for an order (e.g., 'Retail' or 'MPL'), derived from OMS records.\n\nThis is a stub: adapt the FROM/WHERE to the canonical OMS source used for refunds."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "render_sql",
      "qualname": "render_sql",
      "enclosing": [],
      "module": "src.utils.sql_template",
      "file": "src\\utils\\sql_template.py",
      "lineno": 21,
      "end_lineno": 46,
      "decorators": [],
      "parameters": [
        {
          "name": "sql",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "params",
          "kind": "positional_or_keyword",
          "annotation": "Dict[str, Any] | None",
          "default": "None"
        },
        {
          "name": "strict",
          "kind": "kwonly",
          "annotation": "bool",
          "default": "True"
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": "Render SQL template with params and optionally enforce all placeholders are resolved.",
        "returns": "Rendered SQL string",
        "raw": "Render SQL template with params and optionally enforce all placeholders are resolved.\n\nArgs:\n    sql: SQL string with placeholders like {name}\n    params: Mapping of placeholder names to values (converted to str via format)\n    strict: When True (default), raise ValueError if any placeholders remain unresolved\n\nReturns:\n    Rendered SQL string"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_git_commit_hash",
      "qualname": "get_git_commit_hash",
      "enclosing": [],
      "module": "src.utils.system_utils",
      "file": "src\\utils\\system_utils.py",
      "lineno": 15,
      "end_lineno": 35,
      "decorators": [],
      "parameters": [],
      "return_annotation": "str",
      "doc": {
        "summary": "Retrieves the current Git commit hash (short version).",
        "returns": "Short Git commit hash (7 characters) or 'unknown' if not in a git repository",
        "raw": "Retrieves the current Git commit hash (short version).\n\nReturns:\n    Short Git commit hash (7 characters) or 'unknown' if not in a git repository"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_execution_host",
      "qualname": "get_execution_host",
      "enclosing": [],
      "module": "src.utils.system_utils",
      "file": "src\\utils\\system_utils.py",
      "lineno": 38,
      "end_lineno": 50,
      "decorators": [],
      "parameters": [],
      "return_annotation": "str",
      "doc": {
        "summary": "Retrieves the hostname of the machine running the script.",
        "returns": "Hostname of the execution machine",
        "raw": "Retrieves the hostname of the machine running the script.\n\nReturns:\n    Hostname of the execution machine"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_python_version",
      "qualname": "get_python_version",
      "enclosing": [],
      "module": "src.utils.system_utils",
      "file": "src\\utils\\system_utils.py",
      "lineno": 53,
      "end_lineno": 60,
      "decorators": [],
      "parameters": [],
      "return_annotation": "str",
      "doc": {
        "summary": "Retrieves the Python version.",
        "returns": "Python version string",
        "raw": "Retrieves the Python version.\n\nReturns:\n    Python version string"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_system_context",
      "qualname": "get_system_context",
      "enclosing": [],
      "module": "src.utils.system_utils",
      "file": "src\\utils\\system_utils.py",
      "lineno": 63,
      "end_lineno": 75,
      "decorators": [],
      "parameters": [],
      "return_annotation": "Dict[str, Any]",
      "doc": {
        "summary": "Retrieves comprehensive system context information.",
        "returns": "Dictionary containing git commit, hostname, Python version, and runner version",
        "raw": "Retrieves comprehensive system context information.\n\nReturns:\n    Dictionary containing git commit, hostname, Python version, and runner version"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "pytest_collection_modifyitems",
      "qualname": "pytest_collection_modifyitems",
      "enclosing": [],
      "module": "tests.conftest",
      "file": "tests\\conftest.py",
      "lineno": 4,
      "end_lineno": 12,
      "decorators": [],
      "parameters": [
        {
          "name": "config",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "items",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_import",
      "qualname": "test_import",
      "enclosing": [],
      "module": "tests.test_audit_merge_smoke",
      "file": "tests\\test_audit_merge_smoke.py",
      "lineno": 19,
      "end_lineno": 24,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that audit_merge can be imported.",
        "returns": null,
        "raw": "Test that audit_merge can be imported."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_basic_functionality",
      "qualname": "test_basic_functionality",
      "enclosing": [],
      "module": "tests.test_audit_merge_smoke",
      "file": "tests\\test_audit_merge_smoke.py",
      "lineno": 27,
      "end_lineno": 67,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test basic audit_merge functionality.",
        "returns": null,
        "raw": "Test basic audit_merge functionality."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_duplicate_detection",
      "qualname": "test_duplicate_detection",
      "enclosing": [],
      "module": "tests.test_audit_merge_smoke",
      "file": "tests\\test_audit_merge_smoke.py",
      "lineno": 70,
      "end_lineno": 101,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that duplicates are detected correctly.",
        "returns": null,
        "raw": "Test that duplicates are detected correctly."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_rules_loading",
      "qualname": "test_rules_loading",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 21,
      "end_lineno": 26,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_classify_simple_matches",
      "qualname": "test_classify_simple_matches",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 29,
      "end_lineno": 42,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_customer_posting_group_bridge_empty_input",
      "qualname": "test_customer_posting_group_bridge_empty_input",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 45,
      "end_lineno": 56,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test with empty DataFrame",
        "returns": null,
        "raw": "Test with empty DataFrame"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_customer_posting_group_bridge_none_input",
      "qualname": "test_customer_posting_group_bridge_none_input",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 59,
      "end_lineno": 69,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test with None input",
        "returns": null,
        "raw": "Test with None input"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_customer_posting_group_bridge_missing_columns",
      "qualname": "test_customer_posting_group_bridge_missing_columns",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 72,
      "end_lineno": 83,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that missing required columns raise ValueError",
        "returns": null,
        "raw": "Test that missing required columns raise ValueError"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_customer_posting_group_bridge_single_posting_group",
      "qualname": "test_customer_posting_group_bridge_single_posting_group",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 86,
      "end_lineno": 99,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test customers with only one posting group - should return empty",
        "returns": null,
        "raw": "Test customers with only one posting group - should return empty"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_customer_posting_group_bridge_multiple_posting_groups",
      "qualname": "test_customer_posting_group_bridge_multiple_posting_groups",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 102,
      "end_lineno": 134,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test customers with multiple posting groups - should identify them",
        "returns": null,
        "raw": "Test customers with multiple posting groups - should identify them"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_customer_posting_group_bridge_multiple_problem_customers",
      "qualname": "test_customer_posting_group_bridge_multiple_problem_customers",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 137,
      "end_lineno": 177,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test multiple customers with posting group issues",
        "returns": null,
        "raw": "Test multiple customers with posting group issues"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_customer_posting_group_bridge_with_null_values",
      "qualname": "test_customer_posting_group_bridge_with_null_values",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 180,
      "end_lineno": 194,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test handling of NULL/NaN values in posting groups",
        "returns": null,
        "raw": "Test handling of NULL/NaN values in posting groups"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_customer_posting_group_bridge_output_format",
      "qualname": "test_customer_posting_group_bridge_output_format",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 197,
      "end_lineno": 217,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that output DataFrame has the correct format",
        "returns": null,
        "raw": "Test that output DataFrame has the correct format"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_basic",
      "qualname": "test_calculate_vtc_adjustment_basic",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 220,
      "end_lineno": 262,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test basic VTC adjustment calculation with unmatched vouchers.",
        "returns": null,
        "raw": "Test basic VTC adjustment calculation with unmatched vouchers."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_all_matched",
      "qualname": "test_calculate_vtc_adjustment_all_matched",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 265,
      "end_lineno": 289,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment when all vouchers are matched in NAV.",
        "returns": null,
        "raw": "Test VTC adjustment when all vouchers are matched in NAV."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_vtc_manual",
      "qualname": "test_calculate_vtc_adjustment_vtc_manual",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 292,
      "end_lineno": 325,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment recognizes 'VTC Manual' category.",
        "returns": null,
        "raw": "Test VTC adjustment recognizes 'VTC Manual' category."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_vtc_category",
      "qualname": "test_calculate_vtc_adjustment_vtc_category",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 328,
      "end_lineno": 361,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment recognizes 'VTC' category (new categorization).",
        "returns": null,
        "raw": "Test VTC adjustment recognizes 'VTC' category (new categorization)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_empty_nav",
      "qualname": "test_calculate_vtc_adjustment_empty_nav",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 364,
      "end_lineno": 392,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment with empty NAV data (all vouchers unmatched).",
        "returns": null,
        "raw": "Test VTC adjustment with empty NAV data (all vouchers unmatched)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_empty_bob",
      "qualname": "test_calculate_vtc_adjustment_empty_bob",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 395,
      "end_lineno": 409,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment with empty BOB data.",
        "returns": null,
        "raw": "Test VTC adjustment with empty BOB data."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_filters",
      "qualname": "test_calculate_vtc_adjustment_filters",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 412,
      "end_lineno": 467,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that VTC adjustment filters work correctly.",
        "returns": null,
        "raw": "Test that VTC adjustment filters work correctly."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_non_cancellation_categories",
      "qualname": "test_calculate_vtc_adjustment_non_cancellation_categories",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 470,
      "end_lineno": 506,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that non-cancellation categories in NAV don't count as matches.",
        "returns": null,
        "raw": "Test that non-cancellation categories in NAV don't count as matches."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_with_date_filter_within_month",
      "qualname": "test_calculate_vtc_adjustment_with_date_filter_within_month",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 509,
      "end_lineno": 552,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment with date filter - vouchers within reconciliation month.",
        "returns": null,
        "raw": "Test VTC adjustment with date filter - vouchers within reconciliation month."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_with_date_filter_outside_month",
      "qualname": "test_calculate_vtc_adjustment_with_date_filter_outside_month",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 555,
      "end_lineno": 587,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment with date filter - all vouchers outside reconciliation month.",
        "returns": null,
        "raw": "Test VTC adjustment with date filter - all vouchers outside reconciliation month."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_with_date_filter_month_boundaries",
      "qualname": "test_calculate_vtc_adjustment_with_date_filter_month_boundaries",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 590,
      "end_lineno": 639,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment with date filter - test month boundary cases.",
        "returns": null,
        "raw": "Test VTC adjustment with date filter - test month boundary cases."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_without_date_filter",
      "qualname": "test_calculate_vtc_adjustment_without_date_filter",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 642,
      "end_lineno": 672,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment without date filter - should include all vouchers (backward compatibility).",
        "returns": null,
        "raw": "Test VTC adjustment without date filter - should include all vouchers (backward compatibility)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_with_date_filter_no_inactive_at_column",
      "qualname": "test_calculate_vtc_adjustment_with_date_filter_no_inactive_at_column",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 675,
      "end_lineno": 708,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment with date filter when inactive_at column is missing.",
        "returns": null,
        "raw": "Test VTC adjustment with date filter when inactive_at column is missing."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_with_date_filter_december",
      "qualname": "test_calculate_vtc_adjustment_with_date_filter_december",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 711,
      "end_lineno": 744,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment with date filter - December edge case (year boundary).",
        "returns": null,
        "raw": "Test VTC adjustment with date filter - December edge case (year boundary)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_empty_df",
      "qualname": "test_categorize_nav_vouchers_empty_df",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 747,
      "end_lineno": 754,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that empty DataFrames are handled correctly.",
        "returns": null,
        "raw": "Test that empty DataFrames are handled correctly."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_none_df",
      "qualname": "test_categorize_nav_vouchers_none_df",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 757,
      "end_lineno": 764,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that None input is handled correctly.",
        "returns": null,
        "raw": "Test that None input is handled correctly."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step1_integration_type",
      "qualname": "test_categorize_nav_vouchers_step1_integration_type",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 772,
      "end_lineno": 809,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 1: Integration_Type detection (Manual vs Integration).",
        "returns": null,
        "raw": "Test Step 1: Integration_Type detection (Manual vs Integration).\n\nNew strict logic: Only User ID == \"JUMIA/NAV31AFR.BATCH.SRVC\" is Integration."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step2_issuance_integrated_refund",
      "qualname": "test_categorize_nav_vouchers_step2_issuance_integrated_refund",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 817,
      "end_lineno": 832,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 2: Integrated Issuance - Refund (description contains 'Refund').",
        "returns": null,
        "raw": "Test Step 2: Integrated Issuance - Refund (description contains 'Refund')."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step2_issuance_integrated_apology",
      "qualname": "test_categorize_nav_vouchers_step2_issuance_integrated_apology",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 835,
      "end_lineno": 850,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 2: Integrated Issuance - Apology (COMMERCIAL GESTURE).",
        "returns": null,
        "raw": "Test Step 2: Integrated Issuance - Apology (COMMERCIAL GESTURE)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step2_issuance_integrated_jforce",
      "qualname": "test_categorize_nav_vouchers_step2_issuance_integrated_jforce",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 853,
      "end_lineno": 867,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 2: Integrated Issuance - JForce (PYT_PF).",
        "returns": null,
        "raw": "Test Step 2: Integrated Issuance - JForce (PYT_PF)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step2_issuance_manual_store_credit",
      "qualname": "test_categorize_nav_vouchers_step2_issuance_manual_store_credit",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 870,
      "end_lineno": 895,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 2: Manual Issuance - Store Credit (Doc No starts with country code).",
        "returns": null,
        "raw": "Test Step 2: Manual Issuance - Store Credit (Doc No starts with country code)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step2_issuance_manual_refund",
      "qualname": "test_categorize_nav_vouchers_step2_issuance_manual_refund",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 898,
      "end_lineno": 914,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 2: Manual Issuance - Refund.",
        "returns": null,
        "raw": "Test Step 2: Manual Issuance - Refund."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step2_issuance_generic",
      "qualname": "test_categorize_nav_vouchers_step2_issuance_generic",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 917,
      "end_lineno": 932,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 2: Generic Issuance when no sub-category matches.",
        "returns": null,
        "raw": "Test Step 2: Generic Issuance when no sub-category matches."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step3_usage_integrated",
      "qualname": "test_categorize_nav_vouchers_step3_usage_integrated",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 940,
      "end_lineno": 962,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 3: Usage - Integrated transactions.",
        "returns": null,
        "raw": "Test Step 3: Usage - Integrated transactions."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step3_cancellation_apology_voucher_accrual",
      "qualname": "test_categorize_nav_vouchers_step3_cancellation_apology_voucher_accrual",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 965,
      "end_lineno": 979,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 3: Cancellation - Apology (Voucher Accrual description).",
        "returns": null,
        "raw": "Test Step 3: Cancellation - Apology (Voucher Accrual description)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step3_usage_with_voucher_lookup",
      "qualname": "test_categorize_nav_vouchers_step3_usage_with_voucher_lookup",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 982,
      "end_lineno": 1003,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 3: Usage with voucher type lookup from IPE_08.",
        "returns": null,
        "raw": "Test Step 3: Usage with voucher type lookup from IPE_08."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step3_usage_fallback_doc_no",
      "qualname": "test_categorize_nav_vouchers_step3_usage_fallback_doc_no",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1006,
      "end_lineno": 1029,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 3: Usage with fallback lookup via Document No to Transaction_No.",
        "returns": null,
        "raw": "Test Step 3: Usage with fallback lookup via Document No to Transaction_No."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step4_expired_apology",
      "qualname": "test_categorize_nav_vouchers_step4_expired_apology",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1037,
      "end_lineno": 1052,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 4: Expired - Apology (EXPR_APLGY).",
        "returns": null,
        "raw": "Test Step 4: Expired - Apology (EXPR_APLGY)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step4_expired_refund",
      "qualname": "test_categorize_nav_vouchers_step4_expired_refund",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1055,
      "end_lineno": 1069,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 4: Expired - Refund (EXPR_JFORCE).",
        "returns": null,
        "raw": "Test Step 4: Expired - Refund (EXPR_JFORCE)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step4_expired_store_credit",
      "qualname": "test_categorize_nav_vouchers_step4_expired_store_credit",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1072,
      "end_lineno": 1093,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 4: Expired - Store Credit (EXPR_STR CRDT).",
        "returns": null,
        "raw": "Test Step 4: Expired - Store Credit (EXPR_STR CRDT)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step4_expired_generic",
      "qualname": "test_categorize_nav_vouchers_step4_expired_generic",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1096,
      "end_lineno": 1109,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 4: Generic Expired (EXPR without sub-type).",
        "returns": null,
        "raw": "Test Step 4: Generic Expired (EXPR without sub-type)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step5_vtc_manual_rnd",
      "qualname": "test_categorize_nav_vouchers_step5_vtc_manual_rnd",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1117,
      "end_lineno": 1132,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 5: VTC - Manual RND.",
        "returns": null,
        "raw": "Test Step 5: VTC - Manual RND."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step5_vtc_pyt_gtb",
      "qualname": "test_categorize_nav_vouchers_step5_vtc_pyt_gtb",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1135,
      "end_lineno": 1150,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 5: VTC - PYT_ with GTB in Comment.",
        "returns": null,
        "raw": "Test Step 5: VTC - PYT_ with GTB in Comment."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step6_manual_cancellation",
      "qualname": "test_categorize_nav_vouchers_step6_manual_cancellation",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1158,
      "end_lineno": 1174,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 6: Manual Cancellation - Store Credit via Credit Memo.",
        "returns": null,
        "raw": "Test Step 6: Manual Cancellation - Store Credit via Credit Memo."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step7_manual_usage_itempricecredit",
      "qualname": "test_categorize_nav_vouchers_step7_manual_usage_itempricecredit",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1182,
      "end_lineno": 1196,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 7: Manual Usage - ITEMPRICECREDIT (Nigeria exception).",
        "returns": null,
        "raw": "Test Step 7: Manual Usage - ITEMPRICECREDIT (Nigeria exception)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_step7_manual_usage_with_voucher_lookup",
      "qualname": "test_categorize_nav_vouchers_step7_manual_usage_with_voucher_lookup",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1199,
      "end_lineno": 1219,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test Step 7: Manual Usage with voucher type lookup.",
        "returns": null,
        "raw": "Test Step 7: Manual Usage with voucher type lookup."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_non_18412_account",
      "qualname": "test_categorize_nav_vouchers_non_18412_account",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1227,
      "end_lineno": 1245,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that non-18412 accounts are not categorized.",
        "returns": null,
        "raw": "Test that non-18412 accounts are not categorized."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_mixed_scenarios",
      "qualname": "test_categorize_nav_vouchers_mixed_scenarios",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1248,
      "end_lineno": 1297,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test a mix of different categorization rules.",
        "returns": null,
        "raw": "Test a mix of different categorization rules."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_case_insensitivity",
      "qualname": "test_categorize_nav_vouchers_case_insensitivity",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1300,
      "end_lineno": 1320,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that categorization is case-insensitive.",
        "returns": null,
        "raw": "Test that categorization is case-insensitive."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_returns_enriched_columns",
      "qualname": "test_categorize_nav_vouchers_returns_enriched_columns",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1323,
      "end_lineno": 1338,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that the function returns all three required columns.",
        "returns": null,
        "raw": "Test that the function returns all three required columns."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_basic",
      "qualname": "test_calculate_timing_difference_bridge_basic",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1346,
      "end_lineno": 1387,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test basic timing difference bridge comparing Jdash vs IPE_08 amounts.",
        "returns": null,
        "raw": "Test basic timing difference bridge comparing Jdash vs IPE_08 amounts."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_empty_ipe08_input",
      "qualname": "test_calculate_timing_difference_bridge_empty_ipe08_input",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1390,
      "end_lineno": 1404,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test with empty IPE_08 DataFrame.",
        "returns": null,
        "raw": "Test with empty IPE_08 DataFrame."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_none_ipe08_input",
      "qualname": "test_calculate_timing_difference_bridge_none_ipe08_input",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1407,
      "end_lineno": 1420,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test with None IPE_08 input.",
        "returns": null,
        "raw": "Test with None IPE_08 input."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_empty_jdash",
      "qualname": "test_calculate_timing_difference_bridge_empty_jdash",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1423,
      "end_lineno": 1454,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test with empty Jdash DataFrame - all IPE amounts become negative variance.",
        "returns": null,
        "raw": "Test with empty Jdash DataFrame - all IPE amounts become negative variance."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_filter_active_vouchers",
      "qualname": "test_calculate_timing_difference_bridge_filter_active_vouchers",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1457,
      "end_lineno": 1493,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that only inactive vouchers (is_active == 0) are included.",
        "returns": null,
        "raw": "Test that only inactive vouchers (is_active == 0) are included."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_filter_non_marketing",
      "qualname": "test_calculate_timing_difference_bridge_filter_non_marketing",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1496,
      "end_lineno": 1542,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that only non-marketing vouchers are included.",
        "returns": null,
        "raw": "Test that only non-marketing vouchers are included."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_filter_one_year",
      "qualname": "test_calculate_timing_difference_bridge_filter_one_year",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1545,
      "end_lineno": 1591,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that only vouchers created within 1 year of cutoff are included.",
        "returns": null,
        "raw": "Test that only vouchers created within 1 year of cutoff are included."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_jdash_aggregation",
      "qualname": "test_calculate_timing_difference_bridge_jdash_aggregation",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1594,
      "end_lineno": 1624,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that Jdash amounts are aggregated by Voucher Id.",
        "returns": null,
        "raw": "Test that Jdash amounts are aggregated by Voucher Id."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_unmatched_vouchers",
      "qualname": "test_calculate_timing_difference_bridge_unmatched_vouchers",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1627,
      "end_lineno": 1663,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test vouchers in IPE_08 without matching Jdash entries get 0 Jdash amount.",
        "returns": null,
        "raw": "Test vouchers in IPE_08 without matching Jdash entries get 0 Jdash amount."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_all_non_marketing_types",
      "qualname": "test_calculate_timing_difference_bridge_all_non_marketing_types",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1666,
      "end_lineno": 1724,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that all non-marketing types are included.",
        "returns": null,
        "raw": "Test that all non-marketing types are included."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_output_format",
      "qualname": "test_calculate_timing_difference_bridge_output_format",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1727,
      "end_lineno": 1758,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that output DataFrame has the correct columns.",
        "returns": null,
        "raw": "Test that output DataFrame has the correct columns."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_comprehensive",
      "qualname": "test_calculate_timing_difference_bridge_comprehensive",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1761,
      "end_lineno": 1835,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test comprehensive scenario with multiple filters and reconciliation cases.",
        "returns": null,
        "raw": "Test comprehensive scenario with multiple filters and reconciliation cases."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_column_priority",
      "qualname": "test_calculate_timing_difference_bridge_column_priority",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1838,
      "end_lineno": 1870,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that the function prioritizes 'Total Amount Used' over 'Remaining Amount'.",
        "returns": null,
        "raw": "Test that the function prioritizes 'Total Amount Used' over 'Remaining Amount'."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_missing_total_amount_used",
      "qualname": "test_calculate_timing_difference_bridge_missing_total_amount_used",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1873,
      "end_lineno": 1901,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that function returns empty when 'Total Amount Used' column is missing.",
        "returns": null,
        "raw": "Test that function returns empty when 'Total Amount Used' column is missing."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_production_integration_user_nav13",
      "qualname": "test_categorize_nav_vouchers_production_integration_user_nav13",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1909,
      "end_lineno": 1924,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test production data pattern: JUMIA\\NAV31AFR.BATCH.SRVC as Integration user.",
        "returns": null,
        "raw": "Test production data pattern: JUMIA\\NAV31AFR.BATCH.SRVC as Integration user."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_production_rf_prefix_pattern",
      "qualname": "test_categorize_nav_vouchers_production_rf_prefix_pattern",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1927,
      "end_lineno": 1941,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test production data pattern: RF_317... description for refunds.",
        "returns": null,
        "raw": "Test production data pattern: RF_317... description for refunds."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_production_vtc_bank_account_negative",
      "qualname": "test_categorize_nav_vouchers_production_vtc_bank_account_negative",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1944,
      "end_lineno": 1960,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test production data pattern: VTC via Bank Account with negative amount should be Issuance.",
        "returns": null,
        "raw": "Test production data pattern: VTC via Bank Account with negative amount should be Issuance."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_production_vtc_bank_account_positive",
      "qualname": "test_categorize_nav_vouchers_production_vtc_bank_account_positive",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1963,
      "end_lineno": 1979,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test production data pattern: VTC via Bank Account with positive amount.",
        "returns": null,
        "raw": "Test production data pattern: VTC via Bank Account with positive amount."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_production_pyt_jforce",
      "qualname": "test_categorize_nav_vouchers_production_pyt_jforce",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1982,
      "end_lineno": 1996,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test production data pattern: PYT_ pattern for JForce.",
        "returns": null,
        "raw": "Test production data pattern: PYT_ pattern for JForce."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_production_case_insensitivity",
      "qualname": "test_categorize_nav_vouchers_production_case_insensitivity",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 1999,
      "end_lineno": 2013,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test production data pattern: Case insensitivity for all inputs.",
        "returns": null,
        "raw": "Test production data pattern: Case insensitivity for all inputs."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_production_combined_scenario",
      "qualname": "test_categorize_nav_vouchers_production_combined_scenario",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 2016,
      "end_lineno": 2067,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test production data patterns: Combined scenario with multiple row types.",
        "returns": null,
        "raw": "Test production data patterns: Combined scenario with multiple row types."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_categorize_nav_vouchers_production_rf_space_pattern",
      "qualname": "test_categorize_nav_vouchers_production_rf_space_pattern",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 2070,
      "end_lineno": 2084,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test production data pattern: RF with space (RF ) pattern for refunds.",
        "returns": null,
        "raw": "Test production data pattern: RF with space (RF ) pattern for refunds."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_filter_ipe08_scope_basic",
      "qualname": "test_filter_ipe08_scope_basic",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 2092,
      "end_lineno": 2125,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test basic filtering of IPE_08 with non-marketing vouchers.",
        "returns": null,
        "raw": "Test basic filtering of IPE_08 with non-marketing vouchers."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_filter_ipe08_scope_all_non_marketing_types",
      "qualname": "test_filter_ipe08_scope_all_non_marketing_types",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 2128,
      "end_lineno": 2150,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that all non-marketing types are retained.",
        "returns": null,
        "raw": "Test that all non-marketing types are retained."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_filter_ipe08_scope_date_conversion",
      "qualname": "test_filter_ipe08_scope_date_conversion",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 2153,
      "end_lineno": 2175,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that date columns are converted to datetime.",
        "returns": null,
        "raw": "Test that date columns are converted to datetime."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_filter_ipe08_scope_empty_input",
      "qualname": "test_filter_ipe08_scope_empty_input",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 2178,
      "end_lineno": 2185,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that empty DataFrame is handled correctly.",
        "returns": null,
        "raw": "Test that empty DataFrame is handled correctly."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_filter_ipe08_scope_none_input",
      "qualname": "test_filter_ipe08_scope_none_input",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 2188,
      "end_lineno": 2194,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that None input is handled correctly.",
        "returns": null,
        "raw": "Test that None input is handled correctly."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_filter_ipe08_scope_missing_business_use_column",
      "qualname": "test_filter_ipe08_scope_missing_business_use_column",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 2197,
      "end_lineno": 2211,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test handling when business_use column is missing.",
        "returns": null,
        "raw": "Test handling when business_use column is missing."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_filter_ipe08_scope_date_columns_missing",
      "qualname": "test_filter_ipe08_scope_date_columns_missing",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 2214,
      "end_lineno": 2228,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that missing date columns don't cause errors.",
        "returns": null,
        "raw": "Test that missing date columns don't cause errors."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_filter_ipe08_scope_preserves_other_columns",
      "qualname": "test_filter_ipe08_scope_preserves_other_columns",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 2231,
      "end_lineno": 2262,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that other columns are preserved after filtering.",
        "returns": null,
        "raw": "Test that other columns are preserved after filtering."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_filter_ipe08_scope_business_use_formatted_column",
      "qualname": "test_filter_ipe08_scope_business_use_formatted_column",
      "enclosing": [],
      "module": "tests.test_bridges_classifier",
      "file": "tests\\test_bridges_classifier.py",
      "lineno": 2265,
      "end_lineno": 2295,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that business_use_formatted column is also supported for backward compatibility.",
        "returns": null,
        "raw": "Test that business_use_formatted column is also supported for backward compatibility."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_cr_04_quality_rules",
      "qualname": "test_cr_04_quality_rules",
      "enclosing": [],
      "module": "tests.test_catalog_quality_rules",
      "file": "tests\\test_catalog_quality_rules.py",
      "lineno": 20,
      "end_lineno": 36,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test CR_04 (GL Balances) has correct quality rules.",
        "returns": null,
        "raw": "Test CR_04 (GL Balances) has correct quality rules."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_cr_03_quality_rules",
      "qualname": "test_cr_03_quality_rules",
      "enclosing": [],
      "module": "tests.test_catalog_quality_rules",
      "file": "tests\\test_catalog_quality_rules.py",
      "lineno": 39,
      "end_lineno": 54,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test CR_03 (GL Entries) has correct quality rules.",
        "returns": null,
        "raw": "Test CR_03 (GL Entries) has correct quality rules."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_ipe_08_quality_rules",
      "qualname": "test_ipe_08_quality_rules",
      "enclosing": [],
      "module": "tests.test_catalog_quality_rules",
      "file": "tests\\test_catalog_quality_rules.py",
      "lineno": 57,
      "end_lineno": 72,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test IPE_08 (Voucher Issuance) has correct quality rules.",
        "returns": null,
        "raw": "Test IPE_08 (Voucher Issuance) has correct quality rules."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_doc_voucher_usage_quality_rules",
      "qualname": "test_doc_voucher_usage_quality_rules",
      "enclosing": [],
      "module": "tests.test_catalog_quality_rules",
      "file": "tests\\test_catalog_quality_rules.py",
      "lineno": 75,
      "end_lineno": 87,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test DOC_VOUCHER_USAGE (Voucher Usage TV) has correct quality rules.",
        "returns": null,
        "raw": "Test DOC_VOUCHER_USAGE (Voucher Usage TV) has correct quality rules."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_ipe_07_quality_rules",
      "qualname": "test_ipe_07_quality_rules",
      "enclosing": [],
      "module": "tests.test_catalog_quality_rules",
      "file": "tests\\test_catalog_quality_rules.py",
      "lineno": 90,
      "end_lineno": 105,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test IPE_07 (Customer Ledger) has correct quality rules.",
        "returns": null,
        "raw": "Test IPE_07 (Customer Ledger) has correct quality rules."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_ipe_rec_errors_quality_rules",
      "qualname": "test_ipe_rec_errors_quality_rules",
      "enclosing": [],
      "module": "tests.test_catalog_quality_rules",
      "file": "tests\\test_catalog_quality_rules.py",
      "lineno": 108,
      "end_lineno": 126,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test IPE_REC_ERRORS (Integration Errors) has correct quality rules.",
        "returns": null,
        "raw": "Test IPE_REC_ERRORS (Integration Errors) has correct quality rules."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_all_configured_items_have_rules",
      "qualname": "test_all_configured_items_have_rules",
      "enclosing": [],
      "module": "tests.test_catalog_quality_rules",
      "file": "tests\\test_catalog_quality_rules.py",
      "lineno": 129,
      "end_lineno": 136,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that all specified items have quality rules configured.",
        "returns": null,
        "raw": "Test that all specified items have quality rules configured."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_empty_dataframe",
      "qualname": "TestClassifyIntegrationType.test_empty_dataframe",
      "enclosing": [
        "TestClassifyIntegrationType"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 40,
      "end_lineno": 45,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with empty DataFrame.",
        "returns": null,
        "raw": "Test with empty DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_none_dataframe",
      "qualname": "TestClassifyIntegrationType.test_none_dataframe",
      "enclosing": [
        "TestClassifyIntegrationType"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 47,
      "end_lineno": 52,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with None input.",
        "returns": null,
        "raw": "Test with None input."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_integration_user_nav_batch_srvc",
      "qualname": "TestClassifyIntegrationType.test_integration_user_nav_batch_srvc",
      "enclosing": [
        "TestClassifyIntegrationType"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 54,
      "end_lineno": 60,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that JUMIA/NAV*.BATCH.SRVC is detected as Integration.",
        "returns": null,
        "raw": "Test that JUMIA/NAV*.BATCH.SRVC is detected as Integration."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_integration_user_nav13",
      "qualname": "TestClassifyIntegrationType.test_integration_user_nav13",
      "enclosing": [
        "TestClassifyIntegrationType"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 62,
      "end_lineno": 68,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that NAV13AFR.BATCH.SRVC is Manual (only JUMIA/NAV31AFR.BATCH.SRVC is Integration).",
        "returns": null,
        "raw": "Test that NAV13AFR.BATCH.SRVC is Manual (only JUMIA/NAV31AFR.BATCH.SRVC is Integration)."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_manual_user_nav_without_batch_srvc",
      "qualname": "TestClassifyIntegrationType.test_manual_user_nav_without_batch_srvc",
      "enclosing": [
        "TestClassifyIntegrationType"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 70,
      "end_lineno": 76,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that NAV without BATCH/SRVC is Manual.",
        "returns": null,
        "raw": "Test that NAV without BATCH/SRVC is Manual."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_manual_user_regular",
      "qualname": "TestClassifyIntegrationType.test_manual_user_regular",
      "enclosing": [
        "TestClassifyIntegrationType"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 78,
      "end_lineno": 84,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that regular user is Manual.",
        "returns": null,
        "raw": "Test that regular user is Manual."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_case_insensitivity",
      "qualname": "TestClassifyIntegrationType.test_case_insensitivity",
      "enclosing": [
        "TestClassifyIntegrationType"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 86,
      "end_lineno": 92,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test case insensitivity for user ID detection.",
        "returns": null,
        "raw": "Test case insensitivity for user ID detection."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_backslash_separator",
      "qualname": "TestClassifyIntegrationType.test_backslash_separator",
      "enclosing": [
        "TestClassifyIntegrationType"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 94,
      "end_lineno": 100,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that backslash separator is normalized to forward slash.",
        "returns": null,
        "raw": "Test that backslash separator is normalized to forward slash."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_backslash_separator_lowercase",
      "qualname": "TestClassifyIntegrationType.test_backslash_separator_lowercase",
      "enclosing": [
        "TestClassifyIntegrationType"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 102,
      "end_lineno": 108,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test backslash separator with lowercase.",
        "returns": null,
        "raw": "Test backslash separator with lowercase."
      }
    },
    {
      "kind": "class",
      "name": "TestClassifyIntegrationType",
      "qualname": "TestClassifyIntegrationType",
      "enclosing": [],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 37,
      "end_lineno": 108,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for classify_integration_type function.",
        "raw": "Tests for classify_integration_type function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_integration_pattern",
      "qualname": "TestIsIntegrationUser.test_integration_pattern",
      "enclosing": [
        "TestIsIntegrationUser"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 114,
      "end_lineno": 117,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_manual_pattern",
      "qualname": "TestIsIntegrationUser.test_manual_pattern",
      "enclosing": [
        "TestIsIntegrationUser"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 119,
      "end_lineno": 122,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_empty_and_none",
      "qualname": "TestIsIntegrationUser.test_empty_and_none",
      "enclosing": [
        "TestIsIntegrationUser"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 124,
      "end_lineno": 126,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "class",
      "name": "TestIsIntegrationUser",
      "qualname": "TestIsIntegrationUser",
      "enclosing": [],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 111,
      "end_lineno": 126,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for is_integration_user helper function.",
        "raw": "Tests for is_integration_user helper function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_empty_dataframe",
      "qualname": "TestClassifyIssuance.test_empty_dataframe",
      "enclosing": [
        "TestClassifyIssuance"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 136,
      "end_lineno": 140,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with empty DataFrame.",
        "returns": null,
        "raw": "Test with empty DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_integrated_refund_issuance",
      "qualname": "TestClassifyIssuance.test_integrated_refund_issuance",
      "enclosing": [
        "TestClassifyIssuance"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 142,
      "end_lineno": 157,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test integrated refund issuance detection.",
        "returns": null,
        "raw": "Test integrated refund issuance detection.\n\nNote: Integration_Type is pre-set here because classify_issuance \nexpects it to be already computed by classify_integration_type.\nIn the full pipeline (categorize_nav_vouchers), Integration_Type\nis computed automatically from User ID."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_integrated_refund_issuance_from_user_id",
      "qualname": "TestClassifyIssuance.test_integrated_refund_issuance_from_user_id",
      "enclosing": [
        "TestClassifyIssuance"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 159,
      "end_lineno": 177,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test integrated refund issuance with User ID (full pipeline behavior).",
        "returns": null,
        "raw": "Test integrated refund issuance with User ID (full pipeline behavior).\n\nThis test verifies the actual pipeline behavior where Integration_Type\nis computed from User ID, not pre-set."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_integrated_rf_prefix_issuance",
      "qualname": "TestClassifyIssuance.test_integrated_rf_prefix_issuance",
      "enclosing": [
        "TestClassifyIssuance"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 179,
      "end_lineno": 187,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test integrated RF_ prefix detection.",
        "returns": null,
        "raw": "Test integrated RF_ prefix detection."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_integrated_apology_issuance",
      "qualname": "TestClassifyIssuance.test_integrated_apology_issuance",
      "enclosing": [
        "TestClassifyIssuance"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 189,
      "end_lineno": 198,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test integrated commercial gesture detection.",
        "returns": null,
        "raw": "Test integrated commercial gesture detection."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_integrated_jforce_issuance",
      "qualname": "TestClassifyIssuance.test_integrated_jforce_issuance",
      "enclosing": [
        "TestClassifyIssuance"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 200,
      "end_lineno": 209,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test integrated JForce detection.",
        "returns": null,
        "raw": "Test integrated JForce detection."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_manual_store_credit_issuance",
      "qualname": "TestClassifyIssuance.test_manual_store_credit_issuance",
      "enclosing": [
        "TestClassifyIssuance"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 211,
      "end_lineno": 221,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test manual store credit issuance via country code prefix.",
        "returns": null,
        "raw": "Test manual store credit issuance via country code prefix."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_manual_refund_issuance",
      "qualname": "TestClassifyIssuance.test_manual_refund_issuance",
      "enclosing": [
        "TestClassifyIssuance"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 223,
      "end_lineno": 233,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test manual refund issuance.",
        "returns": null,
        "raw": "Test manual refund issuance."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_positive_amount_not_classified",
      "qualname": "TestClassifyIssuance.test_positive_amount_not_classified",
      "enclosing": [
        "TestClassifyIssuance"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 235,
      "end_lineno": 243,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that positive amounts are not classified as issuance.",
        "returns": null,
        "raw": "Test that positive amounts are not classified as issuance."
      }
    },
    {
      "kind": "class",
      "name": "TestClassifyIssuance",
      "qualname": "TestClassifyIssuance",
      "enclosing": [],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 133,
      "end_lineno": 243,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for classify_issuance function.",
        "raw": "Tests for classify_issuance function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_empty_dataframe",
      "qualname": "TestClassifyUsage.test_empty_dataframe",
      "enclosing": [
        "TestClassifyUsage"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 253,
      "end_lineno": 257,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with empty DataFrame.",
        "returns": null,
        "raw": "Test with empty DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_integrated_usage",
      "qualname": "TestClassifyUsage.test_integrated_usage",
      "enclosing": [
        "TestClassifyUsage"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 259,
      "end_lineno": 267,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test integrated usage detection.",
        "returns": null,
        "raw": "Test integrated usage detection."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_voucher_accrual_cancellation",
      "qualname": "TestClassifyUsage.test_voucher_accrual_cancellation",
      "enclosing": [
        "TestClassifyUsage"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 269,
      "end_lineno": 278,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test Voucher Accrual cancellation detection.",
        "returns": null,
        "raw": "Test Voucher Accrual cancellation detection."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_manual_not_classified_as_integrated_usage",
      "qualname": "TestClassifyUsage.test_manual_not_classified_as_integrated_usage",
      "enclosing": [
        "TestClassifyUsage"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 280,
      "end_lineno": 288,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that manual transactions are not classified as integrated usage.",
        "returns": null,
        "raw": "Test that manual transactions are not classified as integrated usage."
      }
    },
    {
      "kind": "class",
      "name": "TestClassifyUsage",
      "qualname": "TestClassifyUsage",
      "enclosing": [],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 250,
      "end_lineno": 288,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for classify_usage function.",
        "raw": "Tests for classify_usage function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_itempricecredit_pattern",
      "qualname": "TestClassifyManualUsage.test_itempricecredit_pattern",
      "enclosing": [
        "TestClassifyManualUsage"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 294,
      "end_lineno": 302,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test ITEMPRICECREDIT pattern detection (Nigeria exception).",
        "returns": null,
        "raw": "Test ITEMPRICECREDIT pattern detection (Nigeria exception)."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_non_itempricecredit_not_classified",
      "qualname": "TestClassifyManualUsage.test_non_itempricecredit_not_classified",
      "enclosing": [
        "TestClassifyManualUsage"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 304,
      "end_lineno": 312,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that non-ITEMPRICECREDIT patterns are not classified.",
        "returns": null,
        "raw": "Test that non-ITEMPRICECREDIT patterns are not classified."
      }
    },
    {
      "kind": "class",
      "name": "TestClassifyManualUsage",
      "qualname": "TestClassifyManualUsage",
      "enclosing": [],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 291,
      "end_lineno": 312,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for classify_manual_usage function.",
        "raw": "Tests for classify_manual_usage function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_empty_dataframe",
      "qualname": "TestClassifyVTC.test_empty_dataframe",
      "enclosing": [
        "TestClassifyVTC"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 322,
      "end_lineno": 326,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with empty DataFrame.",
        "returns": null,
        "raw": "Test with empty DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_vtc_bank_account_negative",
      "qualname": "TestClassifyVTC.test_vtc_bank_account_negative",
      "enclosing": [
        "TestClassifyVTC"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 328,
      "end_lineno": 336,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC via Bank Account with negative amount - should NOT classify (positive amounts only).",
        "returns": null,
        "raw": "Test VTC via Bank Account with negative amount - should NOT classify (positive amounts only)."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_vtc_bank_account_positive",
      "qualname": "TestClassifyVTC.test_vtc_bank_account_positive",
      "enclosing": [
        "TestClassifyVTC"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 338,
      "end_lineno": 347,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC via Bank Account with positive amount.",
        "returns": null,
        "raw": "Test VTC via Bank Account with positive amount."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_vtc_manual_rnd",
      "qualname": "TestClassifyVTC.test_vtc_manual_rnd",
      "enclosing": [
        "TestClassifyVTC"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 349,
      "end_lineno": 358,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC via Manual RND pattern.",
        "returns": null,
        "raw": "Test VTC via Manual RND pattern."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_vtc_pyt_gtb",
      "qualname": "TestClassifyVTC.test_vtc_pyt_gtb",
      "enclosing": [
        "TestClassifyVTC"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 360,
      "end_lineno": 370,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC via PYT_ with GTB in Comment.",
        "returns": null,
        "raw": "Test VTC via PYT_ with GTB in Comment."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_integration_not_classified_as_vtc",
      "qualname": "TestClassifyVTC.test_integration_not_classified_as_vtc",
      "enclosing": [
        "TestClassifyVTC"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 372,
      "end_lineno": 380,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that Integration transactions are not classified as VTC.",
        "returns": null,
        "raw": "Test that Integration transactions are not classified as VTC."
      }
    },
    {
      "kind": "class",
      "name": "TestClassifyVTC",
      "qualname": "TestClassifyVTC",
      "enclosing": [],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 319,
      "end_lineno": 380,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for classify_vtc function.",
        "raw": "Tests for classify_vtc function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_empty_dataframe",
      "qualname": "TestClassifyExpired.test_empty_dataframe",
      "enclosing": [
        "TestClassifyExpired"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 390,
      "end_lineno": 394,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with empty DataFrame.",
        "returns": null,
        "raw": "Test with empty DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_expired_apology",
      "qualname": "TestClassifyExpired.test_expired_apology",
      "enclosing": [
        "TestClassifyExpired"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 396,
      "end_lineno": 405,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test EXPR_APLGY pattern detection.",
        "returns": null,
        "raw": "Test EXPR_APLGY pattern detection."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_expired_refund",
      "qualname": "TestClassifyExpired.test_expired_refund",
      "enclosing": [
        "TestClassifyExpired"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 407,
      "end_lineno": 416,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test EXPR_JFORCE pattern detection.",
        "returns": null,
        "raw": "Test EXPR_JFORCE pattern detection."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_expired_store_credit",
      "qualname": "TestClassifyExpired.test_expired_store_credit",
      "enclosing": [
        "TestClassifyExpired"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 418,
      "end_lineno": 427,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test EXPR_STR CRDT pattern detection.",
        "returns": null,
        "raw": "Test EXPR_STR CRDT pattern detection."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_expired_generic",
      "qualname": "TestClassifyExpired.test_expired_generic",
      "enclosing": [
        "TestClassifyExpired"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 429,
      "end_lineno": 437,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test generic EXPR pattern detection.",
        "returns": null,
        "raw": "Test generic EXPR pattern detection."
      }
    },
    {
      "kind": "class",
      "name": "TestClassifyExpired",
      "qualname": "TestClassifyExpired",
      "enclosing": [],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 387,
      "end_lineno": 437,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for classify_expired function.",
        "raw": "Tests for classify_expired function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_credit_memo_cancellation",
      "qualname": "TestClassifyManualCancellation.test_credit_memo_cancellation",
      "enclosing": [
        "TestClassifyManualCancellation"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 443,
      "end_lineno": 452,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test Manual Cancellation via Credit Memo.",
        "returns": null,
        "raw": "Test Manual Cancellation via Credit Memo."
      }
    },
    {
      "kind": "class",
      "name": "TestClassifyManualCancellation",
      "qualname": "TestClassifyManualCancellation",
      "enclosing": [],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 440,
      "end_lineno": 452,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for classify_manual_cancellation function.",
        "raw": "Tests for classify_manual_cancellation function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_empty_dataframe",
      "qualname": "TestCategorizationPipeline.test_empty_dataframe",
      "enclosing": [
        "TestCategorizationPipeline"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 462,
      "end_lineno": 469,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with empty DataFrame.",
        "returns": null,
        "raw": "Test with empty DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_none_dataframe",
      "qualname": "TestCategorizationPipeline.test_none_dataframe",
      "enclosing": [
        "TestCategorizationPipeline"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 471,
      "end_lineno": 476,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with None input.",
        "returns": null,
        "raw": "Test with None input."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_mixed_scenarios",
      "qualname": "TestCategorizationPipeline.test_mixed_scenarios",
      "enclosing": [
        "TestCategorizationPipeline"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 478,
      "end_lineno": 523,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test a mix of different categorization rules.",
        "returns": null,
        "raw": "Test a mix of different categorization rules."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_vtc_priority_over_issuance",
      "qualname": "TestCategorizationPipeline.test_vtc_priority_over_issuance",
      "enclosing": [
        "TestCategorizationPipeline"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 525,
      "end_lineno": 539,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that VTC Bank Account has priority for positive amounts (negative amounts should be Issuance).",
        "returns": null,
        "raw": "Test that VTC Bank Account has priority for positive amounts (negative amounts should be Issuance)."
      }
    },
    {
      "kind": "class",
      "name": "TestCategorizationPipeline",
      "qualname": "TestCategorizationPipeline",
      "enclosing": [],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 459,
      "end_lineno": 539,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for the main categorization pipeline.",
        "raw": "Tests for the main categorization pipeline."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_empty_dataframe",
      "qualname": "TestGetCategorizationSummary.test_empty_dataframe",
      "enclosing": [
        "TestGetCategorizationSummary"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 545,
      "end_lineno": 550,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test summary with empty DataFrame.",
        "returns": null,
        "raw": "Test summary with empty DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_summary_counts",
      "qualname": "TestGetCategorizationSummary.test_summary_counts",
      "enclosing": [
        "TestGetCategorizationSummary"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 552,
      "end_lineno": 566,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test summary counts are correct.",
        "returns": null,
        "raw": "Test summary counts are correct."
      }
    },
    {
      "kind": "class",
      "name": "TestGetCategorizationSummary",
      "qualname": "TestGetCategorizationSummary",
      "enclosing": [],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 542,
      "end_lineno": 566,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for get_categorization_summary function.",
        "raw": "Tests for get_categorization_summary function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_same_output_for_basic_scenarios",
      "qualname": "TestBackwardCompatibility.test_same_output_for_basic_scenarios",
      "enclosing": [
        "TestBackwardCompatibility"
      ],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 576,
      "end_lineno": 605,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that new pipeline produces same output as original for basic scenarios.",
        "returns": null,
        "raw": "Test that new pipeline produces same output as original for basic scenarios."
      }
    },
    {
      "kind": "class",
      "name": "TestBackwardCompatibility",
      "qualname": "TestBackwardCompatibility",
      "enclosing": [],
      "module": "tests.test_categorization_pipeline",
      "file": "tests\\test_categorization_pipeline.py",
      "lineno": 573,
      "end_lineno": 605,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests to ensure backward compatibility with original _categorize_nav_vouchers.",
        "raw": "Tests to ensure backward compatibility with original _categorize_nav_vouchers."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_with_fx_conversion",
      "qualname": "test_calculate_vtc_adjustment_with_fx_conversion",
      "enclosing": [],
      "module": "tests.test_classifier_fx_conversion",
      "file": "tests\\test_classifier_fx_conversion.py",
      "lineno": 29,
      "end_lineno": 69,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment with FX conversion to USD.",
        "returns": null,
        "raw": "Test VTC adjustment with FX conversion to USD."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_without_fx_conversion",
      "qualname": "test_calculate_vtc_adjustment_without_fx_conversion",
      "enclosing": [],
      "module": "tests.test_classifier_fx_conversion",
      "file": "tests\\test_classifier_fx_conversion.py",
      "lineno": 72,
      "end_lineno": 103,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment without FX converter (local currency).",
        "returns": null,
        "raw": "Test VTC adjustment without FX converter (local currency)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_vtc_adjustment_fx_missing_company_column",
      "qualname": "test_calculate_vtc_adjustment_fx_missing_company_column",
      "enclosing": [],
      "module": "tests.test_classifier_fx_conversion",
      "file": "tests\\test_classifier_fx_conversion.py",
      "lineno": 106,
      "end_lineno": 134,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test VTC adjustment when company column is missing but FX converter provided.",
        "returns": null,
        "raw": "Test VTC adjustment when company column is missing but FX converter provided."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_with_fx_conversion",
      "qualname": "test_calculate_timing_difference_bridge_with_fx_conversion",
      "enclosing": [],
      "module": "tests.test_classifier_fx_conversion",
      "file": "tests\\test_classifier_fx_conversion.py",
      "lineno": 142,
      "end_lineno": 184,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test timing difference bridge - variance calculation in local currency.",
        "returns": null,
        "raw": "Test timing difference bridge - variance calculation in local currency.\n\nNote: FX conversion support was removed from calculate_timing_difference_bridge.\nThe function now returns variance in local currency (Jdash - IPE_08).\nFor USD conversion, apply FXConverter to the output proof_df separately."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_without_fx_conversion",
      "qualname": "test_calculate_timing_difference_bridge_without_fx_conversion",
      "enclosing": [],
      "module": "tests.test_classifier_fx_conversion",
      "file": "tests\\test_classifier_fx_conversion.py",
      "lineno": 187,
      "end_lineno": 211,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test timing difference bridge returns variance in local currency.",
        "returns": null,
        "raw": "Test timing difference bridge returns variance in local currency."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_filter_non_marketing_basic",
      "qualname": "TestFilterIpe08Scope.test_filter_non_marketing_basic",
      "enclosing": [
        "TestFilterIpe08Scope"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 46,
      "end_lineno": 59,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test basic filtering of Non-Marketing vouchers.",
        "returns": null,
        "raw": "Test basic filtering of Non-Marketing vouchers."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_filter_all_non_marketing_types",
      "qualname": "TestFilterIpe08Scope.test_filter_all_non_marketing_types",
      "enclosing": [
        "TestFilterIpe08Scope"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 61,
      "end_lineno": 73,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that all non-marketing types are retained.",
        "returns": null,
        "raw": "Test that all non-marketing types are retained."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_filter_empty_dataframe",
      "qualname": "TestFilterIpe08Scope.test_filter_empty_dataframe",
      "enclosing": [
        "TestFilterIpe08Scope"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 75,
      "end_lineno": 79,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test handling of empty DataFrame.",
        "returns": null,
        "raw": "Test handling of empty DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_filter_none_input",
      "qualname": "TestFilterIpe08Scope.test_filter_none_input",
      "enclosing": [
        "TestFilterIpe08Scope"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 81,
      "end_lineno": 84,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test handling of None input.",
        "returns": null,
        "raw": "Test handling of None input."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_filter_with_business_use_formatted",
      "qualname": "TestFilterIpe08Scope.test_filter_with_business_use_formatted",
      "enclosing": [
        "TestFilterIpe08Scope"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 86,
      "end_lineno": 96,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test filtering with business_use_formatted column.",
        "returns": null,
        "raw": "Test filtering with business_use_formatted column."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_filter_converts_dates",
      "qualname": "TestFilterIpe08Scope.test_filter_converts_dates",
      "enclosing": [
        "TestFilterIpe08Scope"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 98,
      "end_lineno": 112,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that date columns are converted to datetime.",
        "returns": null,
        "raw": "Test that date columns are converted to datetime."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_filter_preserves_columns",
      "qualname": "TestFilterIpe08Scope.test_filter_preserves_columns",
      "enclosing": [
        "TestFilterIpe08Scope"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 114,
      "end_lineno": 124,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that other columns are preserved.",
        "returns": null,
        "raw": "Test that other columns are preserved."
      }
    },
    {
      "kind": "class",
      "name": "TestFilterIpe08Scope",
      "qualname": "TestFilterIpe08Scope",
      "enclosing": [],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 43,
      "end_lineno": 124,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for filter_ipe08_scope function.",
        "raw": "Tests for filter_ipe08_scope function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_filter_gl_basic",
      "qualname": "TestFilterGl18412.test_filter_gl_basic",
      "enclosing": [
        "TestFilterGl18412"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 130,
      "end_lineno": 140,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test basic GL 18412 filtering.",
        "returns": null,
        "raw": "Test basic GL 18412 filtering."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_filter_gl_empty",
      "qualname": "TestFilterGl18412.test_filter_gl_empty",
      "enclosing": [
        "TestFilterGl18412"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 142,
      "end_lineno": 146,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with empty DataFrame.",
        "returns": null,
        "raw": "Test with empty DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_filter_gl_none",
      "qualname": "TestFilterGl18412.test_filter_gl_none",
      "enclosing": [
        "TestFilterGl18412"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 148,
      "end_lineno": 151,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with None input.",
        "returns": null,
        "raw": "Test with None input."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_filter_gl_no_column",
      "qualname": "TestFilterGl18412.test_filter_gl_no_column",
      "enclosing": [
        "TestFilterGl18412"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 153,
      "end_lineno": 162,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test when GL column is missing.",
        "returns": null,
        "raw": "Test when GL column is missing."
      }
    },
    {
      "kind": "class",
      "name": "TestFilterGl18412",
      "qualname": "TestFilterGl18412",
      "enclosing": [],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 127,
      "end_lineno": 162,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for filter_gl_18412 function.",
        "raw": "Tests for filter_gl_18412 function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_summary_basic",
      "qualname": "TestGetNonMarketingSummary.test_summary_basic",
      "enclosing": [
        "TestGetNonMarketingSummary"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 168,
      "end_lineno": 181,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test basic summary generation.",
        "returns": null,
        "raw": "Test basic summary generation."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_summary_empty",
      "qualname": "TestGetNonMarketingSummary.test_summary_empty",
      "enclosing": [
        "TestGetNonMarketingSummary"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 183,
      "end_lineno": 188,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test summary with empty DataFrame.",
        "returns": null,
        "raw": "Test summary with empty DataFrame."
      }
    },
    {
      "kind": "class",
      "name": "TestGetNonMarketingSummary",
      "qualname": "TestGetNonMarketingSummary",
      "enclosing": [],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 165,
      "end_lineno": 188,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for get_non_marketing_summary function.",
        "raw": "Tests for get_non_marketing_summary function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_load_from_dataframe",
      "qualname": "TestLoadJdashData.test_load_from_dataframe",
      "enclosing": [
        "TestLoadJdashData"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 198,
      "end_lineno": 208,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test loading from existing DataFrame.",
        "returns": null,
        "raw": "Test loading from existing DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_load_normalizes_columns",
      "qualname": "TestLoadJdashData.test_load_normalizes_columns",
      "enclosing": [
        "TestLoadJdashData"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 210,
      "end_lineno": 219,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that column names are normalized.",
        "returns": null,
        "raw": "Test that column names are normalized."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_load_no_source_returns_empty",
      "qualname": "TestLoadJdashData.test_load_no_source_returns_empty",
      "enclosing": [
        "TestLoadJdashData"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 221,
      "end_lineno": 226,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that None source with no fallback returns empty DataFrame.",
        "returns": null,
        "raw": "Test that None source with no fallback returns empty DataFrame."
      }
    },
    {
      "kind": "class",
      "name": "TestLoadJdashData",
      "qualname": "TestLoadJdashData",
      "enclosing": [],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 195,
      "end_lineno": 226,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for load_jdash_data function.",
        "raw": "Tests for load_jdash_data function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_aggregate_basic",
      "qualname": "TestAggregateJdashByVoucher.test_aggregate_basic",
      "enclosing": [
        "TestAggregateJdashByVoucher"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 232,
      "end_lineno": 244,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test basic aggregation by voucher ID.",
        "returns": null,
        "raw": "Test basic aggregation by voucher ID."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_aggregate_empty",
      "qualname": "TestAggregateJdashByVoucher.test_aggregate_empty",
      "enclosing": [
        "TestAggregateJdashByVoucher"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 246,
      "end_lineno": 251,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test aggregation of empty DataFrame.",
        "returns": null,
        "raw": "Test aggregation of empty DataFrame."
      }
    },
    {
      "kind": "class",
      "name": "TestAggregateJdashByVoucher",
      "qualname": "TestAggregateJdashByVoucher",
      "enclosing": [],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 229,
      "end_lineno": 251,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for aggregate_jdash_by_voucher function.",
        "raw": "Tests for aggregate_jdash_by_voucher function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_validate_valid_data",
      "qualname": "TestValidateJdashData.test_validate_valid_data",
      "enclosing": [
        "TestValidateJdashData"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 257,
      "end_lineno": 268,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test validation with valid data.",
        "returns": null,
        "raw": "Test validation with valid data."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_validate_missing_columns",
      "qualname": "TestValidateJdashData.test_validate_missing_columns",
      "enclosing": [
        "TestValidateJdashData"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 270,
      "end_lineno": 279,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test validation with missing required columns.",
        "returns": null,
        "raw": "Test validation with missing required columns."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_validate_empty_dataframe",
      "qualname": "TestValidateJdashData.test_validate_empty_dataframe",
      "enclosing": [
        "TestValidateJdashData"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 281,
      "end_lineno": 286,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test validation with empty DataFrame.",
        "returns": null,
        "raw": "Test validation with empty DataFrame."
      }
    },
    {
      "kind": "class",
      "name": "TestValidateJdashData",
      "qualname": "TestValidateJdashData",
      "enclosing": [],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 254,
      "end_lineno": 286,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for validate_jdash_data function.",
        "raw": "Tests for validate_jdash_data function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_no_evidence_returns_none",
      "qualname": "TestGetLatestEvidenceZip.test_no_evidence_returns_none",
      "enclosing": [
        "TestGetLatestEvidenceZip"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 296,
      "end_lineno": 299,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that missing evidence directory returns None.",
        "returns": null,
        "raw": "Test that missing evidence directory returns None."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_finds_evidence_in_temp_dir",
      "qualname": "TestGetLatestEvidenceZip.test_finds_evidence_in_temp_dir",
      "enclosing": [
        "TestGetLatestEvidenceZip"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 301,
      "end_lineno": 320,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test finding evidence in a temporary directory.",
        "returns": null,
        "raw": "Test finding evidence in a temporary directory."
      }
    },
    {
      "kind": "class",
      "name": "TestGetLatestEvidenceZip",
      "qualname": "TestGetLatestEvidenceZip",
      "enclosing": [],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 293,
      "end_lineno": 320,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for get_latest_evidence_zip function.",
        "raw": "Tests for get_latest_evidence_zip function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_find_multiple_packages",
      "qualname": "TestFindEvidencePackages.test_find_multiple_packages",
      "enclosing": [
        "TestFindEvidencePackages"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 326,
      "end_lineno": 350,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test finding multiple evidence packages.",
        "returns": null,
        "raw": "Test finding multiple evidence packages."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_find_empty_directory",
      "qualname": "TestFindEvidencePackages.test_find_empty_directory",
      "enclosing": [
        "TestFindEvidencePackages"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 352,
      "end_lineno": 356,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with no matching packages.",
        "returns": null,
        "raw": "Test with no matching packages."
      }
    },
    {
      "kind": "class",
      "name": "TestFindEvidencePackages",
      "qualname": "TestFindEvidencePackages",
      "enclosing": [],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 323,
      "end_lineno": 356,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for find_evidence_packages function.",
        "raw": "Tests for find_evidence_packages function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_scope_filtering_consistency_with_classifier",
      "qualname": "TestIntegration.test_scope_filtering_consistency_with_classifier",
      "enclosing": [
        "TestIntegration"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 366,
      "end_lineno": 381,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that scope filtering is consistent with classifier behavior.",
        "returns": null,
        "raw": "Test that scope filtering is consistent with classifier behavior."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_non_marketing_constant_matches",
      "qualname": "TestIntegration.test_non_marketing_constant_matches",
      "enclosing": [
        "TestIntegration"
      ],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 383,
      "end_lineno": 388,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that NON_MARKETING_USES constant contains expected values.",
        "returns": null,
        "raw": "Test that NON_MARKETING_USES constant contains expected values."
      }
    },
    {
      "kind": "class",
      "name": "TestIntegration",
      "qualname": "TestIntegration",
      "enclosing": [],
      "module": "tests.test_core_extraction_preprocessing",
      "file": "tests\\test_core_extraction_preprocessing.py",
      "lineno": 363,
      "end_lineno": 388,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Integration tests for the core modules working together.",
        "raw": "Integration tests for the core modules working together."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_secret_manager",
      "qualname": "test_secret_manager",
      "enclosing": [],
      "module": "tests.test_database_connection",
      "file": "tests\\test_database_connection.py",
      "lineno": 23,
      "end_lineno": 38,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test AWS Secrets Manager access.",
        "returns": null,
        "raw": "Test AWS Secrets Manager access."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_database_connection",
      "qualname": "test_database_connection",
      "enclosing": [],
      "module": "tests.test_database_connection",
      "file": "tests\\test_database_connection.py",
      "lineno": 41,
      "end_lineno": 61,
      "decorators": [],
      "parameters": [
        {
          "name": "conn_str",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test database connection.",
        "returns": null,
        "raw": "Test database connection."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_parameterized_query",
      "qualname": "test_parameterized_query",
      "enclosing": [],
      "module": "tests.test_database_connection",
      "file": "tests\\test_database_connection.py",
      "lineno": 64,
      "end_lineno": 92,
      "decorators": [],
      "parameters": [
        {
          "name": "conn_str",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test parameterized query execution.",
        "returns": null,
        "raw": "Test parameterized query execution."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "tests.test_database_connection",
      "file": "tests\\test_database_connection.py",
      "lineno": 95,
      "end_lineno": 123,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Run all connection tests.",
        "returns": null,
        "raw": "Run all connection tests."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_dfprobe_basic_instantiation",
      "qualname": "test_dfprobe_basic_instantiation",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 26,
      "end_lineno": 45,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test DFProbe can be instantiated with basic fields.",
        "returns": null,
        "raw": "Test DFProbe can be instantiated with basic fields."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_dfprobe_full_instantiation",
      "qualname": "test_dfprobe_full_instantiation",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 48,
      "end_lineno": 67,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test DFProbe with all optional fields.",
        "returns": null,
        "raw": "Test DFProbe with all optional fields."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_basic",
      "qualname": "test_probe_df_basic",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 74,
      "end_lineno": 87,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test basic probe_df functionality.",
        "returns": null,
        "raw": "Test basic probe_df functionality."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_with_nulls",
      "qualname": "test_probe_df_with_nulls",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 90,
      "end_lineno": 102,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df correctly counts null values.",
        "returns": null,
        "raw": "Test probe_df correctly counts null values."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_with_duplicates",
      "qualname": "test_probe_df_with_duplicates",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 105,
      "end_lineno": 114,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df correctly counts duplicated rows.",
        "returns": null,
        "raw": "Test probe_df correctly counts duplicated rows."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_empty_dataframe",
      "qualname": "test_probe_df_empty_dataframe",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 117,
      "end_lineno": 126,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df handles empty DataFrames.",
        "returns": null,
        "raw": "Test probe_df handles empty DataFrames."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_with_amount_col",
      "qualname": "test_probe_df_with_amount_col",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 133,
      "end_lineno": 143,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df with amount column.",
        "returns": null,
        "raw": "Test probe_df with amount column."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_amount_col_with_nulls",
      "qualname": "test_probe_df_amount_col_with_nulls",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 146,
      "end_lineno": 156,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df amount calculation with null values.",
        "returns": null,
        "raw": "Test probe_df amount calculation with null values."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_amount_col_missing",
      "qualname": "test_probe_df_amount_col_missing",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 159,
      "end_lineno": 170,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df handles missing amount column gracefully.",
        "returns": null,
        "raw": "Test probe_df handles missing amount column gracefully."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_amount_col_non_numeric",
      "qualname": "test_probe_df_amount_col_non_numeric",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 173,
      "end_lineno": 184,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df handles non-numeric amount column.",
        "returns": null,
        "raw": "Test probe_df handles non-numeric amount column."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_with_date_col",
      "qualname": "test_probe_df_with_date_col",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 191,
      "end_lineno": 201,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df with date column.",
        "returns": null,
        "raw": "Test probe_df with date column."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_date_col_with_datetime",
      "qualname": "test_probe_df_date_col_with_datetime",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 204,
      "end_lineno": 214,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df with datetime objects.",
        "returns": null,
        "raw": "Test probe_df with datetime objects."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_date_col_with_nulls",
      "qualname": "test_probe_df_date_col_with_nulls",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 217,
      "end_lineno": 227,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df date calculation with null values.",
        "returns": null,
        "raw": "Test probe_df date calculation with null values."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_date_col_missing",
      "qualname": "test_probe_df_date_col_missing",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 230,
      "end_lineno": 241,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df handles missing date column gracefully.",
        "returns": null,
        "raw": "Test probe_df handles missing date column gracefully."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_date_col_invalid_dates",
      "qualname": "test_probe_df_date_col_invalid_dates",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 244,
      "end_lineno": 255,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df handles invalid dates gracefully.",
        "returns": null,
        "raw": "Test probe_df handles invalid dates gracefully."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_with_key_cols",
      "qualname": "test_probe_df_with_key_cols",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 262,
      "end_lineno": 277,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df with key columns.",
        "returns": null,
        "raw": "Test probe_df with key columns."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_key_cols_missing",
      "qualname": "test_probe_df_key_cols_missing",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 280,
      "end_lineno": 293,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df handles missing key columns gracefully.",
        "returns": null,
        "raw": "Test probe_df handles missing key columns gracefully."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_key_cols_partial_missing",
      "qualname": "test_probe_df_key_cols_partial_missing",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 296,
      "end_lineno": 310,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df with some key columns missing.",
        "returns": null,
        "raw": "Test probe_df with some key columns missing."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_creates_directory",
      "qualname": "test_probe_df_creates_directory",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 317,
      "end_lineno": 325,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df creates output directory if it doesn't exist.",
        "returns": null,
        "raw": "Test probe_df creates output directory if it doesn't exist."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_with_string_path",
      "qualname": "test_probe_df_with_string_path",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 328,
      "end_lineno": 335,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df works with string paths.",
        "returns": null,
        "raw": "Test probe_df works with string paths."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_creates_log_file",
      "qualname": "test_probe_df_creates_log_file",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 342,
      "end_lineno": 348,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df creates probes.log file.",
        "returns": null,
        "raw": "Test probe_df creates probes.log file."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_log_format",
      "qualname": "test_probe_df_log_format",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 351,
      "end_lineno": 370,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df log file has correct JSON format.",
        "returns": null,
        "raw": "Test probe_df log file has correct JSON format."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_appends_to_log",
      "qualname": "test_probe_df_appends_to_log",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 373,
      "end_lineno": 394,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df appends to existing log file.",
        "returns": null,
        "raw": "Test probe_df appends to existing log file."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_snapshot_basic",
      "qualname": "test_probe_df_snapshot_basic",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 401,
      "end_lineno": 417,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df creates CSV snapshot.",
        "returns": null,
        "raw": "Test probe_df creates CSV snapshot."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_snapshot_with_cols",
      "qualname": "test_probe_df_snapshot_with_cols",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 420,
      "end_lineno": 438,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df snapshot with specific columns.",
        "returns": null,
        "raw": "Test probe_df snapshot with specific columns."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_snapshot_missing_cols",
      "qualname": "test_probe_df_snapshot_missing_cols",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 441,
      "end_lineno": 460,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df snapshot handles missing columns gracefully.",
        "returns": null,
        "raw": "Test probe_df snapshot handles missing columns gracefully."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_no_snapshot_by_default",
      "qualname": "test_probe_df_no_snapshot_by_default",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 463,
      "end_lineno": 469,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df doesn't create snapshot by default.",
        "returns": null,
        "raw": "Test probe_df doesn't create snapshot by default."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_complete_workflow",
      "qualname": "test_probe_df_complete_workflow",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 476,
      "end_lineno": 518,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test complete probe_df workflow with all features.",
        "returns": null,
        "raw": "Test complete probe_df workflow with all features."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_handles_nan_and_infinity",
      "qualname": "test_probe_df_handles_nan_and_infinity",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 521,
      "end_lineno": 557,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df handles NaN and Infinity values in financial data.",
        "returns": null,
        "raw": "Test probe_df handles NaN and Infinity values in financial data."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_handles_decimal_types",
      "qualname": "test_probe_df_handles_decimal_types",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 560,
      "end_lineno": 593,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df handles Decimal types in financial data.",
        "returns": null,
        "raw": "Test probe_df handles Decimal types in financial data."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_snapshot_max_rows",
      "qualname": "test_probe_df_snapshot_max_rows",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 596,
      "end_lineno": 621,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df limits snapshot rows to prevent massive disk writes.",
        "returns": null,
        "raw": "Test probe_df limits snapshot rows to prevent massive disk writes."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_probe_df_snapshot_small_dataframe",
      "qualname": "test_probe_df_snapshot_small_dataframe",
      "enclosing": [],
      "module": "tests.test_debug_probe",
      "file": "tests\\test_debug_probe.py",
      "lineno": 624,
      "end_lineno": 639,
      "decorators": [],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test probe_df doesn't limit snapshot for small DataFrames.",
        "returns": null,
        "raw": "Test probe_df doesn't limit snapshot for small DataFrames."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_probe_df_creates_log_file",
      "qualname": "TestProbeDF.test_probe_df_creates_log_file",
      "enclosing": [
        "TestProbeDF"
      ],
      "module": "tests.test_debug_probes",
      "file": "tests\\test_debug_probes.py",
      "lineno": 17,
      "end_lineno": 35,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that probe_df creates a log file.",
        "returns": null,
        "raw": "Test that probe_df creates a log file."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_probe_df_creates_sample_file",
      "qualname": "TestProbeDF.test_probe_df_creates_sample_file",
      "enclosing": [
        "TestProbeDF"
      ],
      "module": "tests.test_debug_probes",
      "file": "tests\\test_debug_probes.py",
      "lineno": 37,
      "end_lineno": 53,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that probe_df creates a sample CSV file.",
        "returns": null,
        "raw": "Test that probe_df creates a sample CSV file."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_probe_df_with_metrics",
      "qualname": "TestProbeDF.test_probe_df_with_metrics",
      "enclosing": [
        "TestProbeDF"
      ],
      "module": "tests.test_debug_probes",
      "file": "tests\\test_debug_probes.py",
      "lineno": 55,
      "end_lineno": 72,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that probe_df calculates metrics correctly.",
        "returns": null,
        "raw": "Test that probe_df calculates metrics correctly."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_probe_df_with_empty_dataframe",
      "qualname": "TestProbeDF.test_probe_df_with_empty_dataframe",
      "enclosing": [
        "TestProbeDF"
      ],
      "module": "tests.test_debug_probes",
      "file": "tests\\test_debug_probes.py",
      "lineno": 74,
      "end_lineno": 86,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that probe_df handles empty DataFrame gracefully.",
        "returns": null,
        "raw": "Test that probe_df handles empty DataFrame gracefully."
      }
    },
    {
      "kind": "class",
      "name": "TestProbeDF",
      "qualname": "TestProbeDF",
      "enclosing": [],
      "module": "tests.test_debug_probes",
      "file": "tests\\test_debug_probes.py",
      "lineno": 14,
      "end_lineno": 86,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for the probe_df function.",
        "raw": "Tests for the probe_df function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_audit_merge_creates_log_file",
      "qualname": "TestAuditMerge.test_audit_merge_creates_log_file",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_debug_probes",
      "file": "tests\\test_debug_probes.py",
      "lineno": 92,
      "end_lineno": 113,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that audit_merge creates a log file.",
        "returns": null,
        "raw": "Test that audit_merge creates a log file."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_audit_merge_analyzes_keys",
      "qualname": "TestAuditMerge.test_audit_merge_analyzes_keys",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_debug_probes",
      "file": "tests\\test_debug_probes.py",
      "lineno": 115,
      "end_lineno": 134,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that audit_merge analyzes key uniqueness.",
        "returns": null,
        "raw": "Test that audit_merge analyzes key uniqueness."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_audit_merge_with_missing_keys",
      "qualname": "TestAuditMerge.test_audit_merge_with_missing_keys",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_debug_probes",
      "file": "tests\\test_debug_probes.py",
      "lineno": 136,
      "end_lineno": 154,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that audit_merge handles missing keys.",
        "returns": null,
        "raw": "Test that audit_merge handles missing keys."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_audit_merge_match_rate",
      "qualname": "TestAuditMerge.test_audit_merge_match_rate",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_debug_probes",
      "file": "tests\\test_debug_probes.py",
      "lineno": 156,
      "end_lineno": 180,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that audit_merge calculates match rate.",
        "returns": null,
        "raw": "Test that audit_merge calculates match rate."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_audit_merge_with_multiple_keys",
      "qualname": "TestAuditMerge.test_audit_merge_with_multiple_keys",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_debug_probes",
      "file": "tests\\test_debug_probes.py",
      "lineno": 182,
      "end_lineno": 204,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that audit_merge handles multiple merge keys.",
        "returns": null,
        "raw": "Test that audit_merge handles multiple merge keys."
      }
    },
    {
      "kind": "class",
      "name": "TestAuditMerge",
      "qualname": "TestAuditMerge",
      "enclosing": [],
      "module": "tests.test_debug_probes",
      "file": "tests\\test_debug_probes.py",
      "lineno": 89,
      "end_lineno": 204,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for the audit_merge function.",
        "raw": "Tests for the audit_merge function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_probe_df_called_for_cr03_load",
      "qualname": "TestDebugProbeInstrumentation.test_probe_df_called_for_cr03_load",
      "enclosing": [
        "TestDebugProbeInstrumentation"
      ],
      "module": "tests.test_debug_probe_instrumentation",
      "file": "tests\\test_debug_probe_instrumentation.py",
      "lineno": 16,
      "end_lineno": 41,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that probe_df is called for CR_03 after loading.",
        "returns": null,
        "raw": "Test that probe_df is called for CR_03 after loading."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_probe_df_called_for_ipe08_load",
      "qualname": "TestDebugProbeInstrumentation.test_probe_df_called_for_ipe08_load",
      "enclosing": [
        "TestDebugProbeInstrumentation"
      ],
      "module": "tests.test_debug_probe_instrumentation",
      "file": "tests\\test_debug_probe_instrumentation.py",
      "lineno": 43,
      "end_lineno": 68,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that probe_df is called for IPE_08 after loading.",
        "returns": null,
        "raw": "Test that probe_df is called for IPE_08 after loading."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_probe_df_called_for_scope_filtering",
      "qualname": "TestDebugProbeInstrumentation.test_probe_df_called_for_scope_filtering",
      "enclosing": [
        "TestDebugProbeInstrumentation"
      ],
      "module": "tests.test_debug_probe_instrumentation",
      "file": "tests\\test_debug_probe_instrumentation.py",
      "lineno": 70,
      "end_lineno": 96,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that probe_df is called after IPE_08 scope filtering.",
        "returns": null,
        "raw": "Test that probe_df is called after IPE_08 scope filtering."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_probe_df_called_for_categorization",
      "qualname": "TestDebugProbeInstrumentation.test_probe_df_called_for_categorization",
      "enclosing": [
        "TestDebugProbeInstrumentation"
      ],
      "module": "tests.test_debug_probe_instrumentation",
      "file": "tests\\test_debug_probe_instrumentation.py",
      "lineno": 98,
      "end_lineno": 128,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that probe_df is called after NAV categorization.",
        "returns": null,
        "raw": "Test that probe_df is called after NAV categorization."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_audit_merge_called_for_timing_diff",
      "qualname": "TestDebugProbeInstrumentation.test_audit_merge_called_for_timing_diff",
      "enclosing": [
        "TestDebugProbeInstrumentation"
      ],
      "module": "tests.test_debug_probe_instrumentation",
      "file": "tests\\test_debug_probe_instrumentation.py",
      "lineno": 130,
      "end_lineno": 164,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that audit_merge is called before timing difference calculation.",
        "returns": null,
        "raw": "Test that audit_merge is called before timing difference calculation."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_no_probe_for_empty_dataframes",
      "qualname": "TestDebugProbeInstrumentation.test_no_probe_for_empty_dataframes",
      "enclosing": [
        "TestDebugProbeInstrumentation"
      ],
      "module": "tests.test_debug_probe_instrumentation",
      "file": "tests\\test_debug_probe_instrumentation.py",
      "lineno": 166,
      "end_lineno": 188,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that probes are not called for empty DataFrames.",
        "returns": null,
        "raw": "Test that probes are not called for empty DataFrames."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_debug_output_directory_constant",
      "qualname": "TestDebugProbeInstrumentation.test_debug_output_directory_constant",
      "enclosing": [
        "TestDebugProbeInstrumentation"
      ],
      "module": "tests.test_debug_probe_instrumentation",
      "file": "tests\\test_debug_probe_instrumentation.py",
      "lineno": 190,
      "end_lineno": 194,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that DEBUG_OUTPUT_DIR constant is defined.",
        "returns": null,
        "raw": "Test that DEBUG_OUTPUT_DIR constant is defined."
      }
    },
    {
      "kind": "class",
      "name": "TestDebugProbeInstrumentation",
      "qualname": "TestDebugProbeInstrumentation",
      "enclosing": [],
      "module": "tests.test_debug_probe_instrumentation",
      "file": "tests\\test_debug_probe_instrumentation.py",
      "lineno": 13,
      "end_lineno": 194,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for debug probe calls in run_reconciliation.",
        "raw": "Tests for debug probe calls in run_reconciliation."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_get_git_commit_hash",
      "qualname": "TestSystemUtils.test_get_git_commit_hash",
      "enclosing": [
        "TestSystemUtils"
      ],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 44,
      "end_lineno": 50,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test git commit hash retrieval.",
        "returns": null,
        "raw": "Test git commit hash retrieval."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_get_execution_host",
      "qualname": "TestSystemUtils.test_get_execution_host",
      "enclosing": [
        "TestSystemUtils"
      ],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 52,
      "end_lineno": 57,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test hostname retrieval.",
        "returns": null,
        "raw": "Test hostname retrieval."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_get_python_version",
      "qualname": "TestSystemUtils.test_get_python_version",
      "enclosing": [
        "TestSystemUtils"
      ],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 59,
      "end_lineno": 64,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test Python version retrieval.",
        "returns": null,
        "raw": "Test Python version retrieval."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_get_system_context",
      "qualname": "TestSystemUtils.test_get_system_context",
      "enclosing": [
        "TestSystemUtils"
      ],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 66,
      "end_lineno": 75,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test complete system context retrieval.",
        "returns": null,
        "raw": "Test complete system context retrieval."
      }
    },
    {
      "kind": "class",
      "name": "TestSystemUtils",
      "qualname": "TestSystemUtils",
      "enclosing": [],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 41,
      "end_lineno": 75,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Test system utility functions.",
        "raw": "Test system utility functions."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "temp_evidence_dir",
      "qualname": "TestEvidenceManagerEnhancements.temp_evidence_dir",
      "enclosing": [
        "TestEvidenceManagerEnhancements"
      ],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 82,
      "end_lineno": 86,
      "decorators": [
        "pytest.fixture"
      ],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Create a temporary evidence directory.",
        "returns": null,
        "raw": "Create a temporary evidence directory."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_evidence_package_with_country_and_period",
      "qualname": "TestEvidenceManagerEnhancements.test_evidence_package_with_country_and_period",
      "enclosing": [
        "TestEvidenceManagerEnhancements"
      ],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 88,
      "end_lineno": 131,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_evidence_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test evidence package creation with country and period.",
        "returns": null,
        "raw": "Test evidence package creation with country and period."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_evidence_package_without_country_and_period",
      "qualname": "TestEvidenceManagerEnhancements.test_evidence_package_without_country_and_period",
      "enclosing": [
        "TestEvidenceManagerEnhancements"
      ],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 133,
      "end_lineno": 154,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_evidence_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test evidence package creation without country and period (fallback).",
        "returns": null,
        "raw": "Test evidence package creation without country and period (fallback)."
      }
    },
    {
      "kind": "class",
      "name": "TestEvidenceManagerEnhancements",
      "qualname": "TestEvidenceManagerEnhancements",
      "enclosing": [],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 78,
      "end_lineno": 154,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Test enhanced evidence manager functionality.",
        "raw": "Test enhanced evidence manager functionality."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "temp_evidence_dir",
      "qualname": "TestDataSnapshotEnhancements.temp_evidence_dir",
      "enclosing": [
        "TestDataSnapshotEnhancements"
      ],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 161,
      "end_lineno": 165,
      "decorators": [
        "pytest.fixture"
      ],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Create a temporary evidence directory.",
        "returns": null,
        "raw": "Create a temporary evidence directory."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_snapshot_uses_tail",
      "qualname": "TestDataSnapshotEnhancements.test_snapshot_uses_tail",
      "enclosing": [
        "TestDataSnapshotEnhancements"
      ],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 167,
      "end_lineno": 208,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_evidence_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that data snapshot uses tail instead of head.",
        "returns": null,
        "raw": "Test that data snapshot uses tail instead of head."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_snapshot_small_dataframe",
      "qualname": "TestDataSnapshotEnhancements.test_snapshot_small_dataframe",
      "enclosing": [
        "TestDataSnapshotEnhancements"
      ],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 210,
      "end_lineno": 235,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_evidence_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test snapshot with DataFrame smaller than 1000 rows.",
        "returns": null,
        "raw": "Test snapshot with DataFrame smaller than 1000 rows."
      }
    },
    {
      "kind": "class",
      "name": "TestDataSnapshotEnhancements",
      "qualname": "TestDataSnapshotEnhancements",
      "enclosing": [],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 157,
      "end_lineno": 235,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Test data snapshot enhancements (tail instead of head).",
        "raw": "Test data snapshot enhancements (tail instead of head)."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "temp_evidence_dir",
      "qualname": "TestFullParameterLogging.temp_evidence_dir",
      "enclosing": [
        "TestFullParameterLogging"
      ],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 242,
      "end_lineno": 246,
      "decorators": [
        "pytest.fixture"
      ],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Create a temporary evidence directory.",
        "returns": null,
        "raw": "Create a temporary evidence directory."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_full_params_logged",
      "qualname": "TestFullParameterLogging.test_full_params_logged",
      "enclosing": [
        "TestFullParameterLogging"
      ],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 248,
      "end_lineno": 281,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_evidence_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that all parameters are logged in 02_query_parameters.json.",
        "returns": null,
        "raw": "Test that all parameters are logged in 02_query_parameters.json."
      }
    },
    {
      "kind": "class",
      "name": "TestFullParameterLogging",
      "qualname": "TestFullParameterLogging",
      "enclosing": [],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 238,
      "end_lineno": 281,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Test full parameter logging in evidence.",
        "raw": "Test full parameter logging in evidence."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "run_all_tests",
      "qualname": "run_all_tests",
      "enclosing": [],
      "module": "tests.test_evidence_enhancements",
      "file": "tests\\test_evidence_enhancements.py",
      "lineno": 284,
      "end_lineno": 344,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Run all tests manually.",
        "returns": null,
        "raw": "Run all tests manually."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fetch_live_fixtures_importable",
      "qualname": "test_fetch_live_fixtures_importable",
      "enclosing": [],
      "module": "tests.test_fetch_live_fixtures",
      "file": "tests\\test_fetch_live_fixtures.py",
      "lineno": 11,
      "end_lineno": 16,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that fetch_live_fixtures script can be imported.",
        "returns": null,
        "raw": "Test that fetch_live_fixtures script can be imported."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fetch_live_fixtures_has_expected_items",
      "qualname": "test_fetch_live_fixtures_has_expected_items",
      "enclosing": [],
      "module": "tests.test_fetch_live_fixtures",
      "file": "tests\\test_fetch_live_fixtures.py",
      "lineno": 19,
      "end_lineno": 33,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that ITEMS_TO_FETCH contains the expected IPEs.",
        "returns": null,
        "raw": "Test that ITEMS_TO_FETCH contains the expected IPEs."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fetch_live_fixtures_entity_path_logic",
      "qualname": "test_fetch_live_fixtures_entity_path_logic",
      "enclosing": [],
      "module": "tests.test_fetch_live_fixtures",
      "file": "tests\\test_fetch_live_fixtures.py",
      "lineno": 36,
      "end_lineno": 47,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that the entity-specific path logic is correct.",
        "returns": null,
        "raw": "Test that the entity-specific path logic is correct."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fetch_live_fixtures_get_output_dir",
      "qualname": "test_fetch_live_fixtures_get_output_dir",
      "enclosing": [],
      "module": "tests.test_fetch_live_fixtures",
      "file": "tests\\test_fetch_live_fixtures.py",
      "lineno": 50,
      "end_lineno": 66,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that get_output_dir helper function works correctly.",
        "returns": null,
        "raw": "Test that get_output_dir helper function works correctly."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fetch_live_fixtures_different_entities",
      "qualname": "test_fetch_live_fixtures_different_entities",
      "enclosing": [],
      "module": "tests.test_fetch_live_fixtures",
      "file": "tests\\test_fetch_live_fixtures.py",
      "lineno": 69,
      "end_lineno": 81,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that different entities create different paths.",
        "returns": null,
        "raw": "Test that different entities create different paths."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fetch_live_fixtures_entity_whitelist",
      "qualname": "test_fetch_live_fixtures_entity_whitelist",
      "enclosing": [],
      "module": "tests.test_fetch_live_fixtures",
      "file": "tests\\test_fetch_live_fixtures.py",
      "lineno": 84,
      "end_lineno": 96,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that ALLOWED_ENTITIES whitelist exists and contains expected entities.",
        "returns": null,
        "raw": "Test that ALLOWED_ENTITIES whitelist exists and contains expected entities."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fetch_live_fixtures_date_constants",
      "qualname": "test_fetch_live_fixtures_date_constants",
      "enclosing": [],
      "module": "tests.test_fetch_live_fixtures",
      "file": "tests\\test_fetch_live_fixtures.py",
      "lineno": 99,
      "end_lineno": 115,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that date configuration constants are defined.",
        "returns": null,
        "raw": "Test that date configuration constants are defined."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_loads_from_company_subfolder_when_available",
      "qualname": "TestExtractionPipelineSubfolderLoading.test_loads_from_company_subfolder_when_available",
      "enclosing": [
        "TestExtractionPipelineSubfolderLoading"
      ],
      "module": "tests.test_fixture_subfolder_loading",
      "file": "tests\\test_fixture_subfolder_loading.py",
      "lineno": 19,
      "end_lineno": 54,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that fixture is loaded from company subfolder when available.",
        "returns": null,
        "raw": "Test that fixture is loaded from company subfolder when available."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_falls_back_to_root_fixtures_when_company_not_found",
      "qualname": "TestExtractionPipelineSubfolderLoading.test_falls_back_to_root_fixtures_when_company_not_found",
      "enclosing": [
        "TestExtractionPipelineSubfolderLoading"
      ],
      "module": "tests.test_fixture_subfolder_loading",
      "file": "tests\\test_fixture_subfolder_loading.py",
      "lineno": 56,
      "end_lineno": 90,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test fallback to root fixtures when company-specific file not found.",
        "returns": null,
        "raw": "Test fallback to root fixtures when company-specific file not found."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_returns_empty_when_no_fixture_found",
      "qualname": "TestExtractionPipelineSubfolderLoading.test_returns_empty_when_no_fixture_found",
      "enclosing": [
        "TestExtractionPipelineSubfolderLoading"
      ],
      "module": "tests.test_fixture_subfolder_loading",
      "file": "tests\\test_fixture_subfolder_loading.py",
      "lineno": 92,
      "end_lineno": 116,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that empty DataFrame is returned when no fixture found.",
        "returns": null,
        "raw": "Test that empty DataFrame is returned when no fixture found."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_prefers_company_subfolder_over_root",
      "qualname": "TestExtractionPipelineSubfolderLoading.test_prefers_company_subfolder_over_root",
      "enclosing": [
        "TestExtractionPipelineSubfolderLoading"
      ],
      "module": "tests.test_fixture_subfolder_loading",
      "file": "tests\\test_fixture_subfolder_loading.py",
      "lineno": 118,
      "end_lineno": 163,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that company subfolder is preferred over root fixtures.",
        "returns": null,
        "raw": "Test that company subfolder is preferred over root fixtures."
      }
    },
    {
      "kind": "class",
      "name": "TestExtractionPipelineSubfolderLoading",
      "qualname": "TestExtractionPipelineSubfolderLoading",
      "enclosing": [],
      "module": "tests.test_fixture_subfolder_loading",
      "file": "tests\\test_fixture_subfolder_loading.py",
      "lineno": 16,
      "end_lineno": 163,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for ExtractionPipeline fixture loading with company subfolders.",
        "raw": "Tests for ExtractionPipeline fixture loading with company subfolders."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_loads_jdash_from_company_subfolder",
      "qualname": "TestJDashLoaderSubfolderLoading.test_loads_jdash_from_company_subfolder",
      "enclosing": [
        "TestJDashLoaderSubfolderLoading"
      ],
      "module": "tests.test_fixture_subfolder_loading",
      "file": "tests\\test_fixture_subfolder_loading.py",
      "lineno": 169,
      "end_lineno": 201,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that JDASH fixture is loaded from company subfolder when available.",
        "returns": null,
        "raw": "Test that JDASH fixture is loaded from company subfolder when available."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_jdash_falls_back_to_root_fixtures",
      "qualname": "TestJDashLoaderSubfolderLoading.test_jdash_falls_back_to_root_fixtures",
      "enclosing": [
        "TestJDashLoaderSubfolderLoading"
      ],
      "module": "tests.test_fixture_subfolder_loading",
      "file": "tests\\test_fixture_subfolder_loading.py",
      "lineno": 203,
      "end_lineno": 232,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test JDASH fallback to root fixtures when company-specific not found.",
        "returns": null,
        "raw": "Test JDASH fallback to root fixtures when company-specific not found."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_jdash_prefers_company_over_root",
      "qualname": "TestJDashLoaderSubfolderLoading.test_jdash_prefers_company_over_root",
      "enclosing": [
        "TestJDashLoaderSubfolderLoading"
      ],
      "module": "tests.test_fixture_subfolder_loading",
      "file": "tests\\test_fixture_subfolder_loading.py",
      "lineno": 234,
      "end_lineno": 272,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that JDASH prefers company subfolder over root fixtures.",
        "returns": null,
        "raw": "Test that JDASH prefers company subfolder over root fixtures."
      }
    },
    {
      "kind": "class",
      "name": "TestJDashLoaderSubfolderLoading",
      "qualname": "TestJDashLoaderSubfolderLoading",
      "enclosing": [],
      "module": "tests.test_fixture_subfolder_loading",
      "file": "tests\\test_fixture_subfolder_loading.py",
      "lineno": 166,
      "end_lineno": 272,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for JDASH loader with company subfolder support.",
        "raw": "Tests for JDASH loader with company subfolder support."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fx_converter_init_valid",
      "qualname": "test_fx_converter_init_valid",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 20,
      "end_lineno": 32,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test FXConverter initialization with valid CR_05 data.",
        "returns": null,
        "raw": "Test FXConverter initialization with valid CR_05 data."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fx_converter_init_empty_df",
      "qualname": "test_fx_converter_init_empty_df",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 35,
      "end_lineno": 40,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test FXConverter raises error with empty DataFrame.",
        "returns": null,
        "raw": "Test FXConverter raises error with empty DataFrame."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fx_converter_init_none",
      "qualname": "test_fx_converter_init_none",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 43,
      "end_lineno": 46,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test FXConverter raises error with None input.",
        "returns": null,
        "raw": "Test FXConverter raises error with None input."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fx_converter_init_missing_columns",
      "qualname": "test_fx_converter_init_missing_columns",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 49,
      "end_lineno": 56,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test FXConverter raises error when required columns are missing.",
        "returns": null,
        "raw": "Test FXConverter raises error when required columns are missing."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fx_converter_init_with_nulls",
      "qualname": "test_fx_converter_init_with_nulls",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 59,
      "end_lineno": 71,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test FXConverter handles null values correctly during initialization.",
        "returns": null,
        "raw": "Test FXConverter handles null values correctly during initialization."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_convert_to_usd_basic",
      "qualname": "test_convert_to_usd_basic",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 74,
      "end_lineno": 88,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test basic USD conversion.",
        "returns": null,
        "raw": "Test basic USD conversion."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_convert_to_usd_unknown_company",
      "qualname": "test_convert_to_usd_unknown_company",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 91,
      "end_lineno": 102,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test conversion with unknown company code uses default rate.",
        "returns": null,
        "raw": "Test conversion with unknown company code uses default rate."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_convert_to_usd_null_amount",
      "qualname": "test_convert_to_usd_null_amount",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 105,
      "end_lineno": 118,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test conversion with null/NaN amount returns 0.",
        "returns": null,
        "raw": "Test conversion with null/NaN amount returns 0."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_convert_to_usd_null_company",
      "qualname": "test_convert_to_usd_null_company",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 121,
      "end_lineno": 131,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test conversion with null company code uses default rate.",
        "returns": null,
        "raw": "Test conversion with null company code uses default rate."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_convert_series_to_usd",
      "qualname": "test_convert_series_to_usd",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 134,
      "end_lineno": 150,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test vectorized series conversion.",
        "returns": null,
        "raw": "Test vectorized series conversion."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_convert_series_to_usd_length_mismatch",
      "qualname": "test_convert_series_to_usd_length_mismatch",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 153,
      "end_lineno": 166,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that series conversion raises error on length mismatch.",
        "returns": null,
        "raw": "Test that series conversion raises error on length mismatch."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_convert_series_with_mixed_valid_invalid",
      "qualname": "test_convert_series_with_mixed_valid_invalid",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 169,
      "end_lineno": 187,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test series conversion with mix of valid and invalid companies.",
        "returns": null,
        "raw": "Test series conversion with mix of valid and invalid companies."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fx_converter_custom_default_rate",
      "qualname": "test_fx_converter_custom_default_rate",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 190,
      "end_lineno": 202,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test FXConverter with custom default rate.",
        "returns": null,
        "raw": "Test FXConverter with custom default rate."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_fx_converter_real_world_scenario",
      "qualname": "test_fx_converter_real_world_scenario",
      "enclosing": [],
      "module": "tests.test_fx_utils",
      "file": "tests\\test_fx_utils.py",
      "lineno": 205,
      "end_lineno": 224,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test FXConverter with realistic data scenario.",
        "returns": null,
        "raw": "Test FXConverter with realistic data scenario."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_json_formatter_fields",
      "qualname": "test_json_formatter_fields",
      "enclosing": [],
      "module": "tests.test_logging_config",
      "file": "tests\\test_logging_config.py",
      "lineno": 19,
      "end_lineno": 51,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that CustomJsonFormatter adds the expected standard fields.",
        "returns": null,
        "raw": "Test that CustomJsonFormatter adds the expected standard fields."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_json_formatter_with_extra_fields",
      "qualname": "test_json_formatter_with_extra_fields",
      "enclosing": [],
      "module": "tests.test_logging_config",
      "file": "tests\\test_logging_config.py",
      "lineno": 54,
      "end_lineno": 84,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that extra fields are included in JSON output.",
        "returns": null,
        "raw": "Test that extra fields are included in JSON output."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_setup_logging_json_format",
      "qualname": "test_setup_logging_json_format",
      "enclosing": [],
      "module": "tests.test_logging_config",
      "file": "tests\\test_logging_config.py",
      "lineno": 87,
      "end_lineno": 149,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that setup_logging configures JSON formatting correctly.",
        "returns": null,
        "raw": "Test that setup_logging configures JSON formatting correctly."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_setup_logging_standard_format",
      "qualname": "test_setup_logging_standard_format",
      "enclosing": [],
      "module": "tests.test_logging_config",
      "file": "tests\\test_logging_config.py",
      "lineno": 152,
      "end_lineno": 207,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that setup_logging can use standard formatting.",
        "returns": null,
        "raw": "Test that setup_logging can use standard formatting."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_get_logger",
      "qualname": "test_get_logger",
      "enclosing": [],
      "module": "tests.test_logging_config",
      "file": "tests\\test_logging_config.py",
      "lineno": 210,
      "end_lineno": 216,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that get_logger returns a properly configured logger.",
        "returns": null,
        "raw": "Test that get_logger returns a properly configured logger."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_logging_levels",
      "qualname": "test_logging_levels",
      "enclosing": [],
      "module": "tests.test_logging_config",
      "file": "tests\\test_logging_config.py",
      "lineno": 219,
      "end_lineno": 251,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that different logging levels work correctly with JSON format.",
        "returns": null,
        "raw": "Test that different logging levels work correctly with JSON format."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "temp_output_dir",
      "qualname": "temp_output_dir",
      "enclosing": [],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 21,
      "end_lineno": 23,
      "decorators": [
        "pytest.fixture"
      ],
      "parameters": [
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Create a temporary directory for test outputs.",
        "returns": null,
        "raw": "Create a temporary directory for test outputs."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_no_duplicates_clean_merge",
      "qualname": "TestAuditMerge.test_no_duplicates_clean_merge",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 29,
      "end_lineno": 56,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_output_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test audit_merge with clean data (no duplicates).",
        "returns": null,
        "raw": "Test audit_merge with clean data (no duplicates)."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_left_duplicates_only",
      "qualname": "TestAuditMerge.test_left_duplicates_only",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 58,
      "end_lineno": 83,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_output_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test audit_merge with duplicates in left DataFrame only.",
        "returns": null,
        "raw": "Test audit_merge with duplicates in left DataFrame only."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_right_duplicates_only",
      "qualname": "TestAuditMerge.test_right_duplicates_only",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 85,
      "end_lineno": 110,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_output_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test audit_merge with duplicates in right DataFrame only.",
        "returns": null,
        "raw": "Test audit_merge with duplicates in right DataFrame only."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_both_sides_duplicates_cartesian_risk",
      "qualname": "TestAuditMerge.test_both_sides_duplicates_cartesian_risk",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 112,
      "end_lineno": 131,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_output_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test audit_merge with duplicates on both sides (Cartesian product risk).",
        "returns": null,
        "raw": "Test audit_merge with duplicates on both sides (Cartesian product risk)."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_multiple_join_keys",
      "qualname": "TestAuditMerge.test_multiple_join_keys",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 133,
      "end_lineno": 155,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_output_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test audit_merge with multiple join columns.",
        "returns": null,
        "raw": "Test audit_merge with multiple join columns."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_single_key_as_string",
      "qualname": "TestAuditMerge.test_single_key_as_string",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 157,
      "end_lineno": 165,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_output_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that single key can be passed as string (not list).",
        "returns": null,
        "raw": "Test that single key can be passed as string (not list)."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_missing_column_in_left",
      "qualname": "TestAuditMerge.test_missing_column_in_left",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 167,
      "end_lineno": 173,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_output_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test error handling when join column is missing in left DataFrame.",
        "returns": null,
        "raw": "Test error handling when join column is missing in left DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_missing_column_in_right",
      "qualname": "TestAuditMerge.test_missing_column_in_right",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 175,
      "end_lineno": 181,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_output_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test error handling when join column is missing in right DataFrame.",
        "returns": null,
        "raw": "Test error handling when join column is missing in right DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_empty_dataframes",
      "qualname": "TestAuditMerge.test_empty_dataframes",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 183,
      "end_lineno": 194,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_output_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test audit_merge with empty DataFrames.",
        "returns": null,
        "raw": "Test audit_merge with empty DataFrames."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_output_directory_creation",
      "qualname": "TestAuditMerge.test_output_directory_creation",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 196,
      "end_lineno": 208,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that output directory is created if it doesn't exist.",
        "returns": null,
        "raw": "Test that output directory is created if it doesn't exist."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_many_duplicates",
      "qualname": "TestAuditMerge.test_many_duplicates",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 210,
      "end_lineno": 231,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_output_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with many duplicate keys to verify counting logic.",
        "returns": null,
        "raw": "Test with many duplicate keys to verify counting logic."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_real_world_financial_scenario",
      "qualname": "TestAuditMerge.test_real_world_financial_scenario",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 233,
      "end_lineno": 263,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_output_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with realistic financial data scenario.",
        "returns": null,
        "raw": "Test with realistic financial data scenario."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_log_file_append_mode",
      "qualname": "TestAuditMerge.test_log_file_append_mode",
      "enclosing": [
        "TestAuditMerge"
      ],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 265,
      "end_lineno": 285,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "temp_output_dir",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that multiple audits append to the same log file.",
        "returns": null,
        "raw": "Test that multiple audits append to the same log file."
      }
    },
    {
      "kind": "class",
      "name": "TestAuditMerge",
      "qualname": "TestAuditMerge",
      "enclosing": [],
      "module": "tests.test_merge_utils",
      "file": "tests\\test_merge_utils.py",
      "lineno": 26,
      "end_lineno": 285,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Test suite for audit_merge function.",
        "raw": "Test suite for audit_merge function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_fixture_loading_with_company_parameter",
      "qualname": "TestMultiEntityFixtureLoading.test_fixture_loading_with_company_parameter",
      "enclosing": [
        "TestMultiEntityFixtureLoading"
      ],
      "module": "tests.test_multi_entity_fixtures",
      "file": "tests\\test_multi_entity_fixtures.py",
      "lineno": 21,
      "end_lineno": 49,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that fixtures are loaded from company-specific directory when company is set.",
        "returns": null,
        "raw": "Test that fixtures are loaded from company-specific directory when company is set."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_fixture_loading_fallback_to_root",
      "qualname": "TestMultiEntityFixtureLoading.test_fixture_loading_fallback_to_root",
      "enclosing": [
        "TestMultiEntityFixtureLoading"
      ],
      "module": "tests.test_multi_entity_fixtures",
      "file": "tests\\test_multi_entity_fixtures.py",
      "lineno": 51,
      "end_lineno": 77,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "tmp_path",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that fixtures fall back to root directory when company-specific not found.",
        "returns": null,
        "raw": "Test that fixtures fall back to root directory when company-specific not found."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_country_code_extraction_from_company_param",
      "qualname": "TestMultiEntityFixtureLoading.test_country_code_extraction_from_company_param",
      "enclosing": [
        "TestMultiEntityFixtureLoading"
      ],
      "module": "tests.test_multi_entity_fixtures",
      "file": "tests\\test_multi_entity_fixtures.py",
      "lineno": 79,
      "end_lineno": 88,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that country_code is correctly extracted from company parameter.",
        "returns": null,
        "raw": "Test that country_code is correctly extracted from company parameter."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_country_code_extraction_from_id_companies_active",
      "qualname": "TestMultiEntityFixtureLoading.test_country_code_extraction_from_id_companies_active",
      "enclosing": [
        "TestMultiEntityFixtureLoading"
      ],
      "module": "tests.test_multi_entity_fixtures",
      "file": "tests\\test_multi_entity_fixtures.py",
      "lineno": 90,
      "end_lineno": 98,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that country_code is extracted from id_companies_active when company not set.",
        "returns": null,
        "raw": "Test that country_code is extracted from id_companies_active when company not set."
      }
    },
    {
      "kind": "class",
      "name": "TestMultiEntityFixtureLoading",
      "qualname": "TestMultiEntityFixtureLoading",
      "enclosing": [],
      "module": "tests.test_multi_entity_fixtures",
      "file": "tests\\test_multi_entity_fixtures.py",
      "lineno": 18,
      "end_lineno": 98,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Test multi-entity fixture loading logic.",
        "raw": "Test multi-entity fixture loading logic."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_vtc_receives_cutoff_date_in_reconciliation",
      "qualname": "TestVTCDateWiring.test_vtc_receives_cutoff_date_in_reconciliation",
      "enclosing": [
        "TestVTCDateWiring"
      ],
      "module": "tests.test_multi_entity_fixtures",
      "file": "tests\\test_multi_entity_fixtures.py",
      "lineno": 104,
      "end_lineno": 148,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that run_reconciliation passes cutoff_date to calculate_vtc_adjustment.",
        "returns": null,
        "raw": "Test that run_reconciliation passes cutoff_date to calculate_vtc_adjustment."
      }
    },
    {
      "kind": "class",
      "name": "TestVTCDateWiring",
      "qualname": "TestVTCDateWiring",
      "enclosing": [],
      "module": "tests.test_multi_entity_fixtures",
      "file": "tests\\test_multi_entity_fixtures.py",
      "lineno": 101,
      "end_lineno": 148,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Test that VTC adjustment receives cutoff_date parameter.",
        "raw": "Test that VTC adjustment receives cutoff_date parameter."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_company_param_in_load_all_data",
      "qualname": "TestScriptParameterFlow.test_company_param_in_load_all_data",
      "enclosing": [
        "TestScriptParameterFlow"
      ],
      "module": "tests.test_multi_entity_fixtures",
      "file": "tests\\test_multi_entity_fixtures.py",
      "lineno": 154,
      "end_lineno": 182,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that company parameter is used in load_all_data.",
        "returns": null,
        "raw": "Test that company parameter is used in load_all_data."
      }
    },
    {
      "kind": "class",
      "name": "TestScriptParameterFlow",
      "qualname": "TestScriptParameterFlow",
      "enclosing": [],
      "module": "tests.test_multi_entity_fixtures",
      "file": "tests\\test_multi_entity_fixtures.py",
      "lineno": 151,
      "end_lineno": 182,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Test that --company parameter flows correctly through the system.",
        "raw": "Test that --company parameter flows correctly through the system."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_okta_authentication",
      "qualname": "test_okta_authentication",
      "enclosing": [],
      "module": "tests.test_okta_auth",
      "file": "tests\\test_okta_auth.py",
      "lineno": 25,
      "end_lineno": 65,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test basic Okta authentication.",
        "returns": null,
        "raw": "Test basic Okta authentication."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_secrets_manager_with_okta",
      "qualname": "test_secrets_manager_with_okta",
      "enclosing": [],
      "module": "tests.test_okta_auth",
      "file": "tests\\test_okta_auth.py",
      "lineno": 68,
      "end_lineno": 99,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test AWS Secrets Manager access with Okta.",
        "returns": null,
        "raw": "Test AWS Secrets Manager access with Okta."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_s3_with_okta",
      "qualname": "test_s3_with_okta",
      "enclosing": [],
      "module": "tests.test_okta_auth",
      "file": "tests\\test_okta_auth.py",
      "lineno": 102,
      "end_lineno": 130,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test S3 access with Okta.",
        "returns": null,
        "raw": "Test S3 access with Okta."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_credentials_caching",
      "qualname": "test_credentials_caching",
      "enclosing": [],
      "module": "tests.test_okta_auth",
      "file": "tests\\test_okta_auth.py",
      "lineno": 133,
      "end_lineno": 160,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that credentials are properly cached.",
        "returns": null,
        "raw": "Test that credentials are properly cached."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "tests.test_okta_auth",
      "file": "tests\\test_okta_auth.py",
      "lineno": 163,
      "end_lineno": 214,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Run all Okta authentication tests.",
        "returns": null,
        "raw": "Run all Okta authentication tests."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_script_ast",
      "qualname": "get_script_ast",
      "enclosing": [],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 20,
      "end_lineno": 25,
      "decorators": [],
      "parameters": [
        {
          "name": "script_name",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Parse a script file and return its AST.",
        "returns": null,
        "raw": "Parse a script file and return its AST."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "get_imports_from_ast",
      "qualname": "get_imports_from_ast",
      "enclosing": [],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 28,
      "end_lineno": 39,
      "decorators": [],
      "parameters": [
        {
          "name": "tree",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Extract all imports from an AST.",
        "returns": null,
        "raw": "Extract all imports from an AST."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "has_string_literal_with_sql",
      "qualname": "has_string_literal_with_sql",
      "enclosing": [],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 42,
      "end_lineno": 53,
      "decorators": [],
      "parameters": [
        {
          "name": "tree",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Check if AST contains string literals that look like SQL queries.",
        "returns": null,
        "raw": "Check if AST contains string literals that look like SQL queries."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_no_hardcoded_sql",
      "qualname": "TestRunFullReconciliation.test_no_hardcoded_sql",
      "enclosing": [
        "TestRunFullReconciliation"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 59,
      "end_lineno": 63,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify no hardcoded SQL queries in run_full_reconciliation.py",
        "returns": null,
        "raw": "Verify no hardcoded SQL queries in run_full_reconciliation.py"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calls_compliant_subscripts",
      "qualname": "TestRunFullReconciliation.test_calls_compliant_subscripts",
      "enclosing": [
        "TestRunFullReconciliation"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 65,
      "end_lineno": 75,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify run_full_reconciliation.py calls scripts that use catalog",
        "returns": null,
        "raw": "Verify run_full_reconciliation.py calls scripts that use catalog"
      }
    },
    {
      "kind": "class",
      "name": "TestRunFullReconciliation",
      "qualname": "TestRunFullReconciliation",
      "enclosing": [],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 56,
      "end_lineno": 75,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for scripts/run_full_reconciliation.py",
        "raw": "Tests for scripts/run_full_reconciliation.py"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_imports_mssql_runner",
      "qualname": "TestRunDemo.test_imports_mssql_runner",
      "enclosing": [
        "TestRunDemo"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 81,
      "end_lineno": 87,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify run_demo.py imports IPERunner (MSSQL runner)",
        "returns": null,
        "raw": "Verify run_demo.py imports IPERunner (MSSQL runner)"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_imports_catalog",
      "qualname": "TestRunDemo.test_imports_catalog",
      "enclosing": [
        "TestRunDemo"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 89,
      "end_lineno": 95,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify run_demo.py imports from catalog.cpg1",
        "returns": null,
        "raw": "Verify run_demo.py imports from catalog.cpg1"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_imports_classifier",
      "qualname": "TestRunDemo.test_imports_classifier",
      "enclosing": [
        "TestRunDemo"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 97,
      "end_lineno": 103,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify run_demo.py imports classifier functions",
        "returns": null,
        "raw": "Verify run_demo.py imports classifier functions"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_loads_from_fixtures",
      "qualname": "TestRunDemo.test_loads_from_fixtures",
      "enclosing": [
        "TestRunDemo"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 105,
      "end_lineno": 111,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify run_demo.py loads data from tests/fixtures/",
        "returns": null,
        "raw": "Verify run_demo.py loads data from tests/fixtures/"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calls_classify_bridges",
      "qualname": "TestRunDemo.test_calls_classify_bridges",
      "enclosing": [
        "TestRunDemo"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 113,
      "end_lineno": 119,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify run_demo.py calls classify_bridges function",
        "returns": null,
        "raw": "Verify run_demo.py calls classify_bridges function"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_no_hardcoded_sql",
      "qualname": "TestRunDemo.test_no_hardcoded_sql",
      "enclosing": [
        "TestRunDemo"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 121,
      "end_lineno": 125,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify no hardcoded SQL queries in run_demo.py",
        "returns": null,
        "raw": "Verify no hardcoded SQL queries in run_demo.py"
      }
    },
    {
      "kind": "class",
      "name": "TestRunDemo",
      "qualname": "TestRunDemo",
      "enclosing": [],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 78,
      "end_lineno": 125,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for scripts/run_demo.py",
        "raw": "Tests for scripts/run_demo.py"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_imports_catalog",
      "qualname": "TestGenerationScripts.test_imports_catalog",
      "enclosing": [
        "TestGenerationScripts"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 136,
      "end_lineno": 142,
      "decorators": [
        "pytest.mark.parametrize('script_name', ['generate_customer_accounts', 'generate_collection_accounts', 'generate_other_ar'])"
      ],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "script_name",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify generation scripts import from catalog",
        "returns": null,
        "raw": "Verify generation scripts import from catalog"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_uses_get_item_by_id",
      "qualname": "TestGenerationScripts.test_uses_get_item_by_id",
      "enclosing": [
        "TestGenerationScripts"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 149,
      "end_lineno": 155,
      "decorators": [
        "pytest.mark.parametrize('script_name', ['generate_customer_accounts', 'generate_collection_accounts', 'generate_other_ar'])"
      ],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "script_name",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify generation scripts call get_item_by_id to fetch catalog items",
        "returns": null,
        "raw": "Verify generation scripts call get_item_by_id to fetch catalog items"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_fetches_sql_from_catalog",
      "qualname": "TestGenerationScripts.test_fetches_sql_from_catalog",
      "enclosing": [
        "TestGenerationScripts"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 162,
      "end_lineno": 169,
      "decorators": [
        "pytest.mark.parametrize('script_name', ['generate_customer_accounts', 'generate_collection_accounts', 'generate_other_ar'])"
      ],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "script_name",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify generation scripts fetch SQL from catalog item.sql_query",
        "returns": null,
        "raw": "Verify generation scripts fetch SQL from catalog item.sql_query"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_no_hardcoded_sql",
      "qualname": "TestGenerationScripts.test_no_hardcoded_sql",
      "enclosing": [
        "TestGenerationScripts"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 176,
      "end_lineno": 180,
      "decorators": [
        "pytest.mark.parametrize('script_name', ['generate_customer_accounts', 'generate_collection_accounts', 'generate_other_ar'])"
      ],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "script_name",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify no hardcoded SQL queries in generation scripts",
        "returns": null,
        "raw": "Verify no hardcoded SQL queries in generation scripts"
      }
    },
    {
      "kind": "class",
      "name": "TestGenerationScripts",
      "qualname": "TestGenerationScripts",
      "enclosing": [],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 128,
      "end_lineno": 180,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for individual IPE generation scripts",
        "raw": "Tests for individual IPE generation scripts"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_imports_classifier",
      "qualname": "TestClassifyBridges.test_imports_classifier",
      "enclosing": [
        "TestClassifyBridges"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 186,
      "end_lineno": 192,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify classify_bridges.py imports from src.bridges.classifier",
        "returns": null,
        "raw": "Verify classify_bridges.py imports from src.bridges.classifier"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_imports_rules_catalog",
      "qualname": "TestClassifyBridges.test_imports_rules_catalog",
      "enclosing": [
        "TestClassifyBridges"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 194,
      "end_lineno": 200,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify classify_bridges.py imports load_rules from bridges.catalog",
        "returns": null,
        "raw": "Verify classify_bridges.py imports load_rules from bridges.catalog"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calls_classify_bridges",
      "qualname": "TestClassifyBridges.test_calls_classify_bridges",
      "enclosing": [
        "TestClassifyBridges"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 202,
      "end_lineno": 208,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify classify_bridges.py calls classify_bridges function",
        "returns": null,
        "raw": "Verify classify_bridges.py calls classify_bridges function"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calls_load_rules",
      "qualname": "TestClassifyBridges.test_calls_load_rules",
      "enclosing": [
        "TestClassifyBridges"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 210,
      "end_lineno": 216,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify classify_bridges.py calls load_rules function",
        "returns": null,
        "raw": "Verify classify_bridges.py calls load_rules function"
      }
    },
    {
      "kind": "class",
      "name": "TestClassifyBridges",
      "qualname": "TestClassifyBridges",
      "enclosing": [],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 183,
      "end_lineno": 216,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for scripts/classify_bridges.py",
        "raw": "Tests for scripts/classify_bridges.py"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_ipe_07_has_sql_query",
      "qualname": "TestCatalogUsage.test_ipe_07_has_sql_query",
      "enclosing": [
        "TestCatalogUsage"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 222,
      "end_lineno": 229,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify IPE_07 catalog item has sql_query",
        "returns": null,
        "raw": "Verify IPE_07 catalog item has sql_query"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_cr_04_has_sql_query",
      "qualname": "TestCatalogUsage.test_cr_04_has_sql_query",
      "enclosing": [
        "TestCatalogUsage"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 231,
      "end_lineno": 238,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify CR_04 catalog item has sql_query",
        "returns": null,
        "raw": "Verify CR_04 catalog item has sql_query"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_ipe_31_has_sql_query",
      "qualname": "TestCatalogUsage.test_ipe_31_has_sql_query",
      "enclosing": [
        "TestCatalogUsage"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 240,
      "end_lineno": 247,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify IPE_31 catalog item has sql_query",
        "returns": null,
        "raw": "Verify IPE_31 catalog item has sql_query"
      }
    },
    {
      "kind": "class",
      "name": "TestCatalogUsage",
      "qualname": "TestCatalogUsage",
      "enclosing": [],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 219,
      "end_lineno": 247,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Integration tests to verify catalog items are properly structured",
        "raw": "Integration tests to verify catalog items are properly structured"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calculate_vtc_adjustment_available",
      "qualname": "TestClassifierFunctions.test_calculate_vtc_adjustment_available",
      "enclosing": [
        "TestClassifierFunctions"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 253,
      "end_lineno": 256,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify calculate_vtc_adjustment is importable",
        "returns": null,
        "raw": "Verify calculate_vtc_adjustment is importable"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_classify_bridges_available",
      "qualname": "TestClassifierFunctions.test_classify_bridges_available",
      "enclosing": [
        "TestClassifierFunctions"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 258,
      "end_lineno": 261,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify classify_bridges is importable",
        "returns": null,
        "raw": "Verify classify_bridges is importable"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calculate_customer_posting_group_bridge_available",
      "qualname": "TestClassifierFunctions.test_calculate_customer_posting_group_bridge_available",
      "enclosing": [
        "TestClassifierFunctions"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 263,
      "end_lineno": 266,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify calculate_customer_posting_group_bridge is importable",
        "returns": null,
        "raw": "Verify calculate_customer_posting_group_bridge is importable"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calculate_timing_difference_bridge_available",
      "qualname": "TestClassifierFunctions.test_calculate_timing_difference_bridge_available",
      "enclosing": [
        "TestClassifierFunctions"
      ],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 268,
      "end_lineno": 271,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Verify calculate_timing_difference_bridge is importable",
        "returns": null,
        "raw": "Verify calculate_timing_difference_bridge is importable"
      }
    },
    {
      "kind": "class",
      "name": "TestClassifierFunctions",
      "qualname": "TestClassifierFunctions",
      "enclosing": [],
      "module": "tests.test_orchestrator_audit",
      "file": "tests\\test_orchestrator_audit.py",
      "lineno": 250,
      "end_lineno": 271,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Verify classifier functions are available and functional",
        "raw": "Verify classifier functions are available and functional"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_row_count_check_pass_min_only",
      "qualname": "test_row_count_check_pass_min_only",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 28,
      "end_lineno": 36,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test RowCountCheck passes with minimum row count.",
        "returns": null,
        "raw": "Test RowCountCheck passes with minimum row count."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_row_count_check_pass_with_max",
      "qualname": "test_row_count_check_pass_with_max",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 39,
      "end_lineno": 47,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test RowCountCheck passes when within min and max bounds.",
        "returns": null,
        "raw": "Test RowCountCheck passes when within min and max bounds."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_row_count_check_fail_too_few",
      "qualname": "test_row_count_check_fail_too_few",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 50,
      "end_lineno": 59,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test RowCountCheck fails with too few rows.",
        "returns": null,
        "raw": "Test RowCountCheck fails with too few rows."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_row_count_check_fail_too_many",
      "qualname": "test_row_count_check_fail_too_many",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 62,
      "end_lineno": 70,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test RowCountCheck fails with too many rows.",
        "returns": null,
        "raw": "Test RowCountCheck fails with too many rows."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_row_count_check_empty_dataframe",
      "qualname": "test_row_count_check_empty_dataframe",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 73,
      "end_lineno": 81,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test RowCountCheck with empty DataFrame.",
        "returns": null,
        "raw": "Test RowCountCheck with empty DataFrame."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_column_exists_check_pass",
      "qualname": "test_column_exists_check_pass",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 88,
      "end_lineno": 96,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test ColumnExistsCheck passes when column exists.",
        "returns": null,
        "raw": "Test ColumnExistsCheck passes when column exists."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_column_exists_check_fail",
      "qualname": "test_column_exists_check_fail",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 99,
      "end_lineno": 108,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test ColumnExistsCheck fails when column missing.",
        "returns": null,
        "raw": "Test ColumnExistsCheck fails when column missing."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_column_exists_check_empty_dataframe",
      "qualname": "test_column_exists_check_empty_dataframe",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 111,
      "end_lineno": 118,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test ColumnExistsCheck with empty DataFrame.",
        "returns": null,
        "raw": "Test ColumnExistsCheck with empty DataFrame."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_numeric_sum_check_pass_zero",
      "qualname": "test_numeric_sum_check_pass_zero",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 125,
      "end_lineno": 133,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test NumericSumCheck passes when sum is zero and should be.",
        "returns": null,
        "raw": "Test NumericSumCheck passes when sum is zero and should be."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_numeric_sum_check_fail_not_zero",
      "qualname": "test_numeric_sum_check_fail_not_zero",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 136,
      "end_lineno": 144,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test NumericSumCheck fails when sum is not zero but should be.",
        "returns": null,
        "raw": "Test NumericSumCheck fails when sum is not zero but should be."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_numeric_sum_check_pass_non_zero",
      "qualname": "test_numeric_sum_check_pass_non_zero",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 147,
      "end_lineno": 155,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test NumericSumCheck passes when sum is non-zero and should be.",
        "returns": null,
        "raw": "Test NumericSumCheck passes when sum is non-zero and should be."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_numeric_sum_check_fail_zero_when_nonzero_expected",
      "qualname": "test_numeric_sum_check_fail_zero_when_nonzero_expected",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 158,
      "end_lineno": 166,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test NumericSumCheck fails when sum is zero but should be non-zero.",
        "returns": null,
        "raw": "Test NumericSumCheck fails when sum is zero but should be non-zero."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_numeric_sum_check_column_not_found",
      "qualname": "test_numeric_sum_check_column_not_found",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 169,
      "end_lineno": 177,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test NumericSumCheck fails when column doesn't exist.",
        "returns": null,
        "raw": "Test NumericSumCheck fails when column doesn't exist."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_numeric_sum_check_non_numeric_column",
      "qualname": "test_numeric_sum_check_non_numeric_column",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 180,
      "end_lineno": 187,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test NumericSumCheck fails gracefully with non-numeric data.",
        "returns": null,
        "raw": "Test NumericSumCheck fails gracefully with non-numeric data."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_no_nulls_check_pass",
      "qualname": "test_no_nulls_check_pass",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 194,
      "end_lineno": 202,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test NoNullsCheck passes when no nulls present.",
        "returns": null,
        "raw": "Test NoNullsCheck passes when no nulls present."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_no_nulls_check_fail_with_nulls",
      "qualname": "test_no_nulls_check_fail_with_nulls",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 205,
      "end_lineno": 214,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test NoNullsCheck fails when nulls present.",
        "returns": null,
        "raw": "Test NoNullsCheck fails when nulls present."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_no_nulls_check_column_not_found",
      "qualname": "test_no_nulls_check_column_not_found",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 217,
      "end_lineno": 225,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test NoNullsCheck fails when column doesn't exist.",
        "returns": null,
        "raw": "Test NoNullsCheck fails when column doesn't exist."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_no_nulls_check_with_nan",
      "qualname": "test_no_nulls_check_with_nan",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 228,
      "end_lineno": 236,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test NoNullsCheck detects NaN values.",
        "returns": null,
        "raw": "Test NoNullsCheck detects NaN values."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_quality_engine_all_pass",
      "qualname": "test_quality_engine_all_pass",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 243,
      "end_lineno": 264,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test DataQualityEngine with all checks passing.",
        "returns": null,
        "raw": "Test DataQualityEngine with all checks passing."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_quality_engine_some_fail",
      "qualname": "test_quality_engine_some_fail",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 267,
      "end_lineno": 288,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test DataQualityEngine with some checks failing.",
        "returns": null,
        "raw": "Test DataQualityEngine with some checks failing."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_quality_engine_empty_rules",
      "qualname": "test_quality_engine_empty_rules",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 291,
      "end_lineno": 299,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test DataQualityEngine with no rules.",
        "returns": null,
        "raw": "Test DataQualityEngine with no rules."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_quality_engine_empty_dataframe",
      "qualname": "test_quality_engine_empty_dataframe",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 302,
      "end_lineno": 315,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test DataQualityEngine with empty DataFrame.",
        "returns": null,
        "raw": "Test DataQualityEngine with empty DataFrame."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_quality_report_string_representation",
      "qualname": "test_quality_report_string_representation",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 318,
      "end_lineno": 331,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test QualityReport string formatting.",
        "returns": null,
        "raw": "Test QualityReport string formatting."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_integration_realistic_scenario",
      "qualname": "test_integration_realistic_scenario",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 338,
      "end_lineno": 363,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test a realistic scenario with multiple quality checks.",
        "returns": null,
        "raw": "Test a realistic scenario with multiple quality checks."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_integration_failing_scenario",
      "qualname": "test_integration_failing_scenario",
      "enclosing": [],
      "module": "tests.test_quality_checker",
      "file": "tests\\test_quality_checker.py",
      "lineno": 366,
      "end_lineno": 387,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test a scenario where extracted data has quality issues.",
        "returns": null,
        "raw": "Test a scenario where extracted data has quality issues."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_ipe_extraction",
      "qualname": "test_ipe_extraction",
      "enclosing": [],
      "module": "tests.test_single_ipe_extraction",
      "file": "tests\\test_single_ipe_extraction.py",
      "lineno": 30,
      "end_lineno": 171,
      "decorators": [],
      "parameters": [
        {
          "name": "ipe_id",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "'IPE_07'"
        },
        {
          "name": "cutoff_date",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": "None"
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test complete IPE extraction with validation and evidence generation.",
        "returns": "bool: True if test passes, False otherwise",
        "raw": "Test complete IPE extraction with validation and evidence generation.\n\nArgs:\n    ipe_id: IPE to test (default: IPE_07)\n    cutoff_date: Cutoff date for extraction (default: from env or 2024-01-01)\n\nReturns:\n    bool: True if test passes, False otherwise"
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "tests.test_single_ipe_extraction",
      "file": "tests\\test_single_ipe_extraction.py",
      "lineno": 174,
      "end_lineno": 220,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Run single IPE extraction test.",
        "returns": null,
        "raw": "Run single IPE extraction test."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_catalog_has_ipe_07_with_sql",
      "qualname": "test_catalog_has_ipe_07_with_sql",
      "enclosing": [],
      "module": "tests.test_smoke_catalog_and_scripts",
      "file": "tests\\test_smoke_catalog_and_scripts.py",
      "lineno": 12,
      "end_lineno": 50,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test IPE_07 query is aligned with 2025 audited baseline (temp tables, LOAN-REC-NAT).",
        "returns": null,
        "raw": "Test IPE_07 query is aligned with 2025 audited baseline (temp tables, LOAN-REC-NAT)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_catalog_has_ipe_08_with_sql_and_sources",
      "qualname": "test_catalog_has_ipe_08_with_sql_and_sources",
      "enclosing": [],
      "module": "tests.test_smoke_catalog_and_scripts",
      "file": "tests\\test_smoke_catalog_and_scripts.py",
      "lineno": 53,
      "end_lineno": 95,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_catalog_has_cr_03_with_sql_and_sources",
      "qualname": "test_catalog_has_cr_03_with_sql_and_sources",
      "enclosing": [],
      "module": "tests.test_smoke_catalog_and_scripts",
      "file": "tests\\test_smoke_catalog_and_scripts.py",
      "lineno": 98,
      "end_lineno": 126,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_catalog_cr_04_aligned_with_baseline",
      "qualname": "test_catalog_cr_04_aligned_with_baseline",
      "enclosing": [],
      "module": "tests.test_smoke_catalog_and_scripts",
      "file": "tests\\test_smoke_catalog_and_scripts.py",
      "lineno": 127,
      "end_lineno": 163,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test CR_04 query is aligned with Query 2 from CR_03_04 mapping (IA baseline).",
        "returns": null,
        "raw": "Test CR_04 query is aligned with Query 2 from CR_03_04 mapping (IA baseline)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_catalog_ipe_10_aligned_with_baseline",
      "qualname": "test_catalog_ipe_10_aligned_with_baseline",
      "enclosing": [],
      "module": "tests.test_smoke_catalog_and_scripts",
      "file": "tests\\test_smoke_catalog_and_scripts.py",
      "lineno": 166,
      "end_lineno": 202,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test IPE_10 query is aligned with audited baseline (parameterized dates).",
        "returns": null,
        "raw": "Test IPE_10 query is aligned with audited baseline (parameterized dates)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_catalog_ipe_31_aligned_with_baseline",
      "qualname": "test_catalog_ipe_31_aligned_with_baseline",
      "enclosing": [],
      "module": "tests.test_smoke_catalog_and_scripts",
      "file": "tests\\test_smoke_catalog_and_scripts.py",
      "lineno": 205,
      "end_lineno": 270,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test IPE_31 query is aligned with audited baseline (parameterized, 11 tables, no @subsequentmonth).",
        "returns": null,
        "raw": "Test IPE_31 query is aligned with audited baseline (parameterized, 11 tables, no @subsequentmonth)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_catalog_doc_voucher_usage_with_sql_and_sources",
      "qualname": "test_catalog_doc_voucher_usage_with_sql_and_sources",
      "enclosing": [],
      "module": "tests.test_smoke_catalog_and_scripts",
      "file": "tests\\test_smoke_catalog_and_scripts.py",
      "lineno": 273,
      "end_lineno": 342,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test DOC_VOUCHER_USAGE query for Timing Difference Bridge (Usage May 2025 Query - Corrected).",
        "returns": null,
        "raw": "Test DOC_VOUCHER_USAGE query for Timing Difference Bridge (Usage May 2025 Query - Corrected)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_catalog_cr_05_aligned_with_baseline",
      "qualname": "test_catalog_cr_05_aligned_with_baseline",
      "enclosing": [],
      "module": "tests.test_smoke_catalog_and_scripts",
      "file": "tests\\test_smoke_catalog_and_scripts.py",
      "lineno": 345,
      "end_lineno": 405,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test CR_05 query is aligned with correct audited baseline (3-table join with CASE WHEN FX logic).",
        "returns": null,
        "raw": "Test CR_05 query is aligned with correct audited baseline (3-table join with CASE WHEN FX logic)."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_scripts_importable",
      "qualname": "test_scripts_importable",
      "enclosing": [],
      "module": "tests.test_smoke_catalog_and_scripts",
      "file": "tests\\test_smoke_catalog_and_scripts.py",
      "lineno": 418,
      "end_lineno": 420,
      "decorators": [
        "pytest.mark.parametrize('module_name', ['scripts.generate_customer_accounts', 'scripts.generate_collection_accounts', 'scripts.generate_other_ar', 'scripts.run_sql_from_catalog', 'scripts.check_mssql_connection'])"
      ],
      "parameters": [
        {
          "name": "module_name",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_build_connection_string_requires_env",
      "qualname": "test_build_connection_string_requires_env",
      "enclosing": [],
      "module": "tests.test_smoke_catalog_and_scripts",
      "file": "tests\\test_smoke_catalog_and_scripts.py",
      "lineno": 423,
      "end_lineno": 437,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_import_evidence_locator",
      "qualname": "test_import_evidence_locator",
      "enclosing": [],
      "module": "tests.test_smoke_core_modules",
      "file": "tests\\test_smoke_core_modules.py",
      "lineno": 20,
      "end_lineno": 24,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that evidence_locator module can be imported.",
        "returns": null,
        "raw": "Test that evidence_locator module can be imported."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_import_extraction_pipeline",
      "qualname": "test_import_extraction_pipeline",
      "enclosing": [],
      "module": "tests.test_smoke_core_modules",
      "file": "tests\\test_smoke_core_modules.py",
      "lineno": 27,
      "end_lineno": 36,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that extraction_pipeline module can be imported.",
        "returns": null,
        "raw": "Test that extraction_pipeline module can be imported."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_import_jdash_loader",
      "qualname": "test_import_jdash_loader",
      "enclosing": [],
      "module": "tests.test_smoke_core_modules",
      "file": "tests\\test_smoke_core_modules.py",
      "lineno": 39,
      "end_lineno": 48,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that jdash_loader module can be imported.",
        "returns": null,
        "raw": "Test that jdash_loader module can be imported."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_import_scope_filtering",
      "qualname": "test_import_scope_filtering",
      "enclosing": [],
      "module": "tests.test_smoke_core_modules",
      "file": "tests\\test_smoke_core_modules.py",
      "lineno": 51,
      "end_lineno": 61,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that scope_filtering module can be imported.",
        "returns": null,
        "raw": "Test that scope_filtering module can be imported."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_backward_compatibility_classifier_import",
      "qualname": "test_backward_compatibility_classifier_import",
      "enclosing": [],
      "module": "tests.test_smoke_core_modules",
      "file": "tests\\test_smoke_core_modules.py",
      "lineno": 64,
      "end_lineno": 67,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that classifier still exports _filter_ipe08_scope.",
        "returns": null,
        "raw": "Test that classifier still exports _filter_ipe08_scope."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_non_marketing_uses_values",
      "qualname": "test_non_marketing_uses_values",
      "enclosing": [],
      "module": "tests.test_smoke_core_modules",
      "file": "tests\\test_smoke_core_modules.py",
      "lineno": 70,
      "end_lineno": 82,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that NON_MARKETING_USES contains expected values.",
        "returns": null,
        "raw": "Test that NON_MARKETING_USES contains expected values."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_extraction_pipeline_instantiation",
      "qualname": "test_extraction_pipeline_instantiation",
      "enclosing": [],
      "module": "tests.test_smoke_core_modules",
      "file": "tests\\test_smoke_core_modules.py",
      "lineno": 85,
      "end_lineno": 97,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that ExtractionPipeline can be instantiated.",
        "returns": null,
        "raw": "Test that ExtractionPipeline can be instantiated."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_jdash_loader_empty_handling",
      "qualname": "test_jdash_loader_empty_handling",
      "enclosing": [],
      "module": "tests.test_smoke_core_modules",
      "file": "tests\\test_smoke_core_modules.py",
      "lineno": 100,
      "end_lineno": 108,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that jdash_loader handles empty input correctly.",
        "returns": null,
        "raw": "Test that jdash_loader handles empty input correctly."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_scope_filtering_empty_handling",
      "qualname": "test_scope_filtering_empty_handling",
      "enclosing": [],
      "module": "tests.test_smoke_core_modules",
      "file": "tests\\test_smoke_core_modules.py",
      "lineno": 111,
      "end_lineno": 122,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that scope_filtering handles empty input correctly.",
        "returns": null,
        "raw": "Test that scope_filtering handles empty input correctly."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_evidence_locator_nonexistent_path",
      "qualname": "test_evidence_locator_nonexistent_path",
      "enclosing": [],
      "module": "tests.test_smoke_core_modules",
      "file": "tests\\test_smoke_core_modules.py",
      "lineno": 125,
      "end_lineno": 130,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that evidence_locator handles nonexistent paths correctly.",
        "returns": null,
        "raw": "Test that evidence_locator handles nonexistent paths correctly."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_lookup_by_voucher_no_in_ipe08",
      "qualname": "TestVoucherTypeLookupPrimary.test_lookup_by_voucher_no_in_ipe08",
      "enclosing": [
        "TestVoucherTypeLookupPrimary"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 19,
      "end_lineno": 27,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test successful lookup by voucher_no in IPE_08",
        "returns": null,
        "raw": "Test successful lookup by voucher_no in IPE_08"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_lookup_by_voucher_no_in_usage_df",
      "qualname": "TestVoucherTypeLookupPrimary.test_lookup_by_voucher_no_in_usage_df",
      "enclosing": [
        "TestVoucherTypeLookupPrimary"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 29,
      "end_lineno": 38,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test successful lookup by voucher_no in doc_voucher_usage_df",
        "returns": null,
        "raw": "Test successful lookup by voucher_no in doc_voucher_usage_df"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_ipe08_takes_priority_over_usage_df",
      "qualname": "TestVoucherTypeLookupPrimary.test_ipe08_takes_priority_over_usage_df",
      "enclosing": [
        "TestVoucherTypeLookupPrimary"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 40,
      "end_lineno": 53,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that IPE_08 match takes priority over doc_voucher_usage_df",
        "returns": null,
        "raw": "Test that IPE_08 match takes priority over doc_voucher_usage_df"
      }
    },
    {
      "kind": "class",
      "name": "TestVoucherTypeLookupPrimary",
      "qualname": "TestVoucherTypeLookupPrimary",
      "enclosing": [],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 16,
      "end_lineno": 53,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for primary lookup by voucher_no -> id",
        "raw": "Tests for primary lookup by voucher_no -> id"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_fallback_when_voucher_no_is_empty",
      "qualname": "TestVoucherTypeLookupFallback.test_fallback_when_voucher_no_is_empty",
      "enclosing": [
        "TestVoucherTypeLookupFallback"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 59,
      "end_lineno": 69,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test fallback to Transaction_No when voucher_no is empty",
        "returns": null,
        "raw": "Test fallback to Transaction_No when voucher_no is empty"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_fallback_when_voucher_no_is_none",
      "qualname": "TestVoucherTypeLookupFallback.test_fallback_when_voucher_no_is_none",
      "enclosing": [
        "TestVoucherTypeLookupFallback"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 71,
      "end_lineno": 81,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test fallback to Transaction_No when voucher_no is None",
        "returns": null,
        "raw": "Test fallback to Transaction_No when voucher_no is None"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_fallback_when_voucher_no_not_found",
      "qualname": "TestVoucherTypeLookupFallback.test_fallback_when_voucher_no_not_found",
      "enclosing": [
        "TestVoucherTypeLookupFallback"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 83,
      "end_lineno": 93,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test fallback to Transaction_No when voucher_no doesn't match",
        "returns": null,
        "raw": "Test fallback to Transaction_No when voucher_no doesn't match"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_fallback_with_ipe08_present_but_no_match",
      "qualname": "TestVoucherTypeLookupFallback.test_fallback_with_ipe08_present_but_no_match",
      "enclosing": [
        "TestVoucherTypeLookupFallback"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 95,
      "end_lineno": 109,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test fallback works even when IPE_08 is present but has no match",
        "returns": null,
        "raw": "Test fallback works even when IPE_08 is present but has no match"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_no_fallback_when_transaction_no_column_missing",
      "qualname": "TestVoucherTypeLookupFallback.test_no_fallback_when_transaction_no_column_missing",
      "enclosing": [
        "TestVoucherTypeLookupFallback"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 111,
      "end_lineno": 120,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test no fallback when Transaction_No column doesn't exist",
        "returns": null,
        "raw": "Test no fallback when Transaction_No column doesn't exist"
      }
    },
    {
      "kind": "class",
      "name": "TestVoucherTypeLookupFallback",
      "qualname": "TestVoucherTypeLookupFallback",
      "enclosing": [],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 56,
      "end_lineno": 120,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for fallback lookup by doc_no -> Transaction_No",
        "raw": "Tests for fallback lookup by doc_no -> Transaction_No"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_empty_dataframes",
      "qualname": "TestVoucherTypeLookupEdgeCases.test_empty_dataframes",
      "enclosing": [
        "TestVoucherTypeLookupEdgeCases"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 126,
      "end_lineno": 129,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with empty DataFrames",
        "returns": null,
        "raw": "Test with empty DataFrames"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_none_dataframes",
      "qualname": "TestVoucherTypeLookupEdgeCases.test_none_dataframes",
      "enclosing": [
        "TestVoucherTypeLookupEdgeCases"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 131,
      "end_lineno": 134,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with None DataFrames",
        "returns": null,
        "raw": "Test with None DataFrames"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_missing_business_use_column",
      "qualname": "TestVoucherTypeLookupEdgeCases.test_missing_business_use_column",
      "enclosing": [
        "TestVoucherTypeLookupEdgeCases"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 136,
      "end_lineno": 145,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test when business_use column is missing",
        "returns": null,
        "raw": "Test when business_use column is missing"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_type_conversion_in_matching",
      "qualname": "TestVoucherTypeLookupEdgeCases.test_type_conversion_in_matching",
      "enclosing": [
        "TestVoucherTypeLookupEdgeCases"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 147,
      "end_lineno": 157,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that numeric IDs are properly converted to strings for matching",
        "returns": null,
        "raw": "Test that numeric IDs are properly converted to strings for matching"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_whitespace_handling",
      "qualname": "TestVoucherTypeLookupEdgeCases.test_whitespace_handling",
      "enclosing": [
        "TestVoucherTypeLookupEdgeCases"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 159,
      "end_lineno": 169,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that whitespace in IDs is handled correctly",
        "returns": null,
        "raw": "Test that whitespace in IDs is handled correctly"
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_whitespace_in_transaction_no",
      "qualname": "TestVoucherTypeLookupEdgeCases.test_whitespace_in_transaction_no",
      "enclosing": [
        "TestVoucherTypeLookupEdgeCases"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 171,
      "end_lineno": 181,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that whitespace in Transaction_No is handled correctly",
        "returns": null,
        "raw": "Test that whitespace in Transaction_No is handled correctly"
      }
    },
    {
      "kind": "class",
      "name": "TestVoucherTypeLookupEdgeCases",
      "qualname": "TestVoucherTypeLookupEdgeCases",
      "enclosing": [],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 123,
      "end_lineno": 181,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for edge cases",
        "raw": "Tests for edge cases"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_itempricecredit_without_voucher_no",
      "qualname": "TestNigeriaIntegrationIssue.test_itempricecredit_without_voucher_no",
      "enclosing": [
        "TestNigeriaIntegrationIssue"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 187,
      "end_lineno": 208,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test the Nigeria exception case where ITEMPRICECREDIT appears without",
        "returns": null,
        "raw": "Test the Nigeria exception case where ITEMPRICECREDIT appears without \nvoucher ID but has a transaction number.\n\nThis simulates a NAV entry like:\n- Voucher No_: \"\" (missing)\n- Document No: \"TRX12345\" \n- Document Description: \"ITEMPRICECREDIT\"\n\nShould match to BOB transaction and retrieve business_use."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_mixed_scenario_some_with_voucher_some_without",
      "qualname": "TestNigeriaIntegrationIssue.test_mixed_scenario_some_with_voucher_some_without",
      "enclosing": [
        "TestNigeriaIntegrationIssue"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 210,
      "end_lineno": 231,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test a mixed scenario where some transactions have voucher_no",
        "returns": null,
        "raw": "Test a mixed scenario where some transactions have voucher_no \nand others rely on Transaction_No fallback"
      }
    },
    {
      "kind": "class",
      "name": "TestNigeriaIntegrationIssue",
      "qualname": "TestNigeriaIntegrationIssue",
      "enclosing": [],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 184,
      "end_lineno": 231,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests specific to the Nigeria Integration Issue mentioned in the task",
        "raw": "Tests specific to the Nigeria Integration Issue mentioned in the task"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_both_implementations_give_same_results",
      "qualname": "TestBackwardCompatibility.test_both_implementations_give_same_results",
      "enclosing": [
        "TestBackwardCompatibility"
      ],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 237,
      "end_lineno": 262,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that both lookup_voucher_type implementations produce the same results",
        "returns": null,
        "raw": "Test that both lookup_voucher_type implementations produce the same results"
      }
    },
    {
      "kind": "class",
      "name": "TestBackwardCompatibility",
      "qualname": "TestBackwardCompatibility",
      "enclosing": [],
      "module": "tests.test_voucher_type_lookup",
      "file": "tests\\test_voucher_type_lookup.py",
      "lineno": 234,
      "end_lineno": 262,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for backward compatibility with classifier.py",
        "raw": "Tests for backward compatibility with classifier.py"
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_standard_retry_policy_exists",
      "qualname": "test_standard_retry_policy_exists",
      "enclosing": [],
      "module": "tests.archive.test_retry_policy",
      "file": "tests\\archive\\test_retry_policy.py",
      "lineno": 14,
      "end_lineno": 18,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that STANDARD_DB_RETRY_POLICY is defined in cpg1_workflow.",
        "returns": null,
        "raw": "Test that STANDARD_DB_RETRY_POLICY is defined in cpg1_workflow."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_retry_policy_has_exponential_backoff",
      "qualname": "test_retry_policy_has_exponential_backoff",
      "enclosing": [],
      "module": "tests.archive.test_retry_policy",
      "file": "tests\\archive\\test_retry_policy.py",
      "lineno": 21,
      "end_lineno": 27,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that retry policy has exponential backoff configured.",
        "returns": null,
        "raw": "Test that retry policy has exponential backoff configured."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_retry_policy_has_maximum_attempts",
      "qualname": "test_retry_policy_has_maximum_attempts",
      "enclosing": [],
      "module": "tests.archive.test_retry_policy",
      "file": "tests\\archive\\test_retry_policy.py",
      "lineno": 30,
      "end_lineno": 36,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that retry policy has reasonable maximum attempts.",
        "returns": null,
        "raw": "Test that retry policy has reasonable maximum attempts."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_retry_policy_has_maximum_interval",
      "qualname": "test_retry_policy_has_maximum_interval",
      "enclosing": [],
      "module": "tests.archive.test_retry_policy",
      "file": "tests\\archive\\test_retry_policy.py",
      "lineno": 39,
      "end_lineno": 49,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that retry policy has maximum interval configured.",
        "returns": null,
        "raw": "Test that retry policy has maximum interval configured."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_retry_policy_has_initial_interval",
      "qualname": "test_retry_policy_has_initial_interval",
      "enclosing": [],
      "module": "tests.archive.test_retry_policy",
      "file": "tests\\archive\\test_retry_policy.py",
      "lineno": 52,
      "end_lineno": 62,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that retry policy has initial interval configured.",
        "returns": null,
        "raw": "Test that retry policy has initial interval configured."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_retry_policy_excludes_validation_errors",
      "qualname": "test_retry_policy_excludes_validation_errors",
      "enclosing": [],
      "module": "tests.archive.test_retry_policy",
      "file": "tests\\archive\\test_retry_policy.py",
      "lineno": 65,
      "end_lineno": 71,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that retry policy excludes IPEValidationError from retries.",
        "returns": null,
        "raw": "Test that retry policy excludes IPEValidationError from retries."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_retry_policy_excludes_value_errors",
      "qualname": "test_retry_policy_excludes_value_errors",
      "enclosing": [],
      "module": "tests.archive.test_retry_policy",
      "file": "tests\\archive\\test_retry_policy.py",
      "lineno": 74,
      "end_lineno": 80,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that retry policy excludes ValueError from retries.",
        "returns": null,
        "raw": "Test that retry policy excludes ValueError from retries."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_retry_policy_excludes_key_errors",
      "qualname": "test_retry_policy_excludes_key_errors",
      "enclosing": [],
      "module": "tests.archive.test_retry_policy",
      "file": "tests\\archive\\test_retry_policy.py",
      "lineno": 83,
      "end_lineno": 89,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that retry policy excludes KeyError from retries.",
        "returns": null,
        "raw": "Test that retry policy excludes KeyError from retries."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_retry_policy_excludes_type_errors",
      "qualname": "test_retry_policy_excludes_type_errors",
      "enclosing": [],
      "module": "tests.archive.test_retry_policy",
      "file": "tests\\archive\\test_retry_policy.py",
      "lineno": 92,
      "end_lineno": 98,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that retry policy excludes TypeError from retries.",
        "returns": null,
        "raw": "Test that retry policy excludes TypeError from retries."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_workflow_imports",
      "qualname": "test_workflow_imports",
      "enclosing": [],
      "module": "tests.archive.test_retry_policy",
      "file": "tests\\archive\\test_retry_policy.py",
      "lineno": 101,
      "end_lineno": 106,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that workflow and retry policy can be imported together.",
        "returns": null,
        "raw": "Test that workflow and retry policy can be imported together."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_retry_policy_is_workflow_retry_policy_type",
      "qualname": "test_retry_policy_is_workflow_retry_policy_type",
      "enclosing": [],
      "module": "tests.archive.test_retry_policy",
      "file": "tests\\archive\\test_retry_policy.py",
      "lineno": 109,
      "end_lineno": 116,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that STANDARD_DB_RETRY_POLICY is of the correct type.",
        "returns": null,
        "raw": "Test that STANDARD_DB_RETRY_POLICY is of the correct type."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_retry_backoff_progression",
      "qualname": "test_retry_backoff_progression",
      "enclosing": [],
      "module": "tests.archive.test_retry_policy",
      "file": "tests\\archive\\test_retry_policy.py",
      "lineno": 119,
      "end_lineno": 140,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that retry backoff progression is as expected.",
        "returns": null,
        "raw": "Test that retry backoff progression is as expected."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_imports",
      "qualname": "test_imports",
      "enclosing": [],
      "module": "tests.archive.test_temporal_setup",
      "file": "tests\\archive\\test_temporal_setup.py",
      "lineno": 16,
      "end_lineno": 44,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that all Temporal components can be imported.",
        "returns": null,
        "raw": "Test that all Temporal components can be imported."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_dataframe_serialization",
      "qualname": "test_dataframe_serialization",
      "enclosing": [],
      "module": "tests.archive.test_temporal_setup",
      "file": "tests\\archive\\test_temporal_setup.py",
      "lineno": 47,
      "end_lineno": 80,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test DataFrame serialization and deserialization.",
        "returns": null,
        "raw": "Test DataFrame serialization and deserialization."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_empty_dataframe_serialization",
      "qualname": "test_empty_dataframe_serialization",
      "enclosing": [],
      "module": "tests.archive.test_temporal_setup",
      "file": "tests\\archive\\test_temporal_setup.py",
      "lineno": 83,
      "end_lineno": 100,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test serialization of empty DataFrames.",
        "returns": null,
        "raw": "Test serialization of empty DataFrames."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_activity_decorators",
      "qualname": "test_activity_decorators",
      "enclosing": [],
      "module": "tests.archive.test_temporal_setup",
      "file": "tests\\archive\\test_temporal_setup.py",
      "lineno": 103,
      "end_lineno": 116,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that activities have correct Temporal decorators.",
        "returns": null,
        "raw": "Test that activities have correct Temporal decorators."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_workflow_decorator",
      "qualname": "test_workflow_decorator",
      "enclosing": [],
      "module": "tests.archive.test_temporal_setup",
      "file": "tests\\archive\\test_temporal_setup.py",
      "lineno": 119,
      "end_lineno": 126,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that workflow has correct Temporal decorator.",
        "returns": null,
        "raw": "Test that workflow has correct Temporal decorator."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_workflow_run_method",
      "qualname": "test_workflow_run_method",
      "enclosing": [],
      "module": "tests.archive.test_temporal_setup",
      "file": "tests\\archive\\test_temporal_setup.py",
      "lineno": 129,
      "end_lineno": 135,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that workflow has a run method.",
        "returns": null,
        "raw": "Test that workflow has a run method."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_activity_signatures",
      "qualname": "test_activity_signatures",
      "enclosing": [],
      "module": "tests.archive.test_temporal_setup",
      "file": "tests\\archive\\test_temporal_setup.py",
      "lineno": 138,
      "end_lineno": 160,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that activity functions have expected signatures.",
        "returns": null,
        "raw": "Test that activity functions have expected signatures."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_core_business_logic_imports",
      "qualname": "test_core_business_logic_imports",
      "enclosing": [],
      "module": "tests.archive.test_temporal_setup",
      "file": "tests\\archive\\test_temporal_setup.py",
      "lineno": 163,
      "end_lineno": 176,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that core business logic functions can be imported.",
        "returns": null,
        "raw": "Test that core business logic functions can be imported."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_workflow_starter_imports",
      "qualname": "test_workflow_starter_imports",
      "enclosing": [],
      "module": "tests.archive.test_temporal_setup",
      "file": "tests\\archive\\test_temporal_setup.py",
      "lineno": 179,
      "end_lineno": 193,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that workflow starter script can import required modules.",
        "returns": null,
        "raw": "Test that workflow starter script can import required modules."
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "test_worker_script_imports",
      "qualname": "test_worker_script_imports",
      "enclosing": [],
      "module": "tests.archive.test_temporal_setup",
      "file": "tests\\archive\\test_temporal_setup.py",
      "lineno": 196,
      "end_lineno": 213,
      "decorators": [],
      "parameters": [],
      "return_annotation": null,
      "doc": {
        "summary": "Test that worker script can import required modules.",
        "returns": null,
        "raw": "Test that worker script can import required modules."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_missing_cutoff_date",
      "qualname": "TestValidateParams.test_missing_cutoff_date",
      "enclosing": [
        "TestValidateParams"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 22,
      "end_lineno": 26,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that missing cutoff_date is reported as error.",
        "returns": null,
        "raw": "Test that missing cutoff_date is reported as error."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_missing_company",
      "qualname": "TestValidateParams.test_missing_company",
      "enclosing": [
        "TestValidateParams"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 28,
      "end_lineno": 32,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that missing id_companies_active is reported as error.",
        "returns": null,
        "raw": "Test that missing id_companies_active is reported as error."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_invalid_date_format",
      "qualname": "TestValidateParams.test_invalid_date_format",
      "enclosing": [
        "TestValidateParams"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 34,
      "end_lineno": 41,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that invalid date format is reported as error.",
        "returns": null,
        "raw": "Test that invalid date format is reported as error."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_valid_params",
      "qualname": "TestValidateParams.test_valid_params",
      "enclosing": [
        "TestValidateParams"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 43,
      "end_lineno": 50,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that valid params return no errors.",
        "returns": null,
        "raw": "Test that valid params return no errors."
      }
    },
    {
      "kind": "class",
      "name": "TestValidateParams",
      "qualname": "TestValidateParams",
      "enclosing": [],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 19,
      "end_lineno": 50,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for parameter validation.",
        "raw": "Tests for parameter validation."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_empty_dataframe",
      "qualname": "TestGetDataframeSummary.test_empty_dataframe",
      "enclosing": [
        "TestGetDataframeSummary"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 56,
      "end_lineno": 61,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test summary of empty DataFrame.",
        "returns": null,
        "raw": "Test summary of empty DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_none_dataframe",
      "qualname": "TestGetDataframeSummary.test_none_dataframe",
      "enclosing": [
        "TestGetDataframeSummary"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 63,
      "end_lineno": 67,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test summary of None DataFrame.",
        "returns": null,
        "raw": "Test summary of None DataFrame."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_normal_dataframe",
      "qualname": "TestGetDataframeSummary.test_normal_dataframe",
      "enclosing": [
        "TestGetDataframeSummary"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 69,
      "end_lineno": 79,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test summary of normal DataFrame.",
        "returns": null,
        "raw": "Test summary of normal DataFrame."
      }
    },
    {
      "kind": "class",
      "name": "TestGetDataframeSummary",
      "qualname": "TestGetDataframeSummary",
      "enclosing": [],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 53,
      "end_lineno": 79,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for DataFrame summary generation.",
        "raw": "Tests for DataFrame summary generation."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_default_ipes_not_empty",
      "qualname": "TestGetDefaultIpes.test_default_ipes_not_empty",
      "enclosing": [
        "TestGetDefaultIpes"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 85,
      "end_lineno": 88,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that default IPEs list is not empty.",
        "returns": null,
        "raw": "Test that default IPEs list is not empty."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_default_ipes_contains_critical_items",
      "qualname": "TestGetDefaultIpes.test_default_ipes_contains_critical_items",
      "enclosing": [
        "TestGetDefaultIpes"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 90,
      "end_lineno": 96,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that default IPEs contain critical reconciliation items.",
        "returns": null,
        "raw": "Test that default IPEs contain critical reconciliation items."
      }
    },
    {
      "kind": "class",
      "name": "TestGetDefaultIpes",
      "qualname": "TestGetDefaultIpes",
      "enclosing": [],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 82,
      "end_lineno": 96,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for default IPE list.",
        "raw": "Tests for default IPE list."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_returns_required_keys",
      "qualname": "TestRunReconciliation.test_returns_required_keys",
      "enclosing": [
        "TestRunReconciliation"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 102,
      "end_lineno": 123,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that result contains all required keys.",
        "returns": null,
        "raw": "Test that result contains all required keys."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_error_status_on_missing_params",
      "qualname": "TestRunReconciliation.test_error_status_on_missing_params",
      "enclosing": [
        "TestRunReconciliation"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 125,
      "end_lineno": 132,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that error status is returned for missing params.",
        "returns": null,
        "raw": "Test that error status is returned for missing params."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_timestamp_is_iso_format",
      "qualname": "TestRunReconciliation.test_timestamp_is_iso_format",
      "enclosing": [
        "TestRunReconciliation"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 134,
      "end_lineno": 150,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that timestamp is in ISO format.",
        "returns": null,
        "raw": "Test that timestamp is in ISO format."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_params_echoed_in_result",
      "qualname": "TestRunReconciliation.test_params_echoed_in_result",
      "enclosing": [
        "TestRunReconciliation"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 152,
      "end_lineno": 165,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that input params are echoed in result.",
        "returns": null,
        "raw": "Test that input params are echoed in result."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_with_mock_data",
      "qualname": "TestRunReconciliation.test_with_mock_data",
      "enclosing": [
        "TestRunReconciliation"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 167,
      "end_lineno": 204,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test reconciliation with mock data.",
        "returns": null,
        "raw": "Test reconciliation with mock data."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_categorization_with_mock_data",
      "qualname": "TestRunReconciliation.test_categorization_with_mock_data",
      "enclosing": [
        "TestRunReconciliation"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 206,
      "end_lineno": 232,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that categorization runs on CR_03 data.",
        "returns": null,
        "raw": "Test that categorization runs on CR_03 data."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_json_serializable_output",
      "qualname": "TestRunReconciliation.test_json_serializable_output",
      "enclosing": [
        "TestRunReconciliation"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 234,
      "end_lineno": 253,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test that result is JSON serializable.",
        "returns": null,
        "raw": "Test that result is JSON serializable."
      }
    },
    {
      "kind": "class",
      "name": "TestRunReconciliation",
      "qualname": "TestRunReconciliation",
      "enclosing": [],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 99,
      "end_lineno": 253,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for the main run_reconciliation function.",
        "raw": "Tests for the main run_reconciliation function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_full_pipeline_with_fixtures",
      "qualname": "TestReconciliationIntegration.test_full_pipeline_with_fixtures",
      "enclosing": [
        "TestReconciliationIntegration"
      ],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 259,
      "end_lineno": 334,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test full pipeline with fixture data if available.",
        "returns": null,
        "raw": "Test full pipeline with fixture data if available."
      }
    },
    {
      "kind": "class",
      "name": "TestReconciliationIntegration",
      "qualname": "TestReconciliationIntegration",
      "enclosing": [],
      "module": "tests.reconciliation.test_run_reconciliation",
      "file": "tests\\reconciliation\\test_run_reconciliation.py",
      "lineno": 256,
      "end_lineno": 334,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Integration tests for the reconciliation pipeline.",
        "raw": "Integration tests for the reconciliation pipeline."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_empty_data_store",
      "qualname": "TestSummaryBuilder.test_empty_data_store",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 19,
      "end_lineno": 27,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with completely empty data store.",
        "returns": null,
        "raw": "Test with completely empty data store."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calculate_actuals_with_valid_data",
      "qualname": "TestSummaryBuilder.test_calculate_actuals_with_valid_data",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 29,
      "end_lineno": 39,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test actuals calculation with valid CR_04 data.",
        "returns": null,
        "raw": "Test actuals calculation with valid CR_04 data."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calculate_actuals_with_alternative_column_name",
      "qualname": "TestSummaryBuilder.test_calculate_actuals_with_alternative_column_name",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 41,
      "end_lineno": 51,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test actuals calculation with alternative column names.",
        "returns": null,
        "raw": "Test actuals calculation with alternative column names."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calculate_actuals_missing_cr04",
      "qualname": "TestSummaryBuilder.test_calculate_actuals_missing_cr04",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 53,
      "end_lineno": 58,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test actuals calculation when CR_04 is missing.",
        "returns": null,
        "raw": "Test actuals calculation when CR_04 is missing."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calculate_actuals_empty_cr04",
      "qualname": "TestSummaryBuilder.test_calculate_actuals_empty_cr04",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 60,
      "end_lineno": 67,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test actuals calculation when CR_04 is empty.",
        "returns": null,
        "raw": "Test actuals calculation when CR_04 is empty."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calculate_actuals_no_amount_column",
      "qualname": "TestSummaryBuilder.test_calculate_actuals_no_amount_column",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 69,
      "end_lineno": 79,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test actuals calculation when no amount column is found.",
        "returns": null,
        "raw": "Test actuals calculation when no amount column is found."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calculate_target_values_with_valid_data",
      "qualname": "TestSummaryBuilder.test_calculate_target_values_with_valid_data",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 81,
      "end_lineno": 95,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test target values calculation with valid component IPEs.",
        "returns": null,
        "raw": "Test target values calculation with valid component IPEs."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calculate_target_values_partial_data",
      "qualname": "TestSummaryBuilder.test_calculate_target_values_partial_data",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 97,
      "end_lineno": 111,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test target values calculation with only some components available.",
        "returns": null,
        "raw": "Test target values calculation with only some components available."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calculate_target_values_empty_dataframes",
      "qualname": "TestSummaryBuilder.test_calculate_target_values_empty_dataframes",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 113,
      "end_lineno": 124,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test target values calculation with empty DataFrames.",
        "returns": null,
        "raw": "Test target values calculation with empty DataFrames."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_calculate_target_values_invalid_column_data",
      "qualname": "TestSummaryBuilder.test_calculate_target_values_invalid_column_data",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 126,
      "end_lineno": 137,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test target values calculation with invalid data types in columns.",
        "returns": null,
        "raw": "Test target values calculation with invalid data types in columns."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_build_complete_reconciliation",
      "qualname": "TestSummaryBuilder.test_build_complete_reconciliation",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 139,
      "end_lineno": 154,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test complete reconciliation with actuals and targets.",
        "returns": null,
        "raw": "Test complete reconciliation with actuals and targets."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_build_with_variance",
      "qualname": "TestSummaryBuilder.test_build_with_variance",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 156,
      "end_lineno": 171,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test reconciliation with variance exceeding threshold.",
        "returns": null,
        "raw": "Test reconciliation with variance exceeding threshold."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_build_with_missing_actuals",
      "qualname": "TestSummaryBuilder.test_build_with_missing_actuals",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 173,
      "end_lineno": 186,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test reconciliation when actuals cannot be calculated.",
        "returns": null,
        "raw": "Test reconciliation when actuals cannot be calculated."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_build_with_missing_targets",
      "qualname": "TestSummaryBuilder.test_build_with_missing_targets",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 188,
      "end_lineno": 201,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test reconciliation when targets cannot be calculated.",
        "returns": null,
        "raw": "Test reconciliation when targets cannot be calculated."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_variance_at_threshold_boundary",
      "qualname": "TestSummaryBuilder.test_variance_at_threshold_boundary",
      "enclosing": [
        "TestSummaryBuilder"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 203,
      "end_lineno": 223,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test variance calculation at the threshold boundary (1000).",
        "returns": null,
        "raw": "Test variance calculation at the threshold boundary (1000)."
      }
    },
    {
      "kind": "class",
      "name": "TestSummaryBuilder",
      "qualname": "TestSummaryBuilder",
      "enclosing": [],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 16,
      "end_lineno": 223,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for SummaryBuilder class.",
        "raw": "Tests for SummaryBuilder class."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_convenience_function",
      "qualname": "TestCalculateReconciliationMetrics.test_convenience_function",
      "enclosing": [
        "TestCalculateReconciliationMetrics"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 229,
      "end_lineno": 240,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test the convenience function wrapper.",
        "returns": null,
        "raw": "Test the convenience function wrapper."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_convenience_function_empty_data",
      "qualname": "TestCalculateReconciliationMetrics.test_convenience_function_empty_data",
      "enclosing": [
        "TestCalculateReconciliationMetrics"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 242,
      "end_lineno": 248,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test convenience function with empty data.",
        "returns": null,
        "raw": "Test convenience function with empty data."
      }
    },
    {
      "kind": "class",
      "name": "TestCalculateReconciliationMetrics",
      "qualname": "TestCalculateReconciliationMetrics",
      "enclosing": [],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 226,
      "end_lineno": 248,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for the convenience function.",
        "raw": "Tests for the convenience function."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_negative_amounts",
      "qualname": "TestEdgeCases.test_negative_amounts",
      "enclosing": [
        "TestEdgeCases"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 254,
      "end_lineno": 266,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test handling of negative amounts in actuals.",
        "returns": null,
        "raw": "Test handling of negative amounts in actuals."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_very_large_numbers",
      "qualname": "TestEdgeCases.test_very_large_numbers",
      "enclosing": [
        "TestEdgeCases"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 268,
      "end_lineno": 280,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test handling of very large financial amounts.",
        "returns": null,
        "raw": "Test handling of very large financial amounts."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_zero_amounts",
      "qualname": "TestEdgeCases.test_zero_amounts",
      "enclosing": [
        "TestEdgeCases"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 282,
      "end_lineno": 295,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test handling of zero amounts.",
        "returns": null,
        "raw": "Test handling of zero amounts."
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "test_mixed_column_types",
      "qualname": "TestEdgeCases.test_mixed_column_types",
      "enclosing": [
        "TestEdgeCases"
      ],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 297,
      "end_lineno": 311,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": "Test with different column name variations across IPEs.",
        "returns": null,
        "raw": "Test with different column name variations across IPEs."
      }
    },
    {
      "kind": "class",
      "name": "TestEdgeCases",
      "qualname": "TestEdgeCases",
      "enclosing": [],
      "module": "tests.reconciliation.test_summary_builder",
      "file": "tests\\reconciliation\\test_summary_builder.py",
      "lineno": 251,
      "end_lineno": 311,
      "decorators": [],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": "Tests for edge cases and error conditions.",
        "raw": "Tests for edge cases and error conditions."
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "safe_unparse",
      "qualname": "safe_unparse",
      "enclosing": [],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 24,
      "end_lineno": 30,
      "decorators": [],
      "parameters": [
        {
          "name": "node",
          "kind": "positional_or_keyword",
          "annotation": "Optional[ast.AST]",
          "default": null
        }
      ],
      "return_annotation": "Optional[str]",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "read_text",
      "qualname": "read_text",
      "enclosing": [],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 33,
      "end_lineno": 34,
      "decorators": [],
      "parameters": [
        {
          "name": "path",
          "kind": "positional_or_keyword",
          "annotation": "Path",
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "should_skip_path",
      "qualname": "should_skip_path",
      "enclosing": [],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 37,
      "end_lineno": 39,
      "decorators": [],
      "parameters": [
        {
          "name": "path",
          "kind": "positional_or_keyword",
          "annotation": "Path",
          "default": null
        },
        {
          "name": "exclude_names",
          "kind": "positional_or_keyword",
          "annotation": "set[str]",
          "default": null
        }
      ],
      "return_annotation": "bool",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "doc_summary",
      "qualname": "doc_summary",
      "enclosing": [],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 42,
      "end_lineno": 51,
      "decorators": [],
      "parameters": [
        {
          "name": "doc",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": null
        }
      ],
      "return_annotation": "Optional[str]",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "extract_returns_from_docstring",
      "qualname": "extract_returns_from_docstring",
      "enclosing": [],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 54,
      "end_lineno": 91,
      "decorators": [],
      "parameters": [
        {
          "name": "doc",
          "kind": "positional_or_keyword",
          "annotation": "Optional[str]",
          "default": null
        }
      ],
      "return_annotation": "Optional[str]",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "class",
      "name": "Context",
      "qualname": "Context",
      "enclosing": [],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 95,
      "end_lineno": 97,
      "decorators": [
        "dataclass"
      ],
      "bases": [],
      "keywords": [],
      "doc": {
        "summary": null,
        "raw": null
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "method",
      "async": false,
      "name": "__init__",
      "qualname": "APIScanner.__init__",
      "enclosing": [
        "APIScanner"
      ],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 101,
      "end_lineno": 107,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "ctx",
          "kind": "positional_or_keyword",
          "annotation": "Context",
          "default": null
        }
      ],
      "return_annotation": null,
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "nested_function",
      "async": false,
      "name": "add_param",
      "qualname": "APIScanner._args_to_params.add_param",
      "enclosing": [
        "APIScanner",
        "_args_to_params"
      ],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 128,
      "end_lineno": 134,
      "decorators": [],
      "parameters": [
        {
          "name": "kind",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        },
        {
          "name": "a",
          "kind": "positional_or_keyword",
          "annotation": "ast.arg",
          "default": null
        },
        {
          "name": "default_node",
          "kind": "positional_or_keyword",
          "annotation": "Optional[ast.AST]",
          "default": null
        }
      ],
      "return_annotation": "None",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "visit_ClassDef",
      "qualname": "APIScanner.visit_ClassDef",
      "enclosing": [
        "APIScanner"
      ],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 220,
      "end_lineno": 237,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "node",
          "kind": "positional_or_keyword",
          "annotation": "ast.ClassDef",
          "default": null
        }
      ],
      "return_annotation": "Any",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "visit_FunctionDef",
      "qualname": "APIScanner.visit_FunctionDef",
      "enclosing": [
        "APIScanner"
      ],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 251,
      "end_lineno": 252,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "node",
          "kind": "positional_or_keyword",
          "annotation": "ast.FunctionDef",
          "default": null
        }
      ],
      "return_annotation": "Any",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "method",
      "async": false,
      "name": "visit_AsyncFunctionDef",
      "qualname": "APIScanner.visit_AsyncFunctionDef",
      "enclosing": [
        "APIScanner"
      ],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 254,
      "end_lineno": 255,
      "decorators": [],
      "parameters": [
        {
          "name": "self",
          "kind": "positional_or_keyword",
          "annotation": null,
          "default": null
        },
        {
          "name": "node",
          "kind": "positional_or_keyword",
          "annotation": "ast.AsyncFunctionDef",
          "default": null
        }
      ],
      "return_annotation": "Any",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "class",
      "name": "APIScanner",
      "qualname": "APIScanner",
      "enclosing": [],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 100,
      "end_lineno": 255,
      "decorators": [],
      "bases": [
        "ast.NodeVisitor"
      ],
      "keywords": [],
      "doc": {
        "summary": null,
        "raw": null
      },
      "methods": [],
      "init_signature": null
    },
    {
      "kind": "function",
      "async": false,
      "name": "module_from_path",
      "qualname": "module_from_path",
      "enclosing": [],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 258,
      "end_lineno": 265,
      "decorators": [],
      "parameters": [
        {
          "name": "repo_root",
          "kind": "positional_or_keyword",
          "annotation": "Path",
          "default": null
        },
        {
          "name": "file_path",
          "kind": "positional_or_keyword",
          "annotation": "Path",
          "default": null
        }
      ],
      "return_annotation": "str",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "scan_file",
      "qualname": "scan_file",
      "enclosing": [],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 268,
      "end_lineno": 282,
      "decorators": [],
      "parameters": [
        {
          "name": "repo_root",
          "kind": "positional_or_keyword",
          "annotation": "Path",
          "default": null
        },
        {
          "name": "py_path",
          "kind": "positional_or_keyword",
          "annotation": "Path",
          "default": null
        }
      ],
      "return_annotation": "Tuple[List[Dict[str, Any]], Optional[str]]",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "iter_python_files",
      "qualname": "iter_python_files",
      "enclosing": [],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 285,
      "end_lineno": 297,
      "decorators": [],
      "parameters": [
        {
          "name": "repo_root",
          "kind": "positional_or_keyword",
          "annotation": "Path",
          "default": null
        },
        {
          "name": "exclude_names",
          "kind": "positional_or_keyword",
          "annotation": "set[str]",
          "default": null
        }
      ],
      "return_annotation": "List[Path]",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "is_private_name",
      "qualname": "is_private_name",
      "enclosing": [],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 300,
      "end_lineno": 301,
      "decorators": [],
      "parameters": [
        {
          "name": "name",
          "kind": "positional_or_keyword",
          "annotation": "str",
          "default": null
        }
      ],
      "return_annotation": "bool",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    },
    {
      "kind": "function",
      "async": false,
      "name": "main",
      "qualname": "main",
      "enclosing": [],
      "module": "tools.scan_repo_api",
      "file": "tools\\scan_repo_api.py",
      "lineno": 304,
      "end_lineno": 349,
      "decorators": [],
      "parameters": [],
      "return_annotation": "None",
      "doc": {
        "summary": null,
        "returns": null,
        "raw": null
      }
    }
  ],
  "errors": []
}